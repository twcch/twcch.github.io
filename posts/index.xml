<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>所有文章 on 志謙&#39;s Blog</title>
    <link>https://twcch.github.io/posts/</link>
    <description>Recent content in 所有文章 on 志謙&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>zh-tw</language>
    <lastBuildDate>Sat, 21 Dec 2024 00:00:00 +0800</lastBuildDate>
    <atom:link href="https://twcch.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>介紹機器學習</title>
      <link>https://twcch.github.io/posts/machine-learning-lab/introduction-machine-learning/</link>
      <pubDate>Sat, 21 Dec 2024 00:00:00 +0800</pubDate>
      <guid>https://twcch.github.io/posts/machine-learning-lab/introduction-machine-learning/</guid>
      <description>&lt;h2 id=&#34;什麼是機器學習&#34;&gt;什麼是機器學習？&lt;/h2&gt;&#xA;&lt;p&gt;機器學習是一個讓電腦能夠在沒有明確編程的情況下學習的研究領域。Arthur Samuel 在 1959 年提出的經典定義：「Field of study that gives computers the ability to learn without being explicitly programmed」，至今仍然被廣泛引用。&lt;/p&gt;&#xA;&lt;p&gt;機器學習的問題主要可以歸類為以下三大類型：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;監督式學習(Supervised Learning)：基於有標籤的數據進行訓練，目的是學習輸入與輸出之間的關係。&lt;/li&gt;&#xA;&lt;li&gt;無監督式學習(Unsupervised Learning)：基於無標籤的數據進行訓練，目的是探索數據的結構或模式。&lt;/li&gt;&#xA;&lt;li&gt;強化學習(Reinforcement Learning)：透過與環境互動，學習策略以最大化獎勵。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;此外，還有一些延伸方法，例如半監督式學習(Semi-Supervised Learning)和自監督學習(Self-Supervised Learning)，這些技術在特定場景中發揮了重要作用，但不在本次討論範圍內。&lt;/p&gt;&#xA;&lt;h2 id=&#34;機器學習的概念&#34;&gt;機器學習的概念&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;先選擇一個模型(Model)，也可以稱作函數集，它擁有無窮個函數(function)&lt;/li&gt;&#xA;&lt;li&gt;透過機器找出最好的函數&lt;/li&gt;&#xA;&lt;li&gt;再透過這個最好的函數，幫我們做出預測&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;監督式學習supervised-learning&#34;&gt;監督式學習(Supervised Learning)&lt;/h2&gt;&#xA;&lt;p&gt;監督式學習是一種基於有標籤數據的訓練方式，其目的是學習輸入與輸出之間的對應關係，並用於預測新數據的結果。&#xA;常見的應用場景包括：&lt;/p&gt;&#xA;&lt;h3 id=&#34;迴歸-regression&#34;&gt;迴歸 (Regression)&lt;/h3&gt;&#xA;&lt;p&gt;用於預測連續值，例如房價預測、銷量預測。&lt;/p&gt;&#xA;&lt;h3 id=&#34;分類-classification&#34;&gt;分類 (Classification)&lt;/h3&gt;&#xA;&lt;p&gt;用於預測類別，例如垃圾郵件分類、影像中的物體識別。&lt;/p&gt;&#xA;&lt;h2 id=&#34;無監督式學習unsupervised-learning&#34;&gt;無監督式學習(Unsupervised Learning)&lt;/h2&gt;&#xA;&lt;p&gt;無監督式學習是一種基於無標籤數據的訓練方式，其目的是探索數據的內部結構或模式。&lt;/p&gt;&#xA;&lt;p&gt;常見方法包括：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;聚類(Clustering)：將數據分組，例如客戶分群。&lt;/li&gt;&#xA;&lt;li&gt;降維(Dimensionality Reduction)：壓縮數據維度，例如主成分分析(PCA)。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;其他&#34;&gt;其他&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;半監督式學習(Semi-Supervised Learning)：結合少量有標籤數據與大量無標籤數據進行訓練，應用於標籤成本較高的場景。&lt;/li&gt;&#xA;&lt;li&gt;遷移學習(Transfer Learning)：將已有模型的知識應用到新問題上，尤其在數據稀少的情況下非常有效。&lt;/li&gt;&#xA;&lt;li&gt;強化學習(Reinforcement Learning)：通過不斷與環境互動，學習如何採取最佳行動來獲取最大化回報。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;損失函數loss-function&#34;&gt;損失函數(Loss Function)&lt;/h2&gt;&#xA;&lt;p&gt;損失函數用於衡量模型的預測結果與實際目標之間的差距，是模型優化的關鍵指標。如：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;均方誤差 (Mean Squared Error, MSE)：用於迴歸問題。&lt;/li&gt;&#xA;&lt;li&gt;交叉熵損失 (Cross-Entropy Loss)：用於分類問題。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;優化算法&#34;&gt;優化算法&lt;/h2&gt;&#xA;&lt;h3 id=&#34;梯度下降法gradient-descent&#34;&gt;梯度下降法(Gradient Descent)&lt;/h3&gt;&#xA;&lt;p&gt;梯度下降是一種用於最小化損失函數的優化算法，通過不斷調整模型參數以逐步接近最優解。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
