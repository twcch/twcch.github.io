<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>志謙&#39;s Blog</title>
    <link>https://twcch.io/</link>
    <description>Recent content on 志謙&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>zh-heat</language>
    <lastBuildDate>Sat, 06 Sep 2025 00:00:00 +0800</lastBuildDate>
    <atom:link href="https://twcch.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>數據分析師的洞察之眼關聯分析</title>
      <link>https://twcch.io/posts/2025/the-art-of-association/</link>
      <pubDate>Sat, 06 Sep 2025 00:00:00 +0800</pubDate>
      <guid>https://twcch.io/posts/2025/the-art-of-association/</guid>
      <description>&lt;p&gt;關聯規則探勘，是一門讓資料自己開口說話的技術。它不預測未來，也不分類人群，而是靜靜地從無數筆交易中，尋找那些「總是一起出現」的痕跡。對數據分析師而言，這是一種不同於統計假設的思考方式——它不帶偏見，不設方向，只追隨共現的規律。&lt;/p&gt;&#xA;&lt;h2 id=&#34;啤酒與尿布的啟示&#34;&gt;啤酒與尿布的啟示&lt;/h2&gt;&#xA;&lt;p&gt;許多人第一次聽到「關聯規則探勘」 (Association Rule Mining) 這個名詞時，總會想起那個幾乎被引用成神話的故事。美國某家超市在分析顧客購物資料時，發現一個奇特的現象: 購買尿布的男性顧客，常常會順手買一瓶啤酒。&lt;/p&gt;&#xA;&lt;p&gt;當時的分析師並沒有先入為主地設定假設，他們只是單純讓演算法在龐大的交易資料中尋找共現的規律。結果揭露了一種不易察覺的生活節奏——年輕父親在深夜購物時，會同時買尿布與啤酒。這個行為的背後，不是消費理性，而是情緒的慰藉。&lt;/p&gt;&#xA;&lt;p&gt;這便是關聯規則探勘的精神所在: 它讓資料說話，而不是讓人去強迫資料符合預設的故事。在數據分析的世界裡，這種從共現關係中發現行為模式的方法，被廣泛應用於零售、金融、醫療、甚至網路內容推薦系統中。&lt;/p&gt;&#xA;&lt;h2 id=&#34;從購物籃看行為&#34;&gt;從購物籃看行為&lt;/h2&gt;&#xA;&lt;p&gt;想像一間超市的銷售資料表，每一筆交易就像一個購物籃 (basket)，裡面放著當次顧客購買的所有商品。我們想知道的問題其實很簡單:「哪些商品會經常一起被買走?」在資料的語言裡，這樣的問題就是「項目之間的共現關係」。&lt;/p&gt;&#xA;&lt;div class=&#34;callout note &#34;&gt;&#xA;  &lt;p&gt;若 20% 的交易同時出現牛奶與麵包，那麼這個組合的支持度 (support) 就是 0.2。如果在所有買牛奶的顧客中，有 80% 也買了麵包，則這條規則的信賴度 (confidence) 是 0.8。&lt;/p&gt;&#xA;&lt;p&gt;但僅憑這兩個數值，我們還無法判斷這是否只是巧合。因此分析師還會觀察第三個指標「提升度 (lift)」，即實際共現機率與隨機共現機率的比值。&lt;/p&gt;&#xA;&lt;p&gt;當 lift 大於 1，代表兩個項目之間的關聯比隨機還強；若小於 1，則可能互斥。這三個指標——support、confidence、lift——構成了關聯規則探勘的基礎語彙。&lt;/p&gt;&#xA;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;h2 id=&#34;apriori-從最常見的開始&#34;&gt;Apriori: 從最常見的開始&lt;/h2&gt;&#xA;&lt;p&gt;在技術層面上，最經典的演算法是 Apriori。它的核心思想很直觀:「若一個項目集是頻繁的 (Frequent Itemset)，那麼它的子集一定也是頻繁的。」&lt;/p&gt;&#xA;&lt;p&gt;這個原則讓我們得以從最基本的一項商品開始，逐步生成兩項、三項組合，並在每一層過濾不常見的組合，直到再也無法擴展。&lt;/p&gt;&#xA;&lt;p&gt;舉例來說，我們可以用 Python 的 mlxtend 套件進行實作:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;mlxtend.frequent_patterns&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;apriori&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;association_rules&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 模擬交易資料 (每列為一筆交易，每欄為商品)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;DataFrame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;milk&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;bread&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;beer&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;butter&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;diaper&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Step 1: 找出頻繁項集&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;frequent_itemsets&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;apriori&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;min_support&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;use_colnames&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Step 2: 產生關聯規則&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;rules&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;association_rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;frequent_itemsets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;metric&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;lift&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;min_threshold&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;rules&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;lift&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;antecedents&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;consequents&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;support&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;confidence&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;lift&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]])&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;輸出結果可能如下:&lt;/p&gt;</description>
    </item>
    <item>
      <title>在數據中尋找秩序，資料探勘的藝術</title>
      <link>https://twcch.io/posts/2025/the-art-of-data-mining/</link>
      <pubDate>Sat, 02 Aug 2025 00:00:00 +0800</pubDate>
      <guid>https://twcch.io/posts/2025/the-art-of-data-mining/</guid>
      <description>&lt;p&gt;資料探勘 (Data Mining) 是一場從混沌到洞察的旅程，它的核心不只是技術，而是一種思考方式——如何讓資料自己說話，如何從龐大的資訊中找出值得理解的模式，對數據分析師而言，資料探勘不只是「處理資料」，而是「與資料對話」。&lt;/p&gt;&#xA;&lt;h2 id=&#34;資料探勘的先備知識&#34;&gt;資料探勘的先備知識&lt;/h2&gt;&#xA;&lt;p&gt;在開始資料探勘之前，我們需要理解它的理論基礎，資料探勘並非單一技術，而是多個學科的交會點:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;統計學 (Statistics): 提供對資料分佈、變異與相關的量化理解，確保模型結果具可解釋性。&lt;/li&gt;&#xA;&lt;li&gt;機器學習 (Machine Learning): 提供自動化演算法，從資料中學習模式並進行預測。&lt;/li&gt;&#xA;&lt;li&gt;資料庫系統 (Database Systems): 讓我們能有效率地儲存、檢索與處理大規模資料。&lt;/li&gt;&#xA;&lt;li&gt;資訊視覺化 (Data Visualization): 幫助分析師以直覺方式觀察結構與異常，將複雜資料轉化為可理解的圖像。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;這些領域共同構成資料探勘的基礎，使分析師既能理解數學邏輯，也能掌握資料結構與商業語境，換言之，資料探勘的專業是「跨界的知識整合」。&lt;/p&gt;&#xA;&lt;h2 id=&#34;從資料到知識-探勘的本質&#34;&gt;從資料到知識: 探勘的本質&lt;/h2&gt;&#xA;&lt;p&gt;在商業世界裡，資料無所不在，交易紀錄、網站點擊、感測器訊號、醫療紀錄、社群互動——  這些原始資料就像尚未雕琢的石塊，只有經過提煉與建模，才能顯露出價值。&lt;/p&gt;&#xA;&lt;p&gt;資料探勘的任務，正是讓這些看似無序的碎片，拼出意義的圖像，我認為資料探勘的終極目標，不是找到答案，而是找到能啟發問題的模式，這種模式可能是一個潛在客群、一種異常行為、一組重複的事件序列，或是一個被忽略的關聯。它們都是資料在對我們說：「這裡有值得關注的事。」&lt;/p&gt;&#xA;&lt;h2 id=&#34;資料建模流程-從混沌到結構&#34;&gt;資料建模流程: 從混沌到結構&lt;/h2&gt;&#xA;&lt;p&gt;一個成熟的資料探勘專案，通常包含以下五個階段，這不僅是一套技術流程，更是一種分析思維的框架:&lt;/p&gt;&#xA;&lt;h3 id=&#34;問題定義-problem-definition&#34;&gt;問題定義 (Problem Definition)&lt;/h3&gt;&#xA;&lt;p&gt;資料探勘的起點從來不是資料，而是問題，分析師必須明確回答：「我要解決什麼？」、「我關心的現象是什麼？」，因為清晰的問題定義是所有模型的方向盤。&lt;/p&gt;&#xA;&lt;p&gt;如在商業場景中，這可能是「提高留存率」、「預測顧客流失」或「辨識詐欺行為」；在研究場景中，則可能是「發現新的疾病特徵」或「理解群體行為模式」。&lt;/p&gt;&#xA;&lt;h3 id=&#34;資料蒐集與整合-data-collection--integration&#34;&gt;資料蒐集與整合 (Data Collection &amp;amp; Integration)&lt;/h3&gt;&#xA;&lt;p&gt;資料通常分散在不同來源: 資料庫、API、感測器、或外部平台，探勘的第一步是將這些異質資料整合成可用的結構。&lt;/p&gt;&#xA;&lt;p&gt;這個階段強調資料的「廣度」，因為只有跨域整合，才能看見真正的關聯，正確的資料架構，是所有建模的基礎。&lt;/p&gt;&#xA;&lt;h3 id=&#34;資料清理與前處理-data-cleaning--preprocessing&#34;&gt;資料清理與前處理 (Data Cleaning &amp;amp; Preprocessing)&lt;/h3&gt;&#xA;&lt;p&gt;在現實中，資料是混亂的: 有缺失值、重複值、異常點與不一致的格式，分析師必須進行去噪、正規化、轉換與編碼，使資料能夠被模型正確理解，這個階段決定模型的「穩定性」，就像建築的地基——看不見，但至關重要。&lt;/p&gt;&#xA;&lt;h3 id=&#34;建模與探勘-modeling--mining&#34;&gt;建模與探勘 (Modeling &amp;amp; Mining)&lt;/h3&gt;&#xA;&lt;p&gt;當資料準備就緒，真正的探勘才開始，依照問題性質，我們可能採用不同的建模策略:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;描述性模型 (Descriptive Models) 揭示資料的結構，如分群與關聯規則。&lt;/li&gt;&#xA;&lt;li&gt;預測性模型 (Predictive Models) 預測未來行為，如分類與回歸分析。&lt;/li&gt;&#xA;&lt;li&gt;異常偵測模型 (Anomaly Detection Models) 找出與常態不同的模式，用於詐欺或風險預警。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;在這一階段，分析師不僅選擇演算法，更要確保模型的假設與資料特性相符，演算法只是工具，理解資料才是核心。&lt;/p&gt;&#xA;&lt;h3 id=&#34;評估與詮釋-evaluation--interpretation&#34;&gt;評估與詮釋 (Evaluation &amp;amp; Interpretation)&lt;/h3&gt;&#xA;&lt;p&gt;一個模型的成功，取決於它能否「解釋現實」，而不僅是數學上的優越，因此，我們不僅評估準確率或 AUC，更關心模型是否能轉化為可行的洞察。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Archive</title>
      <link>https://twcch.io/archive/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://twcch.io/archive/</guid>
      <description></description>
    </item>
    <item>
      <title>Clients</title>
      <link>https://twcch.io/clients/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://twcch.io/clients/</guid>
      <description></description>
    </item>
    <item>
      <title>Elements</title>
      <link>https://twcch.io/elements/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://twcch.io/elements/</guid>
      <description>&lt;p&gt;This page serves as a reference for the visual and functional elements used throughout the template. Here you can explore typography, buttons, forms, lists, tables, quotes, and other components to see how they are styled and displayed.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;headings-by-default&#34;&gt;Headings by default:&lt;/h2&gt;&#xA;&lt;h1 id=&#34;h1-default-styles-for-headings&#34;&gt;H1 Default styles for headings&lt;/h1&gt;&#xA;&lt;h2 id=&#34;h2-default-styles-for-headings&#34;&gt;H2 Default styles for headings&lt;/h2&gt;&#xA;&lt;h3 id=&#34;h3-default-styles-for-headings&#34;&gt;H3 Default styles for headings&lt;/h3&gt;&#xA;&lt;h4 id=&#34;h4-default-styles-for-headings&#34;&gt;H4 Default styles for headings&lt;/h4&gt;&#xA;&lt;h5 id=&#34;h5-default-styles-for-headings&#34;&gt;H5 Default styles for headings&lt;/h5&gt;&#xA;&lt;h6 id=&#34;h6-default-styles-for-headings&#34;&gt;H6 Default styles for headings&lt;/h6&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;lists&#34;&gt;Lists&lt;/h2&gt;&#xA;&lt;h3 id=&#34;ordered-list-example&#34;&gt;Ordered list example:&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Poutine drinking vinegar bitters.&lt;/li&gt;&#xA;&lt;li&gt;Coloring book distillery fanny pack.&lt;/li&gt;&#xA;&lt;li&gt;Venmo biodiesel gentrify enamel pin meditation.&lt;/li&gt;&#xA;&lt;li&gt;Jean shorts shaman listicle pickled portland.&lt;/li&gt;&#xA;&lt;li&gt;Salvia mumblecore brunch iPhone migas.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;unordered-list-example&#34;&gt;Unordered list example:&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Bitters semiotics vice thundercats synth.&lt;/li&gt;&#xA;&lt;li&gt;Literally cred narwhal bitters wayfarers.&lt;/li&gt;&#xA;&lt;li&gt;Kale chips chartreuse paleo tbh street art marfa.&lt;/li&gt;&#xA;&lt;li&gt;Mlkshk polaroid sriracha brooklyn.&lt;/li&gt;&#xA;&lt;li&gt;Pug you probably haven&amp;rsquo;t heard of them air plant man bun.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;table&#34;&gt;Table&lt;/h2&gt;&#xA;&lt;div class=&#34;table-container&#34;&gt;&#xA;  &lt;table&gt;&#xA;    &lt;tr&gt;&lt;th&gt;Header 1&lt;/th&gt;&lt;th&gt;Header 2&lt;/th&gt;&lt;th&gt;Header 3&lt;/th&gt;&lt;th&gt;Header 4&lt;/th&gt;&lt;th&gt;Header 5&lt;/th&gt;&lt;/tr&gt;&#xA;    &lt;tr&gt;&lt;td&gt;Row:1 Cell:1&lt;/td&gt;&lt;td&gt;Row:1 Cell:2&lt;/td&gt;&lt;td&gt;Row:1 Cell:3&lt;/td&gt;&lt;td&gt;Row:1 Cell:4&lt;/td&gt;&lt;td&gt;Row:1 Cell:5&lt;/td&gt;&lt;/tr&gt;&#xA;    &lt;tr&gt;&lt;td&gt;Row:2 Cell:1&lt;/td&gt;&lt;td&gt;Row:2 Cell:2&lt;/td&gt;&lt;td&gt;Row:2 Cell:3&lt;/td&gt;&lt;td&gt;Row:2 Cell:4&lt;/td&gt;&lt;td&gt;Row:2 Cell:5&lt;/td&gt;&lt;/tr&gt;&#xA;    &lt;tr&gt;&lt;td&gt;Row:3 Cell:1&lt;/td&gt;&lt;td&gt;Row:3 Cell:2&lt;/td&gt;&lt;td&gt;Row:3 Cell:3&lt;/td&gt;&lt;td&gt;Row:3 Cell:4&lt;/td&gt;&lt;td&gt;Row:3 Cell:5&lt;/td&gt;&lt;/tr&gt;&#xA;    &lt;tr&gt;&lt;td&gt;Row:4 Cell:1&lt;/td&gt;&lt;td&gt;Row:4 Cell:2&lt;/td&gt;&lt;td&gt;Row:4 Cell:3&lt;/td&gt;&lt;td&gt;Row:4 Cell:4&lt;/td&gt;&lt;td&gt;Row:4 Cell:5&lt;/td&gt;&lt;/tr&gt;&#xA;    &lt;tr&gt;&lt;td&gt;Row:5 Cell:1&lt;/td&gt;&lt;td&gt;Row:5 Cell:2&lt;/td&gt;&lt;td&gt;Row:5 Cell:3&lt;/td&gt;&lt;td&gt;Row:5 Cell:4&lt;/td&gt;&lt;td&gt;Row:5 Cell:5&lt;/td&gt;&lt;/tr&gt;&#xA;    &lt;tr&gt;&lt;td&gt;Row:6 Cell:1&lt;/td&gt;&lt;td&gt;Row:6 Cell:2&lt;/td&gt;&lt;td&gt;Row:6 Cell:3&lt;/td&gt;&lt;td&gt;Row:6 Cell:4&lt;/td&gt;&lt;td&gt;Row:6 Cell:5&lt;/td&gt;&lt;/tr&gt;&#xA;  &lt;/table&gt;&#xA;&lt;/div&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;quotes&#34;&gt;Quotes&lt;/h2&gt;&#xA;&lt;h4 id=&#34;a-quote-looks-like-this&#34;&gt;A quote looks like this:&lt;/h4&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Design is not just what it looks like and feels like. Design is how it works.&lt;/p&gt;</description>
    </item>
    <item>
      <title>FAQ</title>
      <link>https://twcch.io/faq/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://twcch.io/faq/</guid>
      <description></description>
    </item>
    <item>
      <title>Get In Touch</title>
      <link>https://twcch.io/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://twcch.io/contact/</guid>
      <description></description>
    </item>
    <item>
      <title>Hey friends 👋 I’m 志謙</title>
      <link>https://twcch.io/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://twcch.io/about/</guid>
      <description>&lt;img src=&#34;https://avatars.githubusercontent.com/u/24428408?v=4&#34; alt=&#34;About Me&#34; width=&#34;240px&#34;&gt;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;主要學歷&#34;&gt;主要學歷&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;[2025.09 – Present] 國立成功大學 工程科學系 資訊工程與應用組 博士生&#xA;&lt;ul&gt;&#xA;&lt;li&gt;資料科學與演算法實驗室&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;工作經歷&#34;&gt;工作經歷&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;[2022.04 – 2025.06] 富邦人壽保險股份有限公司 專案襄理 (商業分析師)&#xA;&lt;ul&gt;&#xA;&lt;li&gt;專案經歷&#xA;&lt;ul&gt;&#xA;&lt;li&gt;[2023.05 – 2025.06] 理賠應用系統現代化專案 – 理賠保險金計算規則盤點與規劃&lt;/li&gt;&#xA;&lt;li&gt;[2024.08 – 2025.06] 理賠應用系統現代化專案 – 資料維護功能設計與整合&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;[2020.04 – 2022.03] 南山人壽保險股份有限公司 專員 (商業分析師)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;專業認證&#34;&gt;專業認證&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;[2025] 美國壽險管理師 (FLMI), LOMA&lt;/li&gt;&#xA;&lt;li&gt;[2024] 國際專案管理師 (PMP), PMI&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Videos</title>
      <link>https://twcch.io/videos/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://twcch.io/videos/</guid>
      <description></description>
    </item>
    <item>
      <title>專欄文章</title>
      <link>https://twcch.io/column_article/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://twcch.io/column_article/</guid>
      <description>&lt;h2 id=&#34;ithome-鐵人賽-2025&#34;&gt;iThome 鐵人賽 2025&lt;/h2&gt;&#xA;&lt;h3 id=&#34;快速掌握資料結構與演算法&#34;&gt;快速掌握資料結構與演算法&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;系列連結: &lt;a href=&#34;https://ithelp.ithome.com.tw/users/20163705/ironman/8468&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/users/20163705/ironman/8468&#34;&gt;https://ithelp.ithome.com.tw/users/20163705/ironman/8468&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;table-container&#34;&gt;&#xA;    &lt;table border=&#34;1&#34; cellspacing=&#34;0&#34; cellpadding=&#34;8&#34; style=&#34;width:100%; border-collapse: collapse;&#34;&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;th style=&#34;width:15%;&#34;&gt;天數&lt;/th&gt;&#xA;        &lt;th style=&#34;width:70%;&#34;&gt;標題&lt;/th&gt;&#xA;        &lt;th style=&#34;width:15%;&#34;&gt;連結&lt;/th&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 1&lt;/td&gt;&#xA;        &lt;td&gt;(Day 1) 介紹與準備&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10376664&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 2&lt;/td&gt;&#xA;        &lt;td&gt;(Day 2) 陣列 (Array)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10376687&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 3&lt;/td&gt;&#xA;        &lt;td&gt;(Day 3) 矩陣 (Matrix)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10376831&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 4&lt;/td&gt;&#xA;        &lt;td&gt;(Day 4) 鏈表 (Linked List)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10377037&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 5&lt;/td&gt;&#xA;        &lt;td&gt;(Day 5) 堆疊 (Stack)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10377218&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 6&lt;/td&gt;&#xA;        &lt;td&gt;(Day 6) 隊列 (Queue)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10377372&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 7&lt;/td&gt;&#xA;        &lt;td&gt;(Day 7) 二元樹 (Binary Tree)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10377601&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 8&lt;/td&gt;&#xA;        &lt;td&gt;(Day 8) 平衡樹 (Balanced Tree)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10377826&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 9&lt;/td&gt;&#xA;        &lt;td&gt;(Day 9) 其他樹 (Other Trees)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10377923&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 10&lt;/td&gt;&#xA;        &lt;td&gt;(Day 10) 圖 (Graph)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10378114&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 11&lt;/td&gt;&#xA;        &lt;td&gt;(Day 11) 演算法評估 (Algorithm Analysis)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10378395&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 12&lt;/td&gt;&#xA;        &lt;td&gt;(Day 12) 氣泡排序 (Bubble Sort)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10378627&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 13&lt;/td&gt;&#xA;        &lt;td&gt;(Day 13) 選擇排序 (Selection Sort)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10378827&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 14&lt;/td&gt;&#xA;        &lt;td&gt;(Day 14) 插入排序 (Insertion Sort)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10379362&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 15&lt;/td&gt;&#xA;        &lt;td&gt;(Day 15) 基礎排序演算法比較&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10379460&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 16&lt;/td&gt;&#xA;        &lt;td&gt;(Day 16) 二元搜尋 (Binary Search)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10379712&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 17&lt;/td&gt;&#xA;        &lt;td&gt;(Day 17) 內插搜尋 (Interpolation Search)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10379713&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 18&lt;/td&gt;&#xA;        &lt;td&gt;(Day 18) 分治法 (Divide and Conquer)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10380112&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 19&lt;/td&gt;&#xA;        &lt;td&gt;(Day 19) 動態規劃 (Dynamic Programming)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10381704&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 20&lt;/td&gt;&#xA;        &lt;td&gt;(Day 20) 貪婪演算法 (Greedy Algorithm)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10382404&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 21&lt;/td&gt;&#xA;        &lt;td&gt;(Day 21) 圖演算法 (Graph Algorithm)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10382694&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 22&lt;/td&gt;&#xA;        &lt;td&gt;(Day 22) Dijkstra 最短路徑演算法 (Dijkstra’s Algorithm)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10384113&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 23&lt;/td&gt;&#xA;        &lt;td&gt;(Day 23) Bellman-Ford 演算法&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10384671&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 24&lt;/td&gt;&#xA;        &lt;td&gt;(Day 24) Floyd-Warshall 演算法&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10384934&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 25&lt;/td&gt;&#xA;        &lt;td&gt;(Day 25) A* 搜尋演算法 (A-star Search)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10386100&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 26&lt;/td&gt;&#xA;        &lt;td&gt;(Day 26) 最小生成樹 (Minimum Spanning Tree)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10386861&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 27&lt;/td&gt;&#xA;        &lt;td&gt;(Day 27) Kruskal 演算法&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10387658&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 28&lt;/td&gt;&#xA;        &lt;td&gt;(Day 28) Prim 演算法&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10388160&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 29&lt;/td&gt;&#xA;        &lt;td&gt;(Day 29) 最小生成樹的實務應用 (Applications of MST)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10388748&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 30&lt;/td&gt;&#xA;        &lt;td&gt;(Day 30) 系列結尾&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10389852&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;/table&gt;&#xA;&lt;/div&gt;&#xA;&lt;h3 id=&#34;30-天入門常見的機器學習演算法&#34;&gt;30 天入門常見的機器學習演算法&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;系列連結: &lt;a href=&#34;https://ithelp.ithome.com.tw/users/20163705/ironman/8136&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/users/20163705/ironman/8136&#34;&gt;https://ithelp.ithome.com.tw/users/20163705/ironman/8136&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;table-container&#34;&gt;&#xA;    &lt;table border=&#34;1&#34; cellspacing=&#34;0&#34; cellpadding=&#34;8&#34; style=&#34;width:100%; border-collapse: collapse;&#34;&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;th style=&#34;width:15%;&#34;&gt;天數&lt;/th&gt;&#xA;        &lt;th style=&#34;width:70%;&#34;&gt;標題&lt;/th&gt;&#xA;        &lt;th style=&#34;width:15%;&#34;&gt;連結&lt;/th&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 1&lt;/td&gt;&#xA;        &lt;td&gt;(Day 1) 介紹與準備&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10373216&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 2&lt;/td&gt;&#xA;        &lt;td&gt;(Day 2) 線性迴歸 (Linear Regression)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10373217&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 3&lt;/td&gt;&#xA;        &lt;td&gt;(Day 3) 多項式迴歸 (Polynomial Regression)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10373364&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 4&lt;/td&gt;&#xA;        &lt;td&gt;(Day 4) 正規化迴歸 (Regularization Regression)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10373418&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 5&lt;/td&gt;&#xA;        &lt;td&gt;(Day 5) 邏輯迴歸 (Logistic Regression)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10373499&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 6&lt;/td&gt;&#xA;        &lt;td&gt;(Day 6) 邏輯迴歸 (多項式 + 正規化)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10373570&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 7&lt;/td&gt;&#xA;        &lt;td&gt;(Day 7) 回顧迴歸：從線性邏輯到學習本質&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10373643&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 8&lt;/td&gt;&#xA;        &lt;td&gt;(Day 8) K-近鄰 (K-Nearest Neighbors)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10373716&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 9&lt;/td&gt;&#xA;        &lt;td&gt;(Day 9) 樸素貝氏分類器 (Naive Bayes Classifier)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10373815&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 10&lt;/td&gt;&#xA;        &lt;td&gt;(Day 10) 支援向量機 (Support Vector Machine)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10373865&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 11&lt;/td&gt;&#xA;        &lt;td&gt;(Day 11) 二元分類任務驗證指標&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10373961&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 12&lt;/td&gt;&#xA;        &lt;td&gt;(Day 12) 多元分類任務驗證指標&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10374043&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 13&lt;/td&gt;&#xA;        &lt;td&gt;(Day 13) 迴歸任務驗證指標&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10374148&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 14&lt;/td&gt;&#xA;        &lt;td&gt;(Day 14) 決策樹 (Decision Tree)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10374306&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 15&lt;/td&gt;&#xA;        &lt;td&gt;(Day 15) 隨機森林 (Random Forest)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10374430&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 16&lt;/td&gt;&#xA;        &lt;td&gt;(Day 16) K-Means&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10374527&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 17&lt;/td&gt;&#xA;        &lt;td&gt;(Day 17) 淺談深度學習 (Deep Learning)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10374688&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 18&lt;/td&gt;&#xA;        &lt;td&gt;(Day 18) 全連接神經網絡 (Fully Connected Neural Network)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10374777&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 19&lt;/td&gt;&#xA;        &lt;td&gt;(Day 19) 神經元 (Neuron)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10374923&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 20&lt;/td&gt;&#xA;        &lt;td&gt;(Day 20) 激活函數 (Activation Function)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10375012&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 21&lt;/td&gt;&#xA;        &lt;td&gt;(Day 21) 卷積神經網絡 (Convolutional Neural Network)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10375172&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 22&lt;/td&gt;&#xA;        &lt;td&gt;(Day 22) 深度學習中的正規化與正則化 (Regularization in Deep Learning)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10375314&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 23&lt;/td&gt;&#xA;        &lt;td&gt;(Day 23) 深度學習中的優化方法 (Optimization in Deep Learning)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10375450&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 24&lt;/td&gt;&#xA;        &lt;td&gt;(Day 24) Adam 優化器 (Adaptive Moment Estimation)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10375592&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 25&lt;/td&gt;&#xA;        &lt;td&gt;(Day 25) 循環神經網路 (Recurrent Neural Network)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10375690&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 26&lt;/td&gt;&#xA;        &lt;td&gt;(Day 26) 長短期記憶 (Long Short-Term Memory)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10375865&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 27&lt;/td&gt;&#xA;        &lt;td&gt;(Day 27) 閘控循環單元 (Gated Recurrent Unit)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10376008&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 28&lt;/td&gt;&#xA;        &lt;td&gt;(Day 28) Seq2Seq (Encoder Decoder with RNN, LSTM, GRU)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10376192&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 29&lt;/td&gt;&#xA;        &lt;td&gt;(Day 29) 注意力機制 (Attention Mechanism)&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10376304&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;Day 30&lt;/td&gt;&#xA;        &lt;td&gt;(Day 30) 系列結尾&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/articles/10376490&#34; target=&#34;_blank&#34; ref=&#34;nofollow&#34;&gt;iThome&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;/table&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>服務項目</title>
      <link>https://twcch.io/services/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://twcch.io/services/</guid>
      <description></description>
    </item>
  </channel>
</rss>
