<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>志謙&#39;s Blog</title>
    <link>http://twcch.io/</link>
    <description>Recent content on 志謙&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 07 Sep 2025 00:00:00 +0800</lastBuildDate>
    <atom:link href="http://twcch.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>(Day 9) 其他樹 (Other Trees)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/%E5%BF%AB%E9%80%9F%E6%8E%8C%E6%8F%A1%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E8%88%87%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_2_9/</link>
      <pubDate>Sun, 07 Sep 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/%E5%BF%AB%E9%80%9F%E6%8E%8C%E6%8F%A1%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E8%88%87%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_2_9/</guid>
      <description>&lt;p&gt;在前面兩天，粗淺的介紹了 Binary Tree 與 Balanced Tree，今天更粗淺的介紹一下其他樹，因為本系列只是要做一個拋磚引玉的動作，如果讀者對於資料結構有興趣，建議可以買書來研讀。&lt;/p&gt;&#xA;&lt;p&gt;樹的資料結構他的應用場景非常廣，比如機器學習的決策樹、極限梯度提升樹，或者是資料庫、檔案系統等應用場景，所以樹的資料結構不是僅僅的理論而已，讀者也許會疑惑說，為什麼好像介紹到樹就沒什麼程式碼，向機器學習的決策樹，它是一種機器學習的演算法，它使用的樹的資料結構去設計，所以光這個演算法要講清楚，就會花很久，也不是本系列的範圍，如果要深入的學樹模型，需要讀者自行找資源學習。&lt;/p&gt;&#xA;&lt;h2 id=&#34;各種樹&#34;&gt;各種樹&lt;/h2&gt;&#xA;&lt;p&gt;接下來，淺淺的介紹一下其他樹還有什麼&lt;/p&gt;&#xA;&lt;h3 id=&#34;b-tree&#34;&gt;B-Tree&lt;/h3&gt;&#xA;&lt;p&gt;B-Tree 是一種多路搜尋樹 (multi-way search tree)，與二元搜尋樹不同的是，它的每個節點可以擁有多於兩個子節點。&lt;/p&gt;&#xA;&lt;p&gt;特點:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;節點可以存放多個 key。&lt;/li&gt;&#xA;&lt;li&gt;每個節點的子樹數量 = key 數量 + 1。&lt;/li&gt;&#xA;&lt;li&gt;適合用在「磁碟存取」的場景，因為可以減少磁碟 I/O 次數。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;B-Tree 是資料庫索引的基礎，例如 MySQL 就使用 B-Tree 來實作索引。&lt;/p&gt;&#xA;&lt;h3 id=&#34;b-tree-1&#34;&gt;B+ Tree&lt;/h3&gt;&#xA;&lt;p&gt;B+ Tree 是 B-Tree 的延伸，改進點在於:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;所有資料都存放在葉節點，非葉節點只用來導航。&lt;/li&gt;&#xA;&lt;li&gt;葉節點之間使用 &lt;strong&gt;鏈結串列&lt;/strong&gt; 串接，支援範圍查詢。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;這讓 B+ Tree 在查詢時更有效率，特別是需要「區間搜尋」的情境。&lt;/p&gt;&#xA;&lt;h3 id=&#34;紅黑樹-red-black-tree&#34;&gt;紅黑樹 (Red-Black Tree)&lt;/h3&gt;&#xA;&lt;p&gt;紅黑樹是一種自平衡二元搜尋樹 (self-balancing BST)**，常用於準程式庫的實作，例如:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Java 的 &lt;code&gt;TreeMap&lt;/code&gt;、&lt;code&gt;TreeSet&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;紅黑樹的規則:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;節點要嘛是紅色，要嘛是黑色。&lt;/li&gt;&#xA;&lt;li&gt;根節點一定是黑色。&lt;/li&gt;&#xA;&lt;li&gt;紅節點的子節點必須是黑色 (不能連續兩個紅色)。&lt;/li&gt;&#xA;&lt;li&gt;從根到每個葉節點的路徑，黑色節點數必須相同。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;這些限制保證了樹的高度維持在 $O(\log n)$，因此搜尋、插入、刪除都能保證在 $O(\log n)$ 完成。&lt;/p&gt;&#xA;&lt;h3 id=&#34;trie-樹-prefix-tree&#34;&gt;Trie 樹 (Prefix Tree)&lt;/h3&gt;&#xA;&lt;p&gt;Trie，又叫字典樹，專門用來處理字串集合的問題。&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 8) 平衡樹 (Balanced Tree)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/%E5%BF%AB%E9%80%9F%E6%8E%8C%E6%8F%A1%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E8%88%87%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_2_8/</link>
      <pubDate>Sat, 06 Sep 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/%E5%BF%AB%E9%80%9F%E6%8E%8C%E6%8F%A1%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E8%88%87%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_2_8/</guid>
      <description>&lt;p&gt;Balanced Tree 是一種特殊的二元樹結構，旨在保持樹的高度盡可能低，以提高操作效率。常見的平衡樹包括 AVL 樹、紅黑樹和 B 樹等。以下是關於平衡樹的詳細介紹。&lt;/p&gt;&#xA;&lt;h2 id=&#34;基本概念&#34;&gt;基本概念&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;二元樹: 是一種樹形數據結構，其中每個節點最多有兩個子節點，分別稱為左子節點和右子節點。&lt;/li&gt;&#xA;&lt;li&gt;平衡樹: 是一種二元樹，其特點是任何節點的兩個子樹的高度差不超過一個常數 (通常是 1)。這樣的結構確保了樹的高度保持在 $O(\log n)$，從而使得查找、插入和刪除操作的時間複雜度都能保持在 $O(\log n)$。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;平衡樹類型&#34;&gt;平衡樹類型&lt;/h2&gt;&#xA;&lt;h3 id=&#34;avl-樹&#34;&gt;AVL 樹&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;定義: AVL樹是一種自平衡二元搜索樹，任何節點的兩個子樹的高度差不超過1。&lt;/li&gt;&#xA;&lt;li&gt;操作:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;插入: 插入後可能會破壞平衡，需要通過旋轉來恢復。&lt;/li&gt;&#xA;&lt;li&gt;刪除: 刪除後也可能需要旋轉來保持平衡。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;紅黑樹&#34;&gt;紅黑樹&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;定義: 紅黑樹是一種自平衡二元搜索樹，每個節點都有一個顏色 (紅或黑)，並遵循以下規則:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;節點是紅色或黑色。&lt;/li&gt;&#xA;&lt;li&gt;根節點是黑色。&lt;/li&gt;&#xA;&lt;li&gt;每個葉子節點 (NIL 或空節點) 是黑色。&lt;/li&gt;&#xA;&lt;li&gt;如果一個節點是紅色，則其兩個子節點都是黑色。&lt;/li&gt;&#xA;&lt;li&gt;從任何節點到其每個葉子節點的所有路徑都包含相同數量的黑色節點。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;操作:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;插入: 插入後可能需要重新著色和旋轉來保持平衡。&lt;/li&gt;&#xA;&lt;li&gt;刪除: 刪除後也可能需要重新著色和旋轉。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;b-樹&#34;&gt;B 樹&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;定義: B 樹是一種自平衡樹數據結構，適合用於存儲系統中需要大量讀寫操作的情況。B 樹的每個節點可以有多個子節點。&lt;/li&gt;&#xA;&lt;li&gt;特點:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;節點可以包含多個鍵和子節點。&lt;/li&gt;&#xA;&lt;li&gt;所有葉子節點位於同一層。&lt;/li&gt;&#xA;&lt;li&gt;B 樹的高度較低，適合磁盤存取。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;應用&#34;&gt;應用&lt;/h2&gt;&#xA;&lt;p&gt;平衡樹廣泛應用於需要快速查找、插入和刪除操作的場景，如數據庫索引、文件系統和內存管理等。&lt;/p&gt;&#xA;&lt;h2 id=&#34;優缺點&#34;&gt;優缺點&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;優點&#xA;&lt;ul&gt;&#xA;&lt;li&gt;高效的查找、插入和刪除操作。&lt;/li&gt;&#xA;&lt;li&gt;保持樹的高度低，從而提高操作效率。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;缺點&#xA;&lt;ul&gt;&#xA;&lt;li&gt;實現較為複雜。&lt;/li&gt;&#xA;&lt;li&gt;需要額外的旋轉和重新著色操作來保持平衡。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;結論&#34;&gt;結論&lt;/h2&gt;&#xA;&lt;p&gt;平衡樹是一種強大的數據結構，能夠在多種應用中提供高效的操作性能。理解不同類型的平衡樹及其操作原理，對於設計高效的算法和系統至關重要。&lt;/p&gt;&#xA;&lt;h2 id=&#34;備註&#34;&gt;備註&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;同步發表於 &lt;a href=&#34;https://ithelp.ithome.com.tw/users/20163705/ironman/8468&#34;&gt;iThome 鐵人賽 2025 - 快速掌握資料結構與演算法&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>(Day 7) 二元樹 (Binary Tree)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/%E5%BF%AB%E9%80%9F%E6%8E%8C%E6%8F%A1%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E8%88%87%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_2_7/</link>
      <pubDate>Fri, 05 Sep 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/%E5%BF%AB%E9%80%9F%E6%8E%8C%E6%8F%A1%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E8%88%87%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_2_7/</guid>
      <description>&lt;p&gt;前面幾天所介紹的資料結構就是線性的資料結構，今天開始所介紹的樹資料節構是屬於非線性資料結構，也非常的重要。&lt;/p&gt;&#xA;&lt;h2 id=&#34;基本定義&#34;&gt;基本定義&lt;/h2&gt;&#xA;&lt;p&gt;在進入 Binary Tree 之前，先來介紹一下基本的組成部分，可以搭配著下圖看:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Root: 樹的起始點 (e.g. 2)&lt;/li&gt;&#xA;&lt;li&gt;Internal: 有子節點的節點 (e.g. 7, 5, 6, 9)&lt;/li&gt;&#xA;&lt;li&gt;Leaf: 沒有子節點的節點 (e.g. 2, 5, 11, 4)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/twcch/drive/raw/main/images/Image_2025-09-04_16-42-59.png&#34; alt=&#34;Image_2025-09-04_16-42-59.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Binary Tree 就是一個由有限節點所組成的集合，或由一個 Root 及左右兩個子樹所組成。簡單來說，Binary Tree 最多只能有兩個子節點 (也可以是一個)，Binary Tree 還可以再細分:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Fully Binary Tree&lt;/li&gt;&#xA;&lt;li&gt;Complete Binary Tree&lt;/li&gt;&#xA;&lt;li&gt;Skewed Binary Tree&lt;/li&gt;&#xA;&lt;li&gt;Strictly Binary Tree&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;這邊就先點到為止，不一一的詳細介紹。&lt;/p&gt;&#xA;&lt;h2 id=&#34;資料儲存方式&#34;&gt;資料儲存方式&lt;/h2&gt;&#xA;&lt;p&gt;Binary Tree 有很多種的儲存方式，比較常見的會是 Array 與 Linked List 的儲存方式，本篇就會分別介紹這兩種儲存方式。&lt;/p&gt;&#xA;&lt;h3 id=&#34;array-表示法&#34;&gt;Array 表示法&lt;/h3&gt;&#xA;&lt;p&gt;就直接用上一張圖的部分來說明，先對照一下，由上至下、由左至右的放入 Array。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A[1] = 2&lt;/li&gt;&#xA;&lt;li&gt;A[2] = 7, A[3] = 5&lt;/li&gt;&#xA;&lt;li&gt;A[4] = 2, A[5] = 6, A[6] = null, A[7] = 9&lt;/li&gt;&#xA;&lt;li&gt;A[8] = null, A[9] = null, A[10] = 5, A[11] = 11, A[12] = 4, A[13] = null&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/twcch/drive/raw/main/images/Image_2025-09-04_16-42-59.png&#34; alt=&#34;Image_2025-09-04_16-42-59.png&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 6) 隊列 (Queue)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/%E5%BF%AB%E9%80%9F%E6%8E%8C%E6%8F%A1%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E8%88%87%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_2_6/</link>
      <pubDate>Thu, 04 Sep 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/%E5%BF%AB%E9%80%9F%E6%8E%8C%E6%8F%A1%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E8%88%87%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_2_6/</guid>
      <description>&lt;p&gt;Queue (佇列) 與 Stack 一樣，是一種線性資料結構，但它遵循的是先進先出 (First-In-First-Out; FIFO) 的規則。你可以把 Queue 想像成排隊買票: 最早排隊的人會最先買到票並離開，而新加入的人只能站在隊伍最後。&lt;/p&gt;&#xA;&lt;p&gt;簡單來說，Queue 的操作只允許在「尾端」加入元素，在「前端」移除元素。&lt;/p&gt;&#xA;&lt;h2 id=&#34;queue-的基本操作&#34;&gt;Queue 的基本操作&lt;/h2&gt;&#xA;&lt;p&gt;Queue 與 Stack 的差異就在於操作的方向：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;enqueue: 將元素放到 Queue 尾端&lt;/li&gt;&#xA;&lt;li&gt;dequeue: 將 Queue 前端的元素移除並回傳&lt;/li&gt;&#xA;&lt;li&gt;peek/front: 查看 Queue 前端的元素，但不移除&lt;/li&gt;&#xA;&lt;li&gt;is_empty: 檢查 Queue 是否為空&lt;/li&gt;&#xA;&lt;li&gt;size: 回傳 Queue 的大小&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;自己建立一個-queue&#34;&gt;自己建立一個 Queue&lt;/h2&gt;&#xA;&lt;p&gt;其實 Queue 跟 Stack 差不多，操作都很簡單，直接使用 Python 來自定義一個 Queue 的資料結構，來進行演示。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Create a Queue class&lt;/p&gt;&#xA;&lt;p&gt;和 Stack 一樣，先建立建構子與迭代器，使用 Python 的 list 模擬：&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Queue&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__iter__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;k&#34;&gt;yield&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Create an enqueue() method&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 5) 堆疊 (Stack)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/%E5%BF%AB%E9%80%9F%E6%8E%8C%E6%8F%A1%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E8%88%87%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_2_5/</link>
      <pubDate>Wed, 03 Sep 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/%E5%BF%AB%E9%80%9F%E6%8E%8C%E6%8F%A1%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E8%88%87%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_2_5/</guid>
      <description>&lt;p&gt;Stack (堆疊) 是一種受限的線性資料結構，遵循先進後出 (Last-In-First-Out; LIFO) 的資料結構。你可想像有一疊盤子，最後放上去的盤子會最先被拿走，所以 Stack 只允許在「頂端」進行操作，簡單來說就是你不能看或是取非最上層的元素。&lt;/p&gt;&#xA;&lt;h2 id=&#34;stack-的基本操作&#34;&gt;Stack 的基本操作&lt;/h2&gt;&#xA;&lt;p&gt;Stack 的操作相較 Linked List 簡單很多，因為他只能對頂端進行操作，常見的操作如下:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;push: 將元素放到 Stack 頂端&lt;/li&gt;&#xA;&lt;li&gt;pop: 將 Stack 頂端的元素移除並回傳 (取走)&lt;/li&gt;&#xA;&lt;li&gt;peek/top: 查看堆疊頂端的元素，但不移除&lt;/li&gt;&#xA;&lt;li&gt;is_empty: 檢查堆疊是否為空&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;自己建立一個-stack&#34;&gt;自己建立一個 Stack&lt;/h2&gt;&#xA;&lt;p&gt;直接使用 Python 來自定義一個 Stack 的資料結構&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Create a Stack class&lt;/p&gt;&#xA;&lt;p&gt;起手式跟昨天一樣，建立建構子與實作 iter，透過 Python 的 list 來模擬。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Stack&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__iter__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;reversed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;k&#34;&gt;yield&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Create a push() method&lt;/p&gt;&#xA;&lt;p&gt;Stack 添加元素無法像 Linked List 有那麼多的操作，他一律只能放在最上面，可以想像一下，其實就是把元素加在最後面，再把 list 轉 90 度。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Stack&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__init__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;fm&#34;&gt;__iter__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;item&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;reversed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;k&#34;&gt;yield&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;push&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#x9;    &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;item&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Create a pop() method&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 4) 鏈表 (Linked List)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/%E5%BF%AB%E9%80%9F%E6%8E%8C%E6%8F%A1%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E8%88%87%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_2_4/</link>
      <pubDate>Tue, 02 Sep 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/%E5%BF%AB%E9%80%9F%E6%8E%8C%E6%8F%A1%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E8%88%87%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_2_4/</guid>
      <description>&lt;p&gt;Linked List (鏈表) 是一種常見的資料結構，用來儲存一系列的元素。與陣列 (Array) 不同，Linked List 的元素稱為節點 (Node) 在記憶體中不必是連續的。每個節點除了儲存資料外，還會儲存一個指向下一個節點的參考 (指標)。&lt;/p&gt;&#xA;&lt;p&gt;但是很不巧的 Python 並沒有像 Java 有支援 Linked List，雖然本系列是以 Python 為主，但是也不會直接使用高階 API 來實作，因為這樣就沒有意義了，所以會使用 Python 來自己建立類別來實現，甚至之後的有些資料結構 Python 都沒有，我也會用 Python 來自定義出類別。&lt;/p&gt;&#xA;&lt;h2 id=&#34;為什麼要用-linked-list&#34;&gt;為什麼要用 Linked List?&lt;/h2&gt;&#xA;&lt;p&gt;相較 Array，Linked List 可以隨時增加或刪除元素，不需要事先宣告大小，而且在在已知位置插入或刪除元素時，只需改變指標，不需搬移其他元素，也就是說如果程式需要頻繁的新增與刪除，Linked List 表現會更為優秀；但是 Linked List 不論是哪種型態的，最多只會儲存前後 Node 的位址，所以當需要查詢的時候，就必須遍歷整個 Linked List，所以在這部分就不及 Array 的效率。&lt;/p&gt;&#xA;&lt;h2 id=&#34;linked-list-的種類&#34;&gt;Linked List 的種類&lt;/h2&gt;&#xA;&lt;p&gt;常見的 Linked List 有以下這幾種型態:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Singly Linked List (單向鏈表):  每個 Node 只指向下一個節點。&lt;/li&gt;&#xA;&lt;li&gt;Doubly Linked List (雙向鏈表): 每個 Node 同時指向前一個和下一個節點。&lt;/li&gt;&#xA;&lt;li&gt;Circular Linked List (循環鏈表): 最後一個 Node 指向第一個節點，形成一個環。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;node-的結構&#34;&gt;Node 的結構&lt;/h3&gt;&#xA;&lt;p&gt;看完 Linked List 的種類，其實會發現這些的差異都在 Node，有的 Node 只指向下一個節點，有 Node 同時指向前一個和下一個節點，接下來我們就用 Python 來演式 Node 的結構:&lt;/p&gt;</description>
    </item>
    <item>
      <title>讀書無用論，真的無用嗎?</title>
      <link>http://twcch.io/posts/2025/articles_25090201/</link>
      <pubDate>Tue, 02 Sep 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/2025/articles_25090201/</guid>
      <description>&lt;p&gt;前陣子在一個群組裡，我看到一個案例。一位年僅 19 歲的年輕人，沒有繼續升學，而是直接進入一家小型乙方軟體公司工作。他對此洋洋自得，甚至把「不讀書」當成一種優越感，強調「讀書無用」，彷彿他提早進入職場就是成功的證明。&lt;/p&gt;&#xA;&lt;p&gt;我有花時間看一下他分享的 project，很明顯並不是所謂的「天才作品」，甚至只能算是初階學習者的水平。但他卻以此為榮，並進一步推廣讀書無用論。這讓我不禁反思: 他真正的問題，不在於選擇不讀書，而在於被自己的有限眼界所困。&lt;/p&gt;&#xA;&lt;h2 id=&#34;讀書不是唯一但沒有讀書會少掉很多東西&#34;&gt;讀書不是唯一，但沒有讀書會少掉很多東西&lt;/h2&gt;&#xA;&lt;p&gt;我們必須承認，學校教育不是通往成功的唯一途徑。許多傑出的人才也選擇了不同的路徑。然而，不代表讀書就沒有價值。讀書帶來的，其實是結構化的思維、批判能力、知識廣度與深度。這些東西，未必能在一間小公司裡快速累積。反而，若只停留在低門檻的任務，眼界與能力會被環境綁死。&lt;/p&gt;&#xA;&lt;h2 id=&#34;眼界的限制會製造出錯誤的自信&#34;&gt;眼界的限制，會製造出錯誤的自信&lt;/h2&gt;&#xA;&lt;p&gt;我認為這位年輕人會覺得「讀書無用」，是因為他的視野只停留在眼前的工作場域。他所在的公司或許把簡單的專案包裝成「實戰」，讓他誤以為自己已經站上了高地。但一旦跳出這個小環境，他就會發現自己其實什麼都不是。&lt;/p&gt;&#xA;&lt;p&gt;這就是所謂的「井底之蛙效應」: 當你沒看過更廣闊的世界，就會以為眼前就是全部。&lt;/p&gt;&#xA;&lt;h2 id=&#34;真正該自豪的是學習的韌性與格局&#34;&gt;真正該自豪的，是學習的韌性與格局&lt;/h2&gt;&#xA;&lt;p&gt;19 歲選擇進入職場沒有錯，但把它當成「勝利宣言」卻是幼稚的。&lt;/p&gt;&#xA;&lt;p&gt;真正值得驕傲的，不是早一點領薪水，而是能持續提升自己的能力，無論透過學校、工作或自學。尤其在科技領域，學習的速度與深度往往決定了未來的格局。&lt;/p&gt;&#xA;&lt;p&gt;一個人若因短期的工作成就而看輕讀書，長遠來看，他可能會成為被取代的一群人，而不是推動產業的人。&lt;/p&gt;&#xA;&lt;h2 id=&#34;結語&#34;&gt;結語&lt;/h2&gt;&#xA;&lt;p&gt;「讀書無用論」往往不是知識真的無用，而是說出這句話的人，因為眼界不足，誤以為無用。讀書不保證成功，但它能拓展思維邊界，避免我們陷入自以為是的舒適圈。因此，問題不在於他選擇 19 歲進入小公司，而在於他拒絕承認自己還有更大的學習空間。這種自滿，才是真正的危險。&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 3) 矩陣 (Matrix)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/%E5%BF%AB%E9%80%9F%E6%8E%8C%E6%8F%A1%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E8%88%87%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_2_3/</link>
      <pubDate>Mon, 01 Sep 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/%E5%BF%AB%E9%80%9F%E6%8E%8C%E6%8F%A1%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E8%88%87%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_2_3/</guid>
      <description>&lt;p&gt;我不知道大家看到這天會不會驚訝一下，不是應該接續 List 家族這是什麼? Matrix 就是 Array 只是我單獨抽出來說明，如果你沒有在學習或處理資料科學相關的，應該不會使用到 Matrix，但是我認為這是一個蠻常被忽略的部分，也就花一點篇幅來介紹它。&lt;/p&gt;&#xA;&lt;p&gt;Matrix 是由數字、符號或表達式排列成的長方形陣列。從數學的角度來看，對於 m*n 矩陣的形式，可以描述一個電腦中 A(m,n) 二維陣列。&lt;/p&gt;&#xA;&lt;h2 id=&#34;矩陣的表示方式&#34;&gt;矩陣的表示方式&lt;/h2&gt;&#xA;&lt;p&gt;一個 $m$ 行 $n$ 列的矩陣通常寫作:&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;A = \begin{pmatrix}&#xA;a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n} \&#xA;a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n} \&#xA;\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \&#xA;a_{m1} &amp;amp; a_{m2} &amp;amp; \cdots &amp;amp; a_{mn}&#xA;\end{pmatrix}&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;其中 $a_{ij}$ 表示第 $i$ 行第 $j$ 列的元素。&lt;/p&gt;&#xA;&lt;h2 id=&#34;常見矩陣種類&#34;&gt;常見矩陣種類&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;名稱&lt;/th&gt;&#xA;          &lt;th&gt;定義說明&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;行矩陣&lt;/td&gt;&#xA;          &lt;td&gt;只有一行的矩陣 ($1 \times n$)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;列矩陣&lt;/td&gt;&#xA;          &lt;td&gt;只有一列的矩陣 ($m \times 1$)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;方陣&lt;/td&gt;&#xA;          &lt;td&gt;行數與列數相同的矩陣 ($n \times n$)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;零矩陣&lt;/td&gt;&#xA;          &lt;td&gt;所有元素皆為 0 的矩陣&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;單位矩陣&lt;/td&gt;&#xA;          &lt;td&gt;對角線為 1，其餘為 0 的方陣&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2 id=&#34;矩陣的基本運算&#34;&gt;矩陣的基本運算&lt;/h2&gt;&#xA;&lt;p&gt;如果你使用資料科學常見的函式庫 (e.g. Numpy)，對於 Matrix 的支援非常的強大，常見的基本運算可能調用一個屬性或方法就能直接處理完成，但是本系列是著重底層知識的理解，所以不會使用到這些高階 API，但是在實務上一定是直接使用這些高階 API。&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 2) 陣列 (Array)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/%E5%BF%AB%E9%80%9F%E6%8E%8C%E6%8F%A1%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E8%88%87%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_2_2/</link>
      <pubDate>Sun, 31 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/%E5%BF%AB%E9%80%9F%E6%8E%8C%E6%8F%A1%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E8%88%87%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_2_2/</guid>
      <description>&lt;p&gt;Array 是一種 Static Data Structure 或稱為 Dense List，它是一種將有序串列的資料結構使用 Contiguous Allocation 來儲存，意味著儲存的元素必須是相同類型，且靜態資料結構的記憶體配置是在編譯時，就必須配置給相關的變數，因此在創建時必須先宣告空間大小。&lt;/p&gt;&#xA;&lt;h2 id=&#34;常見的-array-類型-n-dimensional-array&#34;&gt;常見的 Array 類型 (N-Dimensional Array)&lt;/h2&gt;&#xA;&lt;p&gt;Array 應該是有無限多維，基本上到了 3 維除了圖片外就很少看到，4 維含以上我沒見過，也有可能是我才疏學淺，所以這裡就代表性的介紹 1 ~ 3 維的 Array&lt;/p&gt;&#xA;&lt;h3 id=&#34;one-dimensional-array&#34;&gt;One-Dimensional Array&lt;/h3&gt;&#xA;&lt;p&gt;One-Dimensional Array 是一個在記憶體中連續配置 (contiguously allocated) 的元素序列，所有元素型態一致、大小相同，可透過固定大小的偏移量 element_size 在 O(1) 時間計算任意元素的位址。簡單來說，只要給定起始的位置跟每個空間的大小，就能夠直接算出任意元素的位址，位址公式如下:&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;\text{LOC}(A[i]) = \text{Base}(A) + (i - L) \times w&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;其中:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;$\text{LOC}(A[i])$: 表示陣列中第 i 個元素的記憶體位址。&lt;/li&gt;&#xA;&lt;li&gt;$\text{Base}(A)$: 陣列的起始位址。&lt;/li&gt;&#xA;&lt;li&gt;$i$: 要找的索引位置。&lt;/li&gt;&#xA;&lt;li&gt;$L$: 陣列的下標起點 (lower bound)，在大多數語言 (Python, Java, C++)，$L = 0$。&lt;/li&gt;&#xA;&lt;li&gt;$(i - L)$: 表示從起點偏移了幾個元素。&lt;/li&gt;&#xA;&lt;li&gt;$w$: 每個元素的大小 (word size)，以位元組 (bytes) 為單位。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;接下來直接帶入實例計算，假設 $\text{Base}(A) = 1000$、$L = 0$、陣列 ints[5]，型別是 int (4 bytes)，求 A[3] 的位址:&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 1) 介紹與準備</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/%E5%BF%AB%E9%80%9F%E6%8E%8C%E6%8F%A1%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E8%88%87%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_2_1/</link>
      <pubDate>Sat, 30 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/%E5%BF%AB%E9%80%9F%E6%8E%8C%E6%8F%A1%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E8%88%87%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_2_1/</guid>
      <description>&lt;p&gt;我遇過很多學習程式語言的人，都一直學框架或是 API 怎麼用，都不是很注重底層的知識，我認為一棟樓要蓋多高取決於地基打得多深，因為框架與 API 會變，但時間複雜度、記憶體模型、資料結構設計是不會變的。&lt;/p&gt;&#xA;&lt;h2 id=&#34;為什麼要學資料結構與演算法&#34;&gt;為什麼要學資料結構與演算法?&lt;/h2&gt;&#xA;&lt;p&gt;資料結構與演算法是程式設計的基礎，它們除了能幫助你寫出更有效率的程式，也是很多公司技術面試中必考的內容。其實我個人認為這也是本科與分本科的分水嶺，熟練的掌握這部分，能夠讓你跟那些轉職的工程師拉開距離，脫穎而出。&lt;/p&gt;&#xA;&lt;h2 id=&#34;系列規劃說明&#34;&gt;系列規劃說明&lt;/h2&gt;&#xA;&lt;p&gt;本系列將會依照以下方向進行介紹:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;資料結構 (Data structure)&#xA;&lt;ul&gt;&#xA;&lt;li&gt;陣列 (Array)&lt;/li&gt;&#xA;&lt;li&gt;鏈表 (Linked list)&lt;/li&gt;&#xA;&lt;li&gt;堆疊 (Stack)&lt;/li&gt;&#xA;&lt;li&gt;佇列 (Queue)&lt;/li&gt;&#xA;&lt;li&gt;樹 (Trees)&lt;/li&gt;&#xA;&lt;li&gt;圖 (Graphs)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;演算法 (Algorithms)&#xA;&lt;ul&gt;&#xA;&lt;li&gt;演算法分析 (Algorithm analysis)&lt;/li&gt;&#xA;&lt;li&gt;圖演算法 (Graph algorithms)&lt;/li&gt;&#xA;&lt;li&gt;貪婪演算法 (Greedy algorithms)&lt;/li&gt;&#xA;&lt;li&gt;分治法 (Divide and conquer)&lt;/li&gt;&#xA;&lt;li&gt;動態規劃 (Dynamic programming)&lt;/li&gt;&#xA;&lt;li&gt;網路流 (Network flow)&lt;/li&gt;&#xA;&lt;li&gt;超越多項式運行時間的演算法 (Beyond polynomial running time)&lt;/li&gt;&#xA;&lt;li&gt;線性規劃 (Linear programming)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;本系列的重心會放在演算法的部分，如果有剩餘的篇幅會補充排序或是搜尋的演算法；我會盡量會在每個知識點找個 1 ~ 2 題的 Leetcode 來實作。&lt;/p&gt;&#xA;&lt;h2 id=&#34;技術範圍與預期對象&#34;&gt;技術範圍與預期對象&lt;/h2&gt;&#xA;&lt;p&gt;本系列會以 Python 為範例，但是其實你也不一定需要會 Python，理論上只要有理解，就應該要能夠使用你自己熟悉的語言寫出來，所以本系列只預設讀者至少具備一門程式語言 (Python, Java, C++, JavaScript &amp;hellip;) 的基礎即可。&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 30) 系列結尾</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_30/</link>
      <pubDate>Sat, 30 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_30/</guid>
      <description>&lt;p&gt;終於來到這個系列的最後一天。老實說，如果要我替這 30 天打個分數，我大概只會給自己一個 勉強及格。原因很簡單: 這個系列從一開始就有宏大的規劃與期待，但在實際執行的過程中，遭遇了不少現實挑戰，也暴露了自己在知識深度、寫作規劃與時間管理上的不足。&lt;/p&gt;&#xA;&lt;p&gt;在這 30 天裡，生活與學業中不斷插入突發事件，有些日子真的很忙，甚至差點「爛尾」。雖然最後還是撐到了第 30 天，但整體回顧下來，完成度與原本設想的「扎實覆蓋經典機器學習到深度學習主流架構」之間，仍有不小落差。&lt;/p&gt;&#xA;&lt;h2 id=&#34;檢討與反思&#34;&gt;檢討與反思&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;主題跨度過大&#xA;&lt;ul&gt;&#xA;&lt;li&gt;原本規劃是從傳統 ML → 深度學習 → 部分應用架構，打造一條完整脈絡。&lt;/li&gt;&#xA;&lt;li&gt;但實際執行下來，我對部分主題的熟悉度不足，寫出來的內容有時深淺失衡，顯得不上不下。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;篇幅與節奏控制不足&#xA;&lt;ul&gt;&#xA;&lt;li&gt;有些章節內容太過精簡，失去深度；有些章節則過於理論化，少了實作支撐。&lt;/li&gt;&#xA;&lt;li&gt;理想上應該是「理論 + 實作 + 應用案例」三位一體，但最後只能勉強顧到前兩者。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;時間壓力影響品質&#xA;&lt;ul&gt;&#xA;&lt;li&gt;鐵人賽每天要交稿，過程中經常趕進度，導致文章沒有辦法經過充分打磨。&lt;/li&gt;&#xA;&lt;li&gt;如果能提前做更完整的規劃與內容儲備，應該會更從容。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;我仍然學到的&#34;&gt;我仍然學到的&lt;/h2&gt;&#xA;&lt;p&gt;即便有遺憾，這 30 天的挑戰仍帶來不少收穫:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;架構全景感&#xA;&lt;ul&gt;&#xA;&lt;li&gt;把機器學習的經典演算法、深度學習的基礎架構一路梳理過，至少建立了一個「大地圖」。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;寫作與表達訓練&#xA;&lt;ul&gt;&#xA;&lt;li&gt;每天輸出逼迫自己將概念用文字組織，讓自己看得更清楚，也強化了教學思維。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;反思與自我認知&#xA;&lt;ul&gt;&#xA;&lt;li&gt;很清楚感受到自己在數學推導、架構細節、實務應用的平衡上還需要加強。&lt;/li&gt;&#xA;&lt;li&gt;這是檢討，但也是日後努力的方向。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;未來規劃&#34;&gt;未來規劃&lt;/h2&gt;&#xA;&lt;p&gt;這系列雖然結束，但我並不打算就此停下。接下來會有兩條路並行:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;部落格補充&#xA;&lt;ul&gt;&#xA;&lt;li&gt;這次沒有時間展開的主題（例如 XGBoost、One-Class SVM、更多深度學習應用案例），我會在之後逐步補充到部落格。&lt;/li&gt;&#xA;&lt;li&gt;如果有興趣交流，歡迎到我的部落格留言: &lt;a href=&#34;https://twcch.io/&#34;&gt;志謙’s Blog&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;更聚焦的專題&#xA;&lt;ul&gt;&#xA;&lt;li&gt;下一步會傾向以「單一架構 / 單一應用」為主題，深度探索，而不是像這次一樣要在 30 天內覆蓋廣大範圍。&lt;/li&gt;&#xA;&lt;li&gt;例如: 專門寫一系列關於 財報異常偵測模型 或 深度學習解釋性方法 (XAI)。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;累積實作案例&#xA;&lt;ul&gt;&#xA;&lt;li&gt;未來希望每個主題都有完整實驗，包含 dataset、code、結果分析，避免文章僅停留在理論層面。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;結語&#34;&gt;結語&lt;/h2&gt;&#xA;&lt;p&gt;這個系列的完成，對我而言更像是一場「測試」。測試自己能不能在繁忙的生活中，逼迫自己連續 30 天完成一件事。雖然成果不算完美，甚至只能說「勉強及格」，但至少我撐到了最後一天，沒有讓它爛尾。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;鐵人賽不是終點，而是起點。&lt;/strong&gt;&#xA;這 30 天讓我看清了差距，也讓我找到下一步的努力方向。明年如果還有機會，我會嘗試帶來一個更完整、更深入、更有價值的系列。&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 29) 注意力機制 (Attention Mechanism)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_29/</link>
      <pubDate>Fri, 29 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_29/</guid>
      <description>&lt;p&gt;在前一天，我們介紹了 Seq2Seq 架構 (Encoder-Decoder)，它將輸入序列壓縮成一個固定維度的上下文向量 (Context Vector)，再交由解碼器 (Decoder) 逐步生成輸出。這種方法為機器翻譯、摘要生成等任務帶來了突破，但它也有一個致命的缺陷——瓶頸效應 (Bottleneck Problem)。&lt;/p&gt;&#xA;&lt;p&gt;不論輸入序列多長，最終都必須壓縮到單一向量 $c$，再交給解碼器使用。對短序列來說這還能接受，但一旦輸入序列過長，資訊勢必會大量遺失。這就像是要把一本書濃縮成一句話，再交給翻譯員去翻譯成另一種語言，結果可想而知。&lt;/p&gt;&#xA;&lt;p&gt;為了解決這個問題，Bahdanau 等人在 2015 年提出了 Attention 機制，讓模型在生成輸出時，不再依賴單一上下文，而是能夠「動態選擇性地關注輸入序列的不同部分」。這一設計徹底改變了序列建模的方式，並為後來的 Transformer 奠定了基礎。&lt;/p&gt;&#xA;&lt;h2 id=&#34;attention-的核心思想&#34;&gt;Attention 的核心思想&lt;/h2&gt;&#xA;&lt;p&gt;Attention 的直觀想法可以用一個比喻來理解:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;假設你在讀一本英文小說，並且要翻譯成中文。&lt;/li&gt;&#xA;&lt;li&gt;當你翻譯到某一句話的時候，你不會只依靠腦中模糊的整體印象，而是會反覆回頭看英文原文的相關部分。&lt;/li&gt;&#xA;&lt;li&gt;Attention 就是這種「回頭查看、選擇性關注」的能力。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;換句話說：Decoder 在生成每個輸出詞時，不僅依賴最後的上下文向量，而是能針對 Encoder 的所有隱藏狀態進行加權。&lt;/p&gt;&#xA;&lt;h2 id=&#34;attention-的數學公式&#34;&gt;Attention 的數學公式&lt;/h2&gt;&#xA;&lt;p&gt;假設輸入序列為 $(x_1, x_2, \dots, x_T)$，經 Encoder 後得到隱藏狀態序列 $h_1, h_2, \dots, h_T$。在生成輸出 $y_t$ 時:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;計算注意力權重 (Attention Weights)&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;對於輸入的每個隱藏狀態 $h_i$，計算它與當前解碼器狀態 $s_{t-1}$ 的相似度:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;$$&#xA;e_{t,i} = \text{score}(s_{t-1}, h_i)&#xA;$$&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;使用 softmax 轉換為機率分布:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;$$&#xA;\alpha_{t,i} = \frac{\exp(e_{t,i})}{\sum_j \exp(e_{t,j})}&#xA;$$&lt;/p&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;計算上下文向量 (Context Vector)&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 28) Seq2Seq (Encoder Decoder with RNN, LSTM, GRU)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_28/</link>
      <pubDate>Thu, 28 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_28/</guid>
      <description>&lt;p&gt;在前幾天的文章中，我們依序介紹了 RNN、LSTM、GRU，並討論它們如何建模序列資料。這些模型能夠捕捉序列中的上下文關係，並緩解傳統 RNN 的梯度消失問題。然而，若我們想要處理更複雜的任務——例如機器翻譯 (Machine Translation)，僅僅依靠單向 RNN 或 LSTM 並不夠。&lt;/p&gt;&#xA;&lt;p&gt;這就引出了今天的主角: Seq2Seq 架構 (Sequence-to-Sequence Model)。它的核心思想是利用「編碼器 (Encoder)」將輸入序列壓縮成一個上下文表示，再由「解碼器 (Decoder)」生成輸出序列。這種架構在 2014 年被 Sutskever 等人首次提出，用於神經機器翻譯 (Neural Machine Translation, NMT)，開啟了 NLP 領域的一個新時代。&lt;/p&gt;&#xA;&lt;h2 id=&#34;seq2seq-的核心思想&#34;&gt;Seq2Seq 的核心思想&lt;/h2&gt;&#xA;&lt;p&gt;假設我們要將一句英文句子翻譯成中文:&lt;/p&gt;&#xA;&lt;p&gt;輸入: “I am happy today.”&#xA;輸出: “我今天很高興。”&lt;/p&gt;&#xA;&lt;p&gt;傳統的 RNN/LSTM 模型只能處理輸入和輸出的對應關係，但無法直接處理「序列到序列」的轉換問題。Seq2Seq 則透過 Encoder-Decoder 的設計，讓模型能夠處理 輸入與輸出長度不同的情況，這正是翻譯、摘要、對話等任務的核心需求。&lt;/p&gt;&#xA;&lt;p&gt;核心流程:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Encoder：讀取輸入序列，將其壓縮成一個固定維度的上下文向量 $c$。&lt;/li&gt;&#xA;&lt;li&gt;Decoder：根據上下文向量 $c$ 與先前輸出的資訊，逐步生成輸出序列。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;seq2seq-的數學形式&#34;&gt;Seq2Seq 的數學形式&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;編碼器 (Encoder)&#xA;&lt;ul&gt;&#xA;&lt;li&gt;輸入序列: $X = (x_1, x_2, \dots, x_T)$&lt;/li&gt;&#xA;&lt;li&gt;隱藏狀態更新:&#xA;$$&#xA;h_t = f(h_{t-1}, x_t)&#xA;$$&lt;/li&gt;&#xA;&lt;li&gt;最後的隱藏狀態 $h_T$ 作為上下文向量 $c$。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;解碼器 (Decoder)&#xA;&lt;ul&gt;&#xA;&lt;li&gt;初始狀態: $s_0 = c$&lt;/li&gt;&#xA;&lt;li&gt;每一步輸出:&#xA;$$&#xA;s_t = f(s_{t-1}, y_{t-1})&#xA;$$&#xA;$$&#xA;\hat{y}_t = g(s_t)&#xA;$$&#xA;其中:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;$f$ 可以是 RNN / LSTM / GRU 單元&lt;/li&gt;&#xA;&lt;li&gt;$g$ 通常是 softmax 層，用來輸出詞彙的機率分布&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;encoder-decoder-結構&#34;&gt;Encoder-Decoder 結構&lt;/h2&gt;&#xA;&lt;p&gt;從結構上看，Seq2Seq 就像是一個「兩段式」神經網路:&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 27) 閘控循環單元 (Gated Recurrent Unit)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_27/</link>
      <pubDate>Wed, 27 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_27/</guid>
      <description>&lt;p&gt;在前兩篇文章，我們分別介紹了 RNN (Recurrent Neural Network) 與 LSTM (Long Short-Term Memory)。RNN 為序列建模提供了基礎架構，但受限於梯度消失與爆炸問題，難以捕捉長距離依賴；LSTM 則透過引入 記憶單元 (Cell State) 與 門控機制 (Gating Mechanism)，成功緩解了這一問題。&lt;/p&gt;&#xA;&lt;p&gt;然而，LSTM 的設計相對複雜，每個時間步需要更新三個門 (遺忘門、輸入門、輸出門) 與一個記憶單元，計算成本高且參數量龐大。2014 年，Cho 等人在處理機器翻譯問題時提出了一種更簡化的替代方案——GRU (Gated Recurrent Unit)。&lt;/p&gt;&#xA;&lt;p&gt;GRU 的核心思想是: 保留 LSTM 的核心優勢 (門控記憶機制)，但去除冗餘設計，讓模型更輕量、更高效。&lt;/p&gt;&#xA;&lt;h2 id=&#34;gru-的設計動機&#34;&gt;GRU 的設計動機&lt;/h2&gt;&#xA;&lt;p&gt;LSTM 雖然強大，但存在兩個痛點:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;參數多，訓練慢: 每個 LSTM 單元有三個門與一個記憶單元，計算開銷大。&lt;/li&gt;&#xA;&lt;li&gt;模型過於複雜: 在某些任務中，LSTM 的輸出門設計顯得多餘，因為輸出與記憶單元的分離未必必要。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;GRU 將 LSTM 的「遺忘門」與「輸入門」合併為「更新門 (Update Gate)」，並去掉獨立的記憶單元，直接用隱藏狀態 $h_t$ 來承載資訊。這樣的設計大幅簡化了結構，同時保留了建模長距依賴的能力。&lt;/p&gt;&#xA;&lt;h2 id=&#34;gru-的結構直觀理解&#34;&gt;GRU 的結構直觀理解&lt;/h2&gt;&#xA;&lt;p&gt;可以用「筆記本」的比喻來理解:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;更新門: 決定要不要覆蓋舊的內容。&lt;/li&gt;&#xA;&lt;li&gt;重置門: 決定在寫新內容時，要不要忽略舊的資訊。&lt;/li&gt;&#xA;&lt;li&gt;隱藏狀態: 同時扮演了 LSTM 的「記憶單元」與「輸出」，簡化了設計。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;因此，GRU 本質上是 LSTM 的精簡版，保留長期記憶能力，但運算量較小。&lt;/p&gt;&#xA;&lt;h2 id=&#34;gru-與-lstm-的比較&#34;&gt;GRU 與 LSTM 的比較&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;特性&lt;/th&gt;&#xA;          &lt;th&gt;LSTM&lt;/th&gt;&#xA;          &lt;th&gt;GRU&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;記憶單元&lt;/td&gt;&#xA;          &lt;td&gt;有獨立的 Cell State $C_t$&lt;/td&gt;&#xA;          &lt;td&gt;無，僅用隱藏狀態 $h_t$&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;門的數量&lt;/td&gt;&#xA;          &lt;td&gt;三個門 (輸入、遺忘、輸出)&lt;/td&gt;&#xA;          &lt;td&gt;兩個門 (更新、重置)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;參數量&lt;/td&gt;&#xA;          &lt;td&gt;較多&lt;/td&gt;&#xA;          &lt;td&gt;較少&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;訓練速度&lt;/td&gt;&#xA;          &lt;td&gt;較慢&lt;/td&gt;&#xA;          &lt;td&gt;較快&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;表現&lt;/td&gt;&#xA;          &lt;td&gt;適合複雜長序列&lt;/td&gt;&#xA;          &lt;td&gt;在多數任務上與 LSTM 相近&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;應用&lt;/td&gt;&#xA;          &lt;td&gt;NLP、翻譯、語音辨識&lt;/td&gt;&#xA;          &lt;td&gt;NLP、時間序列、邊緣運算&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;研究結果顯示，在許多應用中，GRU 與 LSTM 的表現非常接近，有時甚至更好；但在特別長的序列上，LSTM 仍可能優於 GRU。&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 26) 長短期記憶網路 (Long Short-Term Memory)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_26/</link>
      <pubDate>Tue, 26 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_26/</guid>
      <description>&lt;p&gt;在前一篇，我們介紹了循環神經網路 (RNN)，並指出了它在處理序列資料時的強大之處：透過「隱藏狀態」將前後資訊連結起來。然而，我們同時也看到了 RNN 的最大瓶頸——梯度消失與梯度爆炸，使得它在長距離依賴 (long-term dependency) 的學習上表現不佳。&lt;/p&gt;&#xA;&lt;p&gt;為了解決這個問題，1997 年 Sepp Hochreiter 和 Jürgen Schmidhuber 提出了 長短期記憶網路 (LSTM)。LSTM 是 RNN 的改良版本，透過特殊的「記憶單元 (Memory Cell)」與「門控機制 (Gating Mechanism)」，大幅減緩了梯度消失的問題，成為自然語言處理 (NLP) 與序列建模的經典架構之一。&lt;/p&gt;&#xA;&lt;h2 id=&#34;lstm-的核心概念&#34;&gt;LSTM 的核心概念&lt;/h2&gt;&#xA;&lt;p&gt;LSTM 的設計目標是:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;保留長期資訊（避免梯度消失導致遺忘）&lt;/li&gt;&#xA;&lt;li&gt;選擇性遺忘不必要的資訊（避免無限累積造成干擾）&lt;/li&gt;&#xA;&lt;li&gt;動態決定何時輸入、何時輸出資訊&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;它在傳統 RNN 的基礎上，加入了兩個關鍵設計:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;記憶單元 (Cell State): 一條專門的「資訊高速公路」，允許資訊長距離傳遞。&lt;/li&gt;&#xA;&lt;li&gt;門控機制 (Gates): 透過 sigmoid 函數控制「資訊是否允許通過」，讓模型能選擇性記住或忘記。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;lstm-的結構&#34;&gt;LSTM 的結構&lt;/h2&gt;&#xA;&lt;p&gt;一個 LSTM 單元 (cell) 主要包含三個門與一個記憶單元:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;遺忘門 (Forget Gate)&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;決定要保留多少過去資訊。&lt;/li&gt;&#xA;&lt;li&gt;公式:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;$$&#xA;f_t = \sigma(W_f \cdot [h_{t-1}, x_t] + b_f)&#xA;$$&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;$f_t$ 越接近 0，表示忘得越多；越接近 1，表示保留越多。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;輸入門 (Input Gate)&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 25) 循環神經網路 (Recurrent Neural Network)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_25/</link>
      <pubDate>Mon, 25 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_25/</guid>
      <description>&lt;p&gt;在前面幾天，我們介紹了全連接神經網路 (FCNN) 與卷積神經網路 (CNN)。這些架構在處理結構化數據或影像資料上非常成功，但若應用到「序列資料」時就顯得不足。例如:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;文字句子 (自然語言處理)&lt;/li&gt;&#xA;&lt;li&gt;聲音波形 (語音辨識)&lt;/li&gt;&#xA;&lt;li&gt;時間序列 (股價、氣象、感測器數據)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;這些資料都有一個共同特性：前後之間具有順序與依賴關係。傳統的神經網路會把輸入展平成固定維度向量，忽略了序列的時間結構，這時就需要 循環神經網路 (Recurrent Neural Network, RNN)。&lt;/p&gt;&#xA;&lt;h2 id=&#34;為什麼需要-rnn&#34;&gt;為什麼需要 RNN?&lt;/h2&gt;&#xA;&lt;p&gt;假設我們要預測一句話的下一個單字:&lt;/p&gt;&#xA;&lt;p&gt;“我今天心情很好，所以想去 ___”&lt;/p&gt;&#xA;&lt;p&gt;在這個任務中，模型不僅要知道「今天心情很好」，還要能理解語境，才可能正確預測「散步」、「旅行」等合理詞彙。這就意味著模型需要「記憶」前文資訊。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;FCNN: 輸入固定維度，無法表達序列依賴。&lt;/li&gt;&#xA;&lt;li&gt;CNN: 能捕捉局部特徵，但難以捕捉長距離依賴。&lt;/li&gt;&#xA;&lt;li&gt;RNN: 透過循環結構，將「上一時間步的輸出」作為「下一時間步的輸入」的一部分，實現狀態的傳遞。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;rnn-的結構&#34;&gt;RNN 的結構&lt;/h2&gt;&#xA;&lt;p&gt;RNN 的核心是一個「循環單元 (Recurrent Cell)」，其計算公式如下:&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;h_t = \tanh(W_h h_{t-1} + W_x x_t + b)&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;其中:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;$x_t$: 在時間步 $t$ 的輸入&lt;/li&gt;&#xA;&lt;li&gt;$h_{t-1}$: 前一時間步的隱藏狀態 (hidden state)&lt;/li&gt;&#xA;&lt;li&gt;$h_t$: 當前時間步的隱藏狀態&lt;/li&gt;&#xA;&lt;li&gt;$W_h, W_x, b$: 可學習參數&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;這個設計讓 RNN 可以把前一時刻的資訊「帶到下一個時刻」，實現序列建模。&lt;/p&gt;&#xA;&lt;h2 id=&#34;rnn-的展開視角&#34;&gt;RNN 的展開視角&lt;/h2&gt;&#xA;&lt;p&gt;RNN 看起來是「循環」的，但在數學運算中，我們可以把它展開成多層結構:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;時間步 $t=1$：$h_1 = f(x_1, h_0)$&lt;/li&gt;&#xA;&lt;li&gt;時間步 $t=2$：$h_2 = f(x_2, h_1)$&lt;/li&gt;&#xA;&lt;li&gt;…&lt;/li&gt;&#xA;&lt;li&gt;時間步 $t=T$：$h_T = f(x_T, h_{T-1})$&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;展開後的 RNN 就像一個「深層神經網路」，但每一層的參數 $W_h, W_x$ 是 共享的。&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 24) Adam 優化器 (Adaptive Moment Estimation)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_24/</link>
      <pubDate>Sun, 24 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_24/</guid>
      <description>&lt;p&gt;在前一天，我們整理了深度學習中常見的優化方法，從最基本的隨機梯度下降 (SGD)，到 Momentum、RMSProp、Adagrad 等。今天我們要深入介紹其中最具代表性、也是實務中最常見的優化方法之一——Adam (Adaptive Moment Estimation)。&lt;/p&gt;&#xA;&lt;p&gt;Adam 幾乎是深度學習的「預設優化器」。不論是電腦視覺、自然語言處理，還是時間序列預測，只要使用主流深度學習框架 (PyTorch、TensorFlow、Keras)，Adam 幾乎總是第一個被嘗試的選擇。&lt;/p&gt;&#xA;&lt;h2 id=&#34;adam-的動機&#34;&gt;Adam 的動機&lt;/h2&gt;&#xA;&lt;p&gt;為什麼會有 Adam? 它的出發點是想同時結合 Momentum 與 RMSProp 的優點:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Momentum: 透過累積一階動量 (過去梯度的加權平均)，能加速收斂並減少震盪。&lt;/li&gt;&#xA;&lt;li&gt;RMSProp: 透過維護二階動量 (梯度平方的移動平均)，能自動調整不同維度的學習率。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Adam 的設計思想是: 既要考慮梯度的方向 (Momentum)，又要考慮不同維度的學習率 (RMSProp)，並在數值上進行偏差修正，確保更新穩定。&lt;/p&gt;&#xA;&lt;h2 id=&#34;數學公式&#34;&gt;數學公式&lt;/h2&gt;&#xA;&lt;p&gt;Adam 的更新規則如下:&lt;/p&gt;&#xA;&lt;h3 id=&#34;初始化&#34;&gt;初始化&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;參數 $\theta_0$&lt;/li&gt;&#xA;&lt;li&gt;一階動量 $m_0 = 0$&lt;/li&gt;&#xA;&lt;li&gt;二階動量 $v_0 = 0$&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;更新規則&#34;&gt;更新規則&lt;/h3&gt;&#xA;&lt;p&gt;在第 $t$ 次迭代時:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;計算梯度:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;$$&#xA;g_t = \nabla_\theta L(\theta_t)&#xA;$$&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;一階動量 (類似 Momentum):&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;$$&#xA;m_t = \beta_1 m_{t-1} + (1-\beta_1) g_t&#xA;$$&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;二階動量 (類似 RMSProp):&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;$$&#xA;v_t = \beta_2 v_{t-1} + (1-\beta_2) g_t^2&#xA;$$&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 23) 深度學習中的優化方法 (Optimization in Deep Learning)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_23/</link>
      <pubDate>Sat, 23 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_23/</guid>
      <description>&lt;p&gt;在前一篇，我們談到了深度學習中的正規化與正則化，重點在於如何避免過擬合並保持訓練穩定。然而，光是解決過擬合還不夠：在龐大的神經網路裡，我們還得面對另一個關鍵問題——如何有效率地找到參數的最佳解。&lt;/p&gt;&#xA;&lt;p&gt;這就是「優化方法 (Optimization)」的核心任務。深度學習的訓練，本質上是透過梯度下降類方法來最小化損失函數。但在實務上，單純的梯度下降往往不足，因此衍生出各種改良版演算法。&lt;/p&gt;&#xA;&lt;h2 id=&#34;問題背景-為什麼需要不同優化方法&#34;&gt;問題背景: 為什麼需要不同優化方法？&lt;/h2&gt;&#xA;&lt;p&gt;在數學理論上，假設我們要最小化的目標函數是損失函數 $L(\theta)$，其參數更新規則來自於梯度下降:&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;\theta_{t+1} = \theta_t - \eta \nabla_\theta L(\theta_t)&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;其中:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;$\theta_t$: 第 $t$ 次迭代的參數&lt;/li&gt;&#xA;&lt;li&gt;$\eta$: 學習率 (Learning Rate)&lt;/li&gt;&#xA;&lt;li&gt;$\nabla_\theta L(\theta_t)$: 在當前參數下的梯度&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;這個公式看似簡單，但實務上有幾個挑戰:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;鞍點與局部極小值&#xA;&lt;ul&gt;&#xA;&lt;li&gt;高維空間裡，鞍點比局部極小值更常見，導致模型容易「卡住」。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;不同方向的梯度尺度差異&#xA;&lt;ul&gt;&#xA;&lt;li&gt;某些維度梯度很大、某些維度很小，會造成「之字形震盪」或收斂緩慢。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;學習率的設計&#xA;&lt;ul&gt;&#xA;&lt;li&gt;學習率太大，模型發散；太小，收斂速度慢甚至陷入次優解。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;非凸性&#xA;&lt;ul&gt;&#xA;&lt;li&gt;深度網路的損失函數高度非凸，沒有單一「全局最優解」，需要演算法在複雜地形中找到足夠好的解。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;因此，雖然梯度下降是核心，但各種優化方法的改進就是針對這些問題而來。&lt;/p&gt;&#xA;&lt;h2 id=&#34;基本優化方法&#34;&gt;基本優化方法&lt;/h2&gt;&#xA;&lt;h3 id=&#34;批次梯度下降-batch-gradient-descent&#34;&gt;批次梯度下降 (Batch Gradient Descent)&lt;/h3&gt;&#xA;&lt;p&gt;一次使用所有樣本計算梯度並更新參數。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;優點: 理論收斂穩定，梯度計算精確。&lt;/li&gt;&#xA;&lt;li&gt;缺點: 資料量大時，計算昂貴，幾乎不可行。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;隨機梯度下降-stochastic-gradient-descent-sgd&#34;&gt;隨機梯度下降 (Stochastic Gradient Descent, SGD)&lt;/h3&gt;&#xA;&lt;p&gt;每次隨機抽取一筆樣本進行更新:&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;\theta_{t+1} = \theta_t - \eta \nabla_\theta L(\theta_t; x^{(i)}, y^{(i)})&#xA;$$&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;優點: 計算成本低，每次更新快速。&lt;/li&gt;&#xA;&lt;li&gt;缺點: 梯度估計方差大，收斂過程不穩定。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;小批次梯度下降-mini-batch-gradient-descent&#34;&gt;小批次梯度下降 (Mini-Batch Gradient Descent)&lt;/h3&gt;&#xA;&lt;p&gt;綜合兩者優點，常用一個小批次 (例如 32 或 128 筆樣本) 計算梯度。&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 22) 深度學習中的正規化與正則化 (Regularization in Deep Learning)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_22/</link>
      <pubDate>Fri, 22 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_22/</guid>
      <description>&lt;p&gt;在前幾天的文章裡，我們已經從線性迴歸、邏輯迴歸一路走到 CNN (卷積神經網路)，逐步體驗了機器學習與深度學習的不同。到了深度學習階段，模型的複雜度往往大幅增加，參數數量動輒上百萬甚至上億，這也帶來了一個非常嚴重的問題: 過擬合 (Overfitting)。&lt;/p&gt;&#xA;&lt;p&gt;今天我們要談的主題「正規化 (Normalization) 與正則化 (Regularization)」，就是專門為了解決這類問題而設計的工具。這兩個詞在中文裡常常被混淆，但在深度學習中有明確的區分:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;正規化 (Normalization): 處理資料或中間層輸出的「分布」，讓訓練更穩定。&lt;/li&gt;&#xA;&lt;li&gt;正則化 (Regularization): 在模型學習過程中「限制參數自由度」，避免過度擬合。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;可以把它們理解成:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;正規化是「讓訓練跑得順暢」&lt;/li&gt;&#xA;&lt;li&gt;正則化是「讓模型不要學壞」&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;為什麼需要正規化與正則化&#34;&gt;為什麼需要正規化與正則化?&lt;/h2&gt;&#xA;&lt;p&gt;深度學習的挑戰主要來自於以下幾點:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;參數數量龐大&#xA;&lt;ul&gt;&#xA;&lt;li&gt;FCNN、CNN、RNN 等模型的參數動輒上百萬，模型表達能力非常強。這雖然能學習複雜模式，但也極容易記住「訓練資料」而不是「一般化規律」。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;梯度傳遞問題&#xA;&lt;ul&gt;&#xA;&lt;li&gt;深層網路容易遇到梯度消失或爆炸，導致學習不穩定。&lt;/li&gt;&#xA;&lt;li&gt;即便是設計良好的激活函數 (如 ReLU)，也可能因資料分布不均而造成某些神經元失效。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;資料有限&#xA;&lt;ul&gt;&#xA;&lt;li&gt;真實世界中，資料集往往有限，無法支撐一個龐大模型完全「正確」學習。若沒有適當限制，模型就會死記硬背訓練資料，導致測試集表現不佳。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;為了應對這些問題，正規化與正則化技術被廣泛應用在深度學習的訓練流程中。&lt;/p&gt;&#xA;&lt;h3 id=&#34;正規化-normalization&#34;&gt;正規化 (Normalization)&lt;/h3&gt;&#xA;&lt;p&gt;正規化的核心目標是: 讓輸入資料或中間層輸出的數值保持在合理範圍內，以便模型更容易學習。在模型訓練前，我們通常會對輸入資料進行縮放，例如:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Min-Max Scaling&lt;/li&gt;&#xA;&lt;li&gt;Z-score Standardization&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;正則化-regularization&#34;&gt;正則化 (Regularization)&lt;/h3&gt;&#xA;&lt;p&gt;正則化的核心目標是：避免模型過擬合，提升泛化能力。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;L1 與 L2 正則化&lt;/li&gt;&#xA;&lt;li&gt;Dropout&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;正規化與正則化的互補關係&#34;&gt;正規化與正則化的互補關係&lt;/h2&gt;&#xA;&lt;p&gt;雖然名稱相似，但正規化與正則化針對的問題不同:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;正規化 → 解決訓練穩定性、加速收斂&lt;/li&gt;&#xA;&lt;li&gt;正則化 → 解決過擬合、提升泛化&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;在實務上，它們通常是 同時使用 的。例如:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;CNN: 資料正規化 + Batch Normalization + Dropout + Weight Decay&lt;/li&gt;&#xA;&lt;li&gt;RNN/Transformer: Layer Normalization + Early Stopping + Data Augmentation&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;結語&#34;&gt;結語&lt;/h2&gt;&#xA;&lt;p&gt;深度學習之所以能夠在近十年迅速崛起，不只是因為 GPU 算力提升或資料量增大，還有賴於一系列 正規化與正則化技術 的發展，讓深度模型可以被穩定地訓練並具備良好的泛化能力。&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 21) 卷積神經網絡 (Convolutional Neural Network)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_21/</link>
      <pubDate>Thu, 21 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_21/</guid>
      <description>&lt;p&gt;在初步暸解全連接神經網絡 (Fully Connected Neural Network) 後，接下來必須介紹的經典架構就是卷積神經網絡 (Convolutional Neural Network; CNN)。卷積神經網絡可以說是深度學習的代表性架構之一，特別是在電腦視覺 (Computer Vision) 領域幾乎無處不在。&lt;/p&gt;&#xA;&lt;p&gt;在我們的日常生活中，從手機的人臉辨識、影像搜尋、自駕車的影像識別，到醫學影像的腫瘤檢測，都可以看到卷積神經網絡的身影。它能在海量影像資料中自動學習特徵，避免了傳統機器學習需要人工設計特徵的困難。&lt;/p&gt;&#xA;&lt;h2 id=&#34;為什麼需要-cnn&#34;&gt;為什麼需要 CNN？&lt;/h2&gt;&#xA;&lt;p&gt;在前面介紹的 全連接神經網路 (Fully Connected Neural Network, FCNN) 中，我們知道每一層神經元都與上一層的所有輸入相連。但如果我們把輸入換成圖片，就會發現一個很大的問題:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;假設輸入是一張大小為 $224 \times 224$ 的彩色圖片，這代表有 $224 \times 224 \times 3 = 150,528$ 個像素值。若將這些像素全部展平成一維向量再輸入 FCNN，第一層神經元若有 1000 個，就需要 1.5 億個參數。這樣的參數量幾乎不可訓練，既浪費計算資源，也容易過擬合。&lt;/li&gt;&#xA;&lt;li&gt;CNN 的設計靈感來自於生物學上對「視覺皮質 (Visual Cortex)」的研究：人類大腦在處理影像時，不是一次性看完整張圖，而是先觀察局部特徵 (邊緣、角落、紋理)，再逐步組合成更高層次的語意 (眼睛、鼻子、車輪等)。&lt;/li&gt;&#xA;&lt;li&gt;因此 CNN 引入了「局部感受野 (Local Receptive Field)」與「權重共享 (Weight Sharing)」兩個關鍵設計，使模型能夠高效處理圖片，同時降低參數數量。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;cnn-的基本組件&#34;&gt;CNN 的基本組件&lt;/h2&gt;&#xA;&lt;p&gt;CNN 主要由以下幾種層組成:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;卷積層 (Convolutional Layer)&#xA;&lt;ul&gt;&#xA;&lt;li&gt;透過多個卷積核從輸入影像中提取特徵。&lt;/li&gt;&#xA;&lt;li&gt;每個卷積核產生一張特徵圖 (Feature Map)。&lt;/li&gt;&#xA;&lt;li&gt;通常會搭配激活函數 (例如 ReLU)，引入非線性。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;池化層 (Pooling Layer)&#xA;&lt;ul&gt;&#xA;&lt;li&gt;池化層的功能是「壓縮資料」並「保留重要特徵」。&lt;/li&gt;&#xA;&lt;li&gt;常見方法:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;最大池化 (Max Pooling): 取區域內的最大值。&lt;/li&gt;&#xA;&lt;li&gt;平均池化 (Average Pooling)：取區域內的平均值。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;池化的好處:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;降低資料維度，減少參數數量。&lt;/li&gt;&#xA;&lt;li&gt;增加特徵的不變性 (例如影像的平移或縮放)。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;全連接層 (Fully Connected Layer)&#xA;&lt;ul&gt;&#xA;&lt;li&gt;通常位於 CNN 的尾端，將高層特徵輸出轉換為分類結果。&lt;/li&gt;&#xA;&lt;li&gt;與傳統神經網路類似，最後一層常使用 Softmax 作為多分類輸出。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;激活函數-activation-function&#34;&gt;激活函數 (Activation Function)&lt;/h3&gt;&#xA;&lt;p&gt;CNN 常使用 ReLU (Rectified Linear Unit)，定義為:&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 20) 激活函數 (Activation Function)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_20/</link>
      <pubDate>Wed, 20 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_20/</guid>
      <description>&lt;p&gt;承接昨天的神經元 (Neuron)，神經元的輸出是線性輸出，若僅停留在這個階段，輸出仍然是線性函數，即便我們把很多神經元堆疊在一起，整體模型仍然等效於一個線性轉換，無法捕捉到真實世界中複雜的非線性關係為了解決這個問題，我們需要引入激活函數 (Activation Function) 可以讓模型學習到更複雜的模式 (非線性)，所以激活函數必須是非線性的，這樣才能跟神經元做搭配。&lt;/p&gt;&#xA;&lt;h2 id=&#34;常見的激活函數&#34;&gt;常見的激活函數&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-sigmoid-函數&#34;&gt;1. Sigmoid 函數&lt;/h3&gt;&#xA;&lt;p&gt;$$&#xA;\sigma(x) = \frac{1}{1+e^{-x}}&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;特點:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;輸出範圍在 [0,1] 之間&lt;/li&gt;&#xA;&lt;li&gt;常用於二元分類問題&lt;/li&gt;&#xA;&lt;li&gt;缺點: 容易出現梯度消失問題&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;2-softmax&#34;&gt;2. Softmax&lt;/h3&gt;&#xA;&lt;p&gt;$$&#xA;\sigma(z_i) = \frac{e^{z_i}}{\sum_{j=1}^{K}e^{z_j}}&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;特點:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;輸出範圍: $(0,1)$，且所有輸出和為 1&lt;/li&gt;&#xA;&lt;li&gt;特點: 多分類問題的常用輸出層函數&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;3-relu-rectified-linear-unit&#34;&gt;3. ReLU (Rectified Linear Unit)&lt;/h3&gt;&#xA;&lt;p&gt;$$&#xA;f(x) = max(0, x)&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;特點：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;輸出範圍：$[0, +\infty)$&lt;/li&gt;&#xA;&lt;li&gt;特點: 簡單高效，目前深度學習最常用的激活函數&lt;/li&gt;&#xA;&lt;li&gt;缺點: 在 $x &amp;lt; 0$ 的區域梯度為 0，可能導致「神經元死亡」&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;4-tanh-雙曲正切函數&#34;&gt;4. Tanh (雙曲正切函數)&lt;/h3&gt;&#xA;&lt;p&gt;$$&#xA;\text{tanh}(x) = \frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}&#xA;$$&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 19) 神經元 (Neuron)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_19/</link>
      <pubDate>Tue, 19 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_19/</guid>
      <description>&lt;p&gt;前一篇我們先介紹了全連接神經網絡 (Fully Connected Neural Network)，相信大家還是不太清楚這是什麼，接下來會用幾天的篇幅一一介紹相關的專有名詞，若要理解神經網路，必須先從最小的組成單位 —— 神經元 (Neuron) 開始。&lt;/p&gt;&#xA;&lt;p&gt;人工神經元的靈感來自於生物神經科學中「神經元」的概念: 人腦中的神經細胞會接收訊號、處理並傳遞訊號給下一個神經元，形成複雜的網絡。人工神經網路 (Artificial Neural Network, ANN) 正是透過數學方式去模擬這樣的運作。&lt;/p&gt;&#xA;&lt;h2 id=&#34;神經元數學模型&#34;&gt;神經元數學模型&lt;/h2&gt;&#xA;&lt;p&gt;一個人工神經元的輸入與輸出過程可以寫成:&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;z = \sum\limits_{i=1}^{n} w_i x_i + b&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;a = \sigma(z)&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;其中:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;$x_i$: 輸入特徵&lt;/li&gt;&#xA;&lt;li&gt;$w_i$: 權重 (weight)，決定輸入的重要性&lt;/li&gt;&#xA;&lt;li&gt;$b$: 偏差 (bias)，調整整體的輸入偏移量&lt;/li&gt;&#xA;&lt;li&gt;$\sigma(\cdot)$: 激活函數 (Activation Function)，將線性組合轉換為非線性輸出&lt;/li&gt;&#xA;&lt;li&gt;$a$: 神經元的輸出&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;先不看激活函數的部分，是不是第一眼會覺得好像在哪裡看過? 沒錯就是我們 Day 2 介紹的線性迴歸，所以神經元本身並不是什麼太高級的東西，就是一個線性輸出而已，為了要讓神經元能夠模擬更複雜的非線性關係，才會在線性輸出後再加上激活函數 (激活函數是什麼明天介紹)&lt;/p&gt;&#xA;&lt;h2 id=&#34;神經元的運作流程&#34;&gt;神經元的運作流程&lt;/h2&gt;&#xA;&lt;p&gt;以一個簡單的二元分類例子來看&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;輸入層: 假設有三個特徵 $x_1$, $x_2$, $x_3$&lt;/li&gt;&#xA;&lt;li&gt;加權求和: 每個特徵乘上權重 $w_i$，再加上偏差 $b$&lt;/li&gt;&#xA;&lt;li&gt;激活函數：輸入 ReLU 或 Sigmoid，得到輸出 a&lt;/li&gt;&#xA;&lt;li&gt;傳遞至下一層: 這個輸出作為下一層神經元的輸入&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;當多層神經元堆疊，就形成所謂的「多層感知機 (MLP)」&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 18) 全連接神經網絡 (Fully Connected Neural Network)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_18/</link>
      <pubDate>Mon, 18 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_18/</guid>
      <description>&lt;p&gt;在進入深度學習的第一步，必須要先認識最基礎的深度學習架構，這個架構稱為:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;全連接神經網路 (Fully Connected Neural Network; FCNN)&lt;/li&gt;&#xA;&lt;li&gt;多層感知機 (Multi-Layer Perceptron; MLP)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;這兩個都是指同一個東西，這個架構也是所有深度學習架構的基石，CNN、RNN、Transformer 都可以看作是在 FCNN 上加入特殊結構與限制後的延伸&lt;/p&gt;&#xA;&lt;h2 id=&#34;基本架構&#34;&gt;基本架構&lt;/h2&gt;&#xA;&lt;p&gt;大家可以使用這個 &lt;a href=&#34;https://playground.tensorflow.org/#activation=tanh&amp;amp;batchSize=10&amp;amp;dataset=circle&amp;amp;regDataset=reg-plane&amp;amp;learningRate=0.03&amp;amp;regularizationRate=0&amp;amp;noise=0&amp;amp;networkShape=4,2&amp;amp;seed=0.61546&amp;amp;showTestData=false&amp;amp;discretize=false&amp;amp;percTrainData=50&amp;amp;x=true&amp;amp;y=true&amp;amp;xTimesY=false&amp;amp;xSquared=false&amp;amp;ySquared=false&amp;amp;cosX=false&amp;amp;sinX=false&amp;amp;cosY=false&amp;amp;sinY=false&amp;amp;collectStats=false&amp;amp;problem=classification&amp;amp;initZero=false&amp;amp;hideText=false&#34;&gt;網站&lt;/a&gt; 看一下神經網絡的架構與運行過程，簡單來說最基礎的神經網絡架構一定有以下三個 layer:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;輸入層 (Input Layer): 接收原始特徵，大小等於特徵數量&lt;/li&gt;&#xA;&lt;li&gt;隱藏層 (Hidden Layers): 由多個神經元 (Neurons) 組成，每個神經元與前一層的所有神經元相連&lt;/li&gt;&#xA;&lt;li&gt;輸出層 (Output Layer): 對應任務需求，分類問題常用 softmax、多類別輸出；回歸問題則可能是單一實值，簡單的區分如下:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;回歸問題&#xA;&lt;ul&gt;&#xA;&lt;li&gt;輸出層神經元數 = 1 (代表一個連續數值)&lt;/li&gt;&#xA;&lt;li&gt;常用激活函數: 無激活 (linear)&lt;/li&gt;&#xA;&lt;li&gt;Loss function: MSE, MAE&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;二元分類&#xA;&lt;ul&gt;&#xA;&lt;li&gt;寫法一: 1 個神經元 + Sigmoid 激活 (輸出機率 [0,1])&lt;/li&gt;&#xA;&lt;li&gt;寫法二: 2 個神經元 + Softmax (輸出兩類的機率分佈)&lt;/li&gt;&#xA;&lt;li&gt;Loss function: Binary Crossentropy / Categorical Crossentropy&lt;/li&gt;&#xA;&lt;li&gt;✅ 工程上最常用的是 1 個輸出神經元 + Sigmoid&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;多元分類 (N 類別)&#xA;&lt;ul&gt;&#xA;&lt;li&gt;輸出層神經元數 = N&lt;/li&gt;&#xA;&lt;li&gt;激活函數: Softmax (保證所有輸出加起來 = 1，形成機率分布)&lt;/li&gt;&#xA;&lt;li&gt;Loss function: Categorical Crossentropy / Sparse Categorical Crossentropy&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;運作流程&#34;&gt;運作流程&lt;/h2&gt;&#xA;&lt;p&gt;整個神經網絡的運做過程，核心就是「輸入資料 (X) → 正向傳播 (Forward) → 計算 Loss → 反向傳播 (Backward) → 更新參數 (Gradient Descent) → 再正向傳播」，說明如下:&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 17) 淺談深度學習 (Deep Learning)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_17/</link>
      <pubDate>Sun, 17 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_17/</guid>
      <description>&lt;p&gt;我們機器學習的部分還有 XGBoost、PCA、OneClass SVM 都還沒有談，只是篇幅限制，原本規劃深度學習大概就要花 15 篇左右的內容來談談，如果後續有篇幅我再補充。&lt;/p&gt;&#xA;&lt;p&gt;從這篇開始，系列會進入另一個階段: 深度學習 (Deep Learning)。這部分的內容將與前 16 天有明顯不同，因為重點不再是數學公式與演算法推導，而是各種網路架構 (Architectures) 的原理、設計思維與應用。&lt;/p&gt;&#xA;&lt;h2 id=&#34;機器學習-vs-深度學習&#34;&gt;機器學習 vs. 深度學習&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;機器學習 (Machine Learning)&#xA;&lt;ul&gt;&#xA;&lt;li&gt;特徵工程往往是關鍵: 要先設計、轉換、挑選特徵，才能把問題丟給模型學習&lt;/li&gt;&#xA;&lt;li&gt;模型通常較淺，例如: 決策樹、SVM、線性回歸&lt;/li&gt;&#xA;&lt;li&gt;適合中小型資料集，計算需求相對低&lt;/li&gt;&#xA;&lt;li&gt;優點: 可解釋性高、對資料量需求不大&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;深度學習 (Deep Learning)&#xA;&lt;ul&gt;&#xA;&lt;li&gt;以多層神經網路為核心，能自動從原始資料中學習特徵&lt;/li&gt;&#xA;&lt;li&gt;不再依賴繁重的人工特徵設計，例如圖像處理不需要先抽 SIFT/HOG，網路會自己學&lt;/li&gt;&#xA;&lt;li&gt;特別適合高維度、非結構化資料 (圖像、語音、文字)&lt;/li&gt;&#xA;&lt;li&gt;需要大量資料與算力支撐，否則容易過擬合&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;一句話總結: 機器學習的「重點」在於 人設計特徵 → 模型學習規則；深度學習則是 模型自己學特徵 + 規則。&lt;/p&gt;&#xA;&lt;h2 id=&#34;為什麼需要深度學習&#34;&gt;為什麼需要深度學習？&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;處理高維與非結構化資料&#xA;&lt;ul&gt;&#xA;&lt;li&gt;傳統 ML 模型處理數值表格非常好用，但面對影像像素矩陣、語音頻譜、自然語言文字序列就顯得力不從心。&lt;/li&gt;&#xA;&lt;li&gt;深度學習的 CNN、RNN、Transformer 等架構正好能捕捉這些資料的內在結構。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;表達能力強大&#xA;&lt;ul&gt;&#xA;&lt;li&gt;理論上，一個足夠深的神經網路能近似任何函數 (Universal Approximation Theorem)。&lt;/li&gt;&#xA;&lt;li&gt;在實務上，這意味著深度學習能擬合遠比傳統演算法更複雜的非線性關係。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;自動化特徵抽取&#xA;&lt;ul&gt;&#xA;&lt;li&gt;從手動設計特徵到「端到端」學習，深度學習大幅降低了人工干預，提升了跨領域可遷移性。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;深度學習的挑戰&#34;&gt;深度學習的挑戰&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;資料需求: 需要大量標註資料，否則效果有限&lt;/li&gt;&#xA;&lt;li&gt;計算需求: 需要 GPU/TPU 等硬體加速&lt;/li&gt;&#xA;&lt;li&gt;可解釋性低: 模型往往是「黑盒子」，難以直接解釋決策依據&lt;/li&gt;&#xA;&lt;li&gt;訓練難度: 需要調整大量超參數 (學習率、層數、激活函數、正則化方法等)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;結語&#34;&gt;結語&lt;/h2&gt;&#xA;&lt;p&gt;深度學習並不是「更高級的機器學習」，而是一種 不同思維：它將特徵學習與規則學習合而為一，讓模型能直接面對複雜且原始的資料。這篇文章作為深度學習的起手式，主要幫助讀者建立心態轉換：從「演算法」的框架，轉向「架構」的世界。&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 16) K-Means</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_16/</link>
      <pubDate>Sat, 16 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_16/</guid>
      <description>&lt;p&gt;今天本來要說極限梯度提升數 (XGBoost)，但是我發現後面的篇幅可能快不夠了，今天開始的內容會調整成，無監督式學習 → 深度學習 → 如果有時間再回來補充 One-Class SVM 跟 XGBoost。&lt;/p&gt;&#xA;&lt;p&gt;K-Means 是一種無監督學習中的聚類演算法，旨在將資料分為 K 個群集，使同一群集內的資料點之間相似度最高，而不同群集之間相似度最低。到這邊可能會有疑問，分類跟聚類差在哪? 分類要有標籤 (監督式學習)，而聚類不需要有標籤 (無監督式學習)，可以想像一下原始資料，如果要訓練分類模型，你在訓練之前就會知道每筆資料要分成什麼類別，但是到了聚類，你的資料完全分不出來該筆資料要分成什麼類別，只知道我這組資料要分成幾群。&lt;/p&gt;&#xA;&lt;h2 id=&#34;模型介紹&#34;&gt;模型介紹&lt;/h2&gt;&#xA;&lt;h3 id=&#34;模型邏輯與核心概念&#34;&gt;模型邏輯與核心概念&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;依照 K 的數量，隨機選出 K 個資料點作為初始質心 (centroids)&lt;/li&gt;&#xA;&lt;li&gt;每筆資料進行窮舉比較與 centroids 的歐幾里得距離，與距離最小的 centroids 為一群&lt;/li&gt;&#xA;&lt;li&gt;計算每個群集的平均值，為該群集所有資料點的 centroids&lt;/li&gt;&#xA;&lt;li&gt;重複指派與更新步驟，直到 centroids 不再顯著變動或達到最大迭代次數&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;cost-function&#34;&gt;Cost Function&lt;/h4&gt;&#xA;&lt;p&gt;$$&#xA;J = \sum_{i=1}^K \sum_{x \in C_i} |x - \mu_i|^2&#xA;$$&lt;/p&gt;&#xA;&lt;h4 id=&#34;肘部法&#34;&gt;肘部法&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;K 值得決定，可以依照肘部法進行判斷&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;k-means-的核心弱點&#34;&gt;K-Means 的核心弱點&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;初始中心點敏感問題 (Initialization Sensitivity): 當第一次初始化結果不好，導致誤差就很大，且沒辦法降低怎麼辦，即使資料本身具有明確的群聚特徵，也可能被錯誤分群，可以透過 K-Means++ 解決&#xA;&lt;ul&gt;&#xA;&lt;li&gt;替代隨機初始化，透過機率機制選出「較分散」的中心點&lt;/li&gt;&#xA;&lt;li&gt;能顯著降低收斂到壞解的風險，推薦預設使用&lt;/li&gt;&#xA;&lt;li&gt;sklearn 中內建支援: KMeans(init=&amp;lsquo;k-means++&amp;rsquo;) (預設就是這個)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;優缺點&#34;&gt;優缺點&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;優點&lt;/th&gt;&#xA;          &lt;th&gt;缺點&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;計算快速、可擴展、易平行&lt;/td&gt;&#xA;          &lt;td&gt;需先給定 k，對初始化與尺度敏感&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;易實作、常作為分群基線&lt;/td&gt;&#xA;          &lt;td&gt;假設球形/大小相近群，對離群值非常敏感&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;可搭配 MiniBatchKMeans 處理大規模資料&lt;/td&gt;&#xA;          &lt;td&gt;對非凸形狀或重疊群表現不佳&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2 id=&#34;模型實作&#34;&gt;模型實作&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Day 16 - K-Means on Iris (library dataset, full pipeline)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;seaborn&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sns&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;numpy&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;np&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.pipeline&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Pipeline&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.preprocessing&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;StandardScaler&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.cluster&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;KMeans&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;MiniBatchKMeans&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;silhouette_score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adjusted_rand_score&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ParameterGrid&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.decomposition&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;PCA&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;plt&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 1) 載入資料（無需外部檔案）&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;iris&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sns&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load_dataset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;iris&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# columns: sepal_length, sepal_width, petal_length, petal_width, species&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;iris&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;drop&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;species&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;y_true&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;iris&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;species&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 僅作對照評估，不參與訓練（非監督）&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 2) 工程化 Pipeline：標準化 + KMeans&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;make_kmeans_pipe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Pipeline&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;scaler&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;StandardScaler&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()),&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;kmeans&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;KMeans&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;n_clusters&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;init&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;k-means++&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;n_init&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;            &lt;span class=&#34;c1&#34;&gt;# 提升穩定性&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;max_iter&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;300&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;random_state&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;42&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 3) 用 Elbow 與 Silhouette 輔助挑 k&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;K_RANGE&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# Iris 通常 2~6 即可觀察&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;wcss&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sils&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[],&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;K_RANGE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;pipe&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;make_kmeans_pipe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pipe&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;named_steps&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;kmeans&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;labels_&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;wcss&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pipe&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;named_steps&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;kmeans&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;inertia_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# WCSS&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;sils&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;silhouette_score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pipe&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;named_steps&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;scaler&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;k vs WCSS:&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;list&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;zip&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;K_RANGE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;round&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;wcss&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])))&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;k vs Silhouette:&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;list&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;zip&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;K_RANGE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;round&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sils&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])))&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 4) 以 k=3 做主實驗（Iris 有 3 個物種）&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;pipe&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;make_kmeans_pipe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;pipe&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pipe&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;named_steps&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;kmeans&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;labels_&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 5) 非監督情境下的評估指標&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;sil&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;silhouette_score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pipe&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;named_steps&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;scaler&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 若有真實標籤可作參考（僅作對照用）：Adjusted Rand Index（ARI）&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;ari&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;adjusted_rand_score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y_true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Silhouette Score (k=&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;): &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sil&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;.4f&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Adjusted Rand Index vs species (k=&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;): &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ari&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;.4f&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 6) 簡易視覺化（PCA 2D）&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Z&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;PCA&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_components&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;random_state&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;42&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit_transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pipe&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;named_steps&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;scaler&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;figure&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;figsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;scatter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Z&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[:,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Z&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[:,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;K-Means (k=&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;) on Iris (PCA 2D)&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;Silhouette=&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sil&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;.3f&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;, ARI=&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ari&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;.3f&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xlabel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;PC1&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ylabel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;PC2&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tight_layout&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;show&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 7) 進一步：MiniBatchKMeans（大資料時）&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;mbk_pipe&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Pipeline&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;scaler&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;StandardScaler&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()),&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;kmeans&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;MiniBatchKMeans&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;n_clusters&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;init&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;k-means++&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;random_state&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;42&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;batch_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n_init&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;mbk_labels&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mbk_pipe&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;named_steps&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;kmeans&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;labels_&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;mbk_sil&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;silhouette_score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mbk_pipe&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;named_steps&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;scaler&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mbk_labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;MiniBatchKMeans Silhouette (k=&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;): &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mbk_sil&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;.4f&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 8) 粗略參數掃描（僅示例）&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;grid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;kmeans__n_clusters&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;kmeans__n_init&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]}&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;best&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;params&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ParameterGrid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;grid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;candidate&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Pipeline&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;scaler&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;StandardScaler&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()),&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;kmeans&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;KMeans&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;init&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;k-means++&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;max_iter&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;300&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;random_state&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;42&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))])&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;candidate&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;set_params&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;params&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;labels_c&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;candidate&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;named_steps&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;kmeans&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;labels_&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;sil_c&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;silhouette_score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;candidate&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;named_steps&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;scaler&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labels_c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;best&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sil_c&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;best&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]):&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;best&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sil_c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;params&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Best by Silhouette:&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;round&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;best&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;best&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;執行結果&#34;&gt;執行結果&lt;/h3&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;k vs WCSS: [(2, 222.36), (3, 139.82), (4, 114.09), (5, 90.93), (6, 81.54), (7, 72.63)]&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;k vs Silhouette: [(2, 0.5818), (3, 0.4599), (4, 0.3869), (5, 0.3459), (6, 0.3171), (7, 0.3202)]&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Silhouette Score (k=3): 0.4599&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Adjusted Rand Index vs species (k=3): 0.6201&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;MiniBatchKMeans Silhouette (k=3): 0.4557&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Best by Silhouette: 0.5818 {&amp;#39;kmeans__n_clusters&amp;#39;: 2, &amp;#39;kmeans__n_init&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;結果評估&#34;&gt;結果評估&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;k 值與 WCSS (Elbow 法)&#xA;&lt;ul&gt;&#xA;&lt;li&gt;WCSS 從 k=2 到 k=7 持續下降，且在 k=3 後下降幅度明顯趨緩 (139.82 → 114.09 → 90.93)&lt;/li&gt;&#xA;&lt;li&gt;這符合 Elbow 法的典型訊號：在 k=3 之後邊際效益降低&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;k 值與 Silhouette Score&#xA;&lt;ul&gt;&#xA;&lt;li&gt;最高分在 k=2 (0.5818)，k=3 則下降至 0.4599，之後隨著 k 增加分數持續降低&lt;/li&gt;&#xA;&lt;li&gt;這意味著，若純粹以內部結構 (凝聚度與分離度) 來衡量，k=2 是最緊密且分離度最佳的分群方案&lt;/li&gt;&#xA;&lt;li&gt;但 Silhouette 只考慮幾何結構，不代表與實際業務需求或真實標籤完全對應&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;k=3 的分群表現&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Silhouette Score = 0.4599，屬於中等偏弱的群分離度，叢集邊界可能有交疊&lt;/li&gt;&#xA;&lt;li&gt;Adjusted Rand Index (ARI) = 0.6201：與真實 species 標籤有中等對齊程度，表示模型能部分復原真實物種結構，但錯分率仍顯著&lt;/li&gt;&#xA;&lt;li&gt;與 MiniBatchKMeans 相比，Silhouette 由 0.4599 降至 0.4557，效能損失不大，但 MiniBatch 在大資料場景下能顯著節省計算時間&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;參數搜尋結果&#xA;&lt;ul&gt;&#xA;&lt;li&gt;最佳 Silhouette 方案是 k=2, n_init=10 (0.5818)&lt;/li&gt;&#xA;&lt;li&gt;這與初步觀察一致，顯示在內部幾何結構下，Iris 資料更適合分成兩群，但這不符合三物種的領域先驗&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;結語&#34;&gt;結語&lt;/h2&gt;&#xA;&lt;p&gt;K-Means 在本篇範例中清楚展現了它作為無監督式分群基線的特性: 計算效率高、實作簡單、可快速提供初步的資料結構洞察。透過 Elbow 法與 Silhouette Score 的雙重分析，我們觀察到在 Iris 資料集上，幾何結構最佳的分群數為 k=2，而符合領域知識的 k=3 則在分群品質上略顯不足，顯示資料真實分佈與理想分群假設之間的落差。這種差異提醒我們，分群結果不能僅憑數學指標決定，還需結合業務目標與領域先驗做取捨。&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 15) 隨機森林 (Random Forest)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_15/</link>
      <pubDate>Fri, 15 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_15/</guid>
      <description>&lt;p&gt;隨機森林是以「多棵弱學習器 (決策樹)」為基底的集成學習 (Ensemble) 方法，透過資料抽樣 (Bagging) 與特徵隨機子抽樣 (Random Subspace)  降低單棵樹的方差與不穩定性。直覺上，它像是一群專家各自投票: 每位專家 (樹) 看見的資料與特徵都不完全相同，最後以多數決 (分類) 或平均 (回歸) 給出更穩健的預測。&lt;/p&gt;&#xA;&lt;h2 id=&#34;模型介紹&#34;&gt;模型介紹&lt;/h2&gt;&#xA;&lt;h3 id=&#34;模型邏輯與核心概念&#34;&gt;模型邏輯與核心概念&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Bagging (Bootstrap Aggregating): 對原始訓練集做 有放回抽樣，為每棵樹準備一份不同的訓練子集；未被抽到的樣本稱 OOB (Out-of-Bag)，可用來近似泛化誤差。&lt;/li&gt;&#xA;&lt;li&gt;隨機特徵子集 (max_features): 每個節點分裂時，僅在隨機抽出的特徵子集中尋找最佳分裂，打破樹之間的強相關，進一步降低方差。&lt;/li&gt;&#xA;&lt;li&gt;投票 / 平均: 分類任務以多數決投票；回歸任務取平均值。&lt;/li&gt;&#xA;&lt;li&gt;偏差—方差權衡: 相較單棵樹，隨機森林以增加偏差換取顯著降低方差，整體泛化表現通常更佳且更穩定。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;模型建構說明&#34;&gt;模型建構說明&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;基學習器: 通常使用未剪枝或淺剪枝的 DecisionTree(Classifier|Regressor)。&lt;/li&gt;&#xA;&lt;li&gt;訓練流程 (分類為例)&#xA;&lt;ul&gt;&#xA;&lt;li&gt;進行 B 次 bootstrap 抽樣，得到 B 個訓練子集；&lt;/li&gt;&#xA;&lt;li&gt;對於第 b 棵樹，每個節點僅在 max_features 個隨機特徵中找最佳分裂；&lt;/li&gt;&#xA;&lt;li&gt;訓練完成後，以 多數決 聚合各樹的預測；&lt;/li&gt;&#xA;&lt;li&gt;可用 OOB 樣本估計泛化表現 (oob_score_)。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;重要超參數 (分類)&#xA;&lt;ul&gt;&#xA;&lt;li&gt;n_estimators: 樹的數量 (越多越穩，但成本上升)&lt;/li&gt;&#xA;&lt;li&gt;max_depth、min_samples_leaf: 限制複雜度，抑制過擬合&lt;/li&gt;&#xA;&lt;li&gt;max_features: 每次分裂可用特徵數 (分類預設 sqrt(p) 常為穩健選擇)&lt;/li&gt;&#xA;&lt;li&gt;class_weight: 處理類別不平衡&lt;/li&gt;&#xA;&lt;li&gt;oob_score: 啟用 OOB 估計&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;模型優缺點&#34;&gt;模型優缺點&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;優點&lt;/th&gt;&#xA;          &lt;th&gt;缺點&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;對高維與雜訊相對穩健，較不易過擬合 (相對單樹)&lt;/td&gt;&#xA;          &lt;td&gt;訓練與推論成本高於單樹，難以極致壓縮&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;幾乎不需特徵縮放，能處理數值＋類別混合&lt;/td&gt;&#xA;          &lt;td&gt;全模型可解釋性較低 (可用特徵重要度、Permutation Importance 緩解)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;內建 OOB 評估、特徵重要度&lt;/td&gt;&#xA;          &lt;td&gt;對極度不平衡資料仍可能偏向多數類 (需調 class_weight 或重抽樣)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;易於平行化、對超參數敏感度相對低&lt;/td&gt;&#xA;          &lt;td&gt;單棵樹可視覺化但「整體」難以直觀解釋&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2 id=&#34;模型實作&#34;&gt;模型實作&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;seaborn&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sns&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;numpy&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;np&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train_test_split&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.compose&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ColumnTransformer&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.pipeline&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Pipeline&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.impute&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SimpleImputer&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.preprocessing&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;OneHotEncoder&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.ensemble&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;RandomForestClassifier&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;accuracy_score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;classification_report&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;roc_auc_score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;average_precision_score&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.inspection&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;permutation_importance&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# -----------------------------&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 1) 載入資料（無需外部檔案）&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# -----------------------------&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sns&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load_dataset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;titanic&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 2) 目標與特徵（seaborn titanic 欄位）&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;target&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;survived&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;num_features&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;age&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;fare&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;pclass&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;sibsp&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;parch&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;cat_features&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;sex&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;class&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;embarked&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;who&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;adult_male&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;alone&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;num_features&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cat_features&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;target&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;astype&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# -----------------------------&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 3) 前處理：數值補中位數、類別補眾數 + One-Hot&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# -----------------------------&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;numeric_transformer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Pipeline&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;steps&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;imputer&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SimpleImputer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;strategy&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;median&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;categorical_transformer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Pipeline&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;steps&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;imputer&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SimpleImputer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;strategy&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;most_frequent&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)),&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;onehot&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;OneHotEncoder&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;handle_unknown&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;ignore&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;preprocess&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ColumnTransformer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;transformers&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;num&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;numeric_transformer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;num_features&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;cat&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;categorical_transformer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cat_features&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# -----------------------------&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 4) 隨機森林模型&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# -----------------------------&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;rf&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;RandomForestClassifier&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;n_estimators&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;400&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;max_depth&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;min_samples_leaf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;max_features&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;sqrt&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;class_weight&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;balanced&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;   &lt;span class=&#34;c1&#34;&gt;# Titanic 類別略不平衡&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;oob_score&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;n_jobs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;random_state&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;42&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;pipe&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Pipeline&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;steps&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;preprocess&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;preprocess&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                      &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;model&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)])&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# -----------------------------&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 5) 切分資料與訓練&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# -----------------------------&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;X_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;X_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_test&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train_test_split&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;test_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stratify&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;random_state&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;42&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;pipe&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# -----------------------------&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 6) 評估指標&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# -----------------------------&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;y_pred&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pipe&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;predict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;y_proba&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pipe&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;predict_proba&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)[:,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Test Accuracy:&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;round&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;accuracy_score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_pred&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;classification_report&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_pred&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;digits&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;ROC-AUC:&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;round&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;roc_auc_score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_proba&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;PR-AUC (Average Precision):&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;round&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;average_precision_score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_proba&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;rf_model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pipe&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;named_steps&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;model&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;hasattr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rf_model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;oob_score_&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;OOB Score:&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;round&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rf_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;oob_score_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# -----------------------------&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 7) 取得「展開後特徵名」&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#    - 與模型看到的列數對齊，避免長度不一致錯誤&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# -----------------------------&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# One-Hot 展開後的類別名稱&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;ohe&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pipe&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;named_steps&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;preprocess&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;named_transformers_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;cat&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;named_steps&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;onehot&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;ohe_names&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;list&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ohe&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_feature_names_out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cat_features&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;all_feature_names&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;num_features&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ohe_names&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 與模型實際特徵數對齊（保險做法）&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;n_model_features&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rf_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_features_in_&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all_feature_names&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n_model_features&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# 若 ColumnTransformer 產生的欄位數與推定不一致（理論上不會），則切齊&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;all_feature_names&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;all_feature_names&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n_model_features&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# -----------------------------&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 8) 特徵重要度（MDI）&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# -----------------------------&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;mdi_importance&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;DataFrame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;({&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s2&#34;&gt;&amp;#34;feature&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;all_feature_names&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s2&#34;&gt;&amp;#34;importance&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rf_model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;feature_importances_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[:&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all_feature_names&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)]&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sort_values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;importance&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ascending&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;Top MDI Importances:&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mdi_importance&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_string&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# -----------------------------&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 9) Permutation Importance（在「前處理後特徵空間」計算）&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#    這樣 perm.importances_* 的長度就會與 all_feature_names 完全一致&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# -----------------------------&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;X_test_trans&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pipe&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;named_steps&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;preprocess&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 稀疏或稠密皆可&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;estimator&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pipe&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;named_steps&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;model&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 直接用 RF 在 transformed space 上做 PI&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;perm&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;permutation_importance&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;estimator&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;X_test_trans&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;n_repeats&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;random_state&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;42&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n_jobs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;perm_importance&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;DataFrame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;({&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s2&#34;&gt;&amp;#34;feature&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;all_feature_names&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s2&#34;&gt;&amp;#34;importance_mean&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;perm&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;importances_mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[:&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all_feature_names&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)],&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s2&#34;&gt;&amp;#34;importance_std&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;perm&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;importances_std&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[:&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all_feature_names&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)],&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sort_values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;importance_mean&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ascending&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;head&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;Top Permutation Importances (transformed space):&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;perm_importance&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_string&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;執行結果&#34;&gt;執行結果&lt;/h3&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Test Accuracy: 0.8324&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              precision    recall  f1-score   support&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           0     0.8509    0.8818    0.8661       110&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           1     0.8000    0.7536    0.7761        69&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    accuracy                         0.8324       179&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   macro avg     0.8254    0.8177    0.8211       179&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;weighted avg     0.8313    0.8324    0.8314       179&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ROC-AUC: 0.8515&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;PR-AUC (Average Precision): 0.8335&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;OOB Score: 0.8216&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Top MDI Importances:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         feature  importance&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            fare    0.194484&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;             age    0.145927&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;adult_male_False    0.115839&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; adult_male_True    0.080458&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      sex_female    0.075092&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         who_man    0.074631&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          pclass    0.047228&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        sex_male    0.046897&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           sibsp    0.037505&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     class_Third    0.035858&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;       who_woman    0.029911&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     class_First    0.025534&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           parch    0.022043&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      embarked_S    0.017173&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      embarked_C    0.011033&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    class_Second    0.010601&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     alone_False    0.009373&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      alone_True    0.007693&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      embarked_Q    0.006361&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;       who_child    0.006358&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Top Permutation Importances (transformed space):&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         feature  importance_mean  importance_std&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            fare         0.070950        0.013466&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;             age         0.031285        0.014823&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; adult_male_True         0.021788        0.008815&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;adult_male_False         0.021788        0.008815&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         who_man         0.021788        0.008815&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      embarked_S         0.012849        0.006634&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     class_Third         0.006145        0.008076&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      embarked_C         0.005587        0.002498&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        sex_male         0.005587        0.004327&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;       who_woman         0.005028        0.005833&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           sibsp         0.004469        0.007821&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      sex_female         0.003911        0.005028&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;       who_child         0.003352        0.003706&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           parch         0.002793        0.005151&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      embarked_Q         0.001676        0.003577&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          pclass        -0.000559        0.010133&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    class_Second        -0.004469        0.006017&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      alone_True        -0.005028        0.009497&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     class_First        -0.006704        0.008939&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     alone_False        -0.008939        0.008727&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;結果評估&#34;&gt;結果評估&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;整體表現&#xA;&lt;ul&gt;&#xA;&lt;li&gt;測試集 Accuracy=0.8324，相較於單棵決策樹的 0.8268 有小幅提升，且 ROC-AUC=0.8515、PR-AUC=0.8335 顯示模型在排序與正類預測能力上更穩定。OOB 分數 0.8216 與測試集表現接近，顯示隨機森林在控制方差與避免過擬合上運作正常。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;類別分析&#xA;&lt;ul&gt;&#xA;&lt;li&gt;負類 (未存活) Precision=0.8509、Recall=0.8818，正類 (存活) Precision=0.8000、Recall=0.7536，雖然正類召回率較單棵樹略高，但仍有 約 24.6% 的存活樣本被誤判為未存活，在成本敏感場景下 (漏抓正類成本高) 仍需改善。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;特徵重要度觀察&#xA;&lt;ul&gt;&#xA;&lt;li&gt;MDI (樹內部的 Gini 減少量): fare、age、adult_male_False/True、sex_female、who_man 是主要決策依據，且重要度分佈較單棵樹分散，顯示森林結構引入更多多樣化特徵分裂。&lt;/li&gt;&#xA;&lt;li&gt;Permutation Importance (泛化貢獻): fare 與 age 在測試集的實際貢獻最高，其餘特徵影響幅度顯著降低，甚至有部分特徵出現負值 (打亂該特徵反而略提升模型表現，代表該特徵在測試集可能引入雜訊)。這提醒我們 MDI 可能高估某些特徵的作用，需同時參考兩種方法做解讀。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;下一步建議&#34;&gt;下一步建議&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;提升正類召回率&#xA;&lt;ul&gt;&#xA;&lt;li&gt;調整決策閾值 (predict_proba 輸出)，在 Precision 與 Recall 間找到業務可接受的平衡。&lt;/li&gt;&#xA;&lt;li&gt;結合 class_weight 微調 (如 {0:1, 1:1.5}) 強化正類權重，觀察召回率與 FPR 的變化。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;進一步驗證特徵貢獻&#xA;&lt;ul&gt;&#xA;&lt;li&gt;對前五大特徵 (fare、age、adult_male、sex_female、who_man) 繪製 Partial Dependence Plot (PDP) 或 Individual Conditional Expectation (ICE)，檢查模型對特徵變化的響應是否符合邏輯與領域知識。&lt;/li&gt;&#xA;&lt;li&gt;移除 Permutation Importance 為負值的特徵，重新訓練模型，比較 AUC 與穩定性。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;模型穩定性檢驗&#xA;&lt;ul&gt;&#xA;&lt;li&gt;使用 Stratified K-Fold (k=5 或 10) 交叉驗證回報平均值與標準差，量化隨機森林在不同資料切分下的波動性。&lt;/li&gt;&#xA;&lt;li&gt;檢查 OOB 與交叉驗證分數的差距，確保模型泛化能力穩定。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;集成與對照實驗&#xA;&lt;ul&gt;&#xA;&lt;li&gt;與 Gradient Boosting (XGBoost、LightGBM、CatBoost) 比較，特別是在正類召回率與 PR-AUC 上的表現。&lt;/li&gt;&#xA;&lt;li&gt;若業務需求重視可解釋性，可建立 surrogate decision tree 模型近似隨機森林的決策邏輯，協助非技術人員理解。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;結語&#34;&gt;結語&lt;/h2&gt;&#xA;&lt;p&gt;隨機森林作為一種集成學習方法，在本篇示例中展現了穩健的泛化能力與優異的整體效能。透過 Bagging 與 隨機特徵子抽樣，它有效降低了單棵決策樹易受資料擾動影響的缺點，並減少了過擬合的風險。與單樹相比，隨機森林在測試集的 Accuracy、ROC-AUC、PR-AUC 及穩定性上皆有顯著提升，且 OOB 分數與測試表現接近，反映出其在實務環境中的可靠性。&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 14) 決策樹 (Decision Tree)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_14/</link>
      <pubDate>Thu, 14 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_14/</guid>
      <description>&lt;p&gt;Decision Tree 是一種基於條件分支的監督式學習模型，可用於分類與回歸任務。它透過一連串的「是/否」判斷，將資料不斷切分成更純淨的子集，最終形成一個由節點 (Nodes) 與邊 (Edges) 組成的樹狀結構。直覺上，你可以將它想成一連串的決策問句:「乘客的性別是女性嗎？」 → 是 → 「年齡是否小於 12 歲？」 → 是 → 存活機率高。其最大特色是 可解釋性高，每個決策規則都能清楚對應到特徵與閾值，便於與非技術背景的利害關係人溝通。&lt;/p&gt;&#xA;&lt;h2 id=&#34;模型介紹&#34;&gt;模型介紹&lt;/h2&gt;&#xA;&lt;h3 id=&#34;模型邏輯與核心概念&#34;&gt;模型邏輯與核心概念&lt;/h3&gt;&#xA;&lt;p&gt;決策樹 (Decision Tree) 是一種監督式學習演算法，可用於分類與回歸任務。模型的結構類似一棵樹，由節點 (Node) 與分支 (Branch) 組成&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;內部節點 (Internal Node):  表示一個特徵的條件判斷&lt;/li&gt;&#xA;&lt;li&gt;葉節點 (Leaf Node):  對應模型的預測結果 (類別或數值)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;建構過程是「貪婪式遞迴分割 (Greedy Recursive Splitting)」，根據資訊增益 (Information Gain) 最大或吉尼不純度 (Gini Impurity) 最小的原則進行&lt;/p&gt;&#xA;&lt;h4 id=&#34;模型建構說明&#34;&gt;模型建構說明&lt;/h4&gt;&#xA;&lt;p&gt;決策樹使用「貪婪演算法」建構模型，並無使用梯度下降類優化器，主要特徵:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;每次分裂僅考慮當前最佳特徵 (不做全局最優)&lt;/li&gt;&#xA;&lt;li&gt;使用遞迴方式構建整棵樹&lt;/li&gt;&#xA;&lt;li&gt;終止條件包括:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;節點樣本數過小&lt;/li&gt;&#xA;&lt;li&gt;不再能提升資訊增益&lt;/li&gt;&#xA;&lt;li&gt;最大深度限制&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;節點的特徵選擇:  每次分裂節點時，會從候選特徵中選出最佳分割特徵，其依據如下:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;DecisionTreeClassifier&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Information Gain&lt;/li&gt;&#xA;&lt;li&gt;Gini Impurity&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;DecisionTreeRegressor&#xA;&lt;ul&gt;&#xA;&lt;li&gt;MSE 減少量&lt;/li&gt;&#xA;&lt;li&gt;MAE 減少量&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;模型優缺點&#34;&gt;模型優缺點&lt;/h3&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;優點&lt;/th&gt;&#xA;          &lt;th&gt;缺點&lt;/th&gt;&#xA;          &lt;th&gt;&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;模型結構直觀，可視覺化&lt;/td&gt;&#xA;          &lt;td&gt;易過擬合，尤其是深樹&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;對特徵縮放不敏感 (不需標準化)&lt;/td&gt;&#xA;          &lt;td&gt;對資料擾動敏感 (小變化可能改變樹結構)&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;可處理數值與類別型特徵&lt;/td&gt;&#xA;          &lt;td&gt;單棵樹表現有限 (通常需配合集成方法如 Random Forest, XGBoost)&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;支援特徵重要性評估&lt;/td&gt;&#xA;          &lt;td&gt;分裂偏向多取值的特徵 (需調整)&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2 id=&#34;模型實作&#34;&gt;模型實作&lt;/h2&gt;&#xA;&lt;h3 id=&#34;程式實例&#34;&gt;程式實例&lt;/h3&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;plt&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train_test_split&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.tree&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;DecisionTreeClassifier&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;plot_tree&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 讀取資料&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read_csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;titanic.csv&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 特徵與標籤&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;features&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Pclass&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Sex&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Age&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Fare&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dropna&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;subset&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Age&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 簡單處理缺失值&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_dummies&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;features&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# One-Hot Encoding&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Survived&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 訓練 / 測試切分&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;X_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;X_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_test&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train_test_split&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;test_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;random_state&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;42&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 建立模型&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;clf&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;DecisionTreeClassifier&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;criterion&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;gini&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;max_depth&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;random_state&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;42&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;clf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 評估&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Accuracy: &amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;clf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 視覺化&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;figure&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;figsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;15&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;plot_tree&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;clf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;feature_names&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;class_names&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Not Survived&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;Survived&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;filled&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;show&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;執行結果&#34;&gt;執行結果&lt;/h3&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Test Accuracy:  0.8268&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;              precision    recall  f1-score   support&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           0     0.8319    0.9000    0.8646       110&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           1     0.8167    0.7101    0.7597        69&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    accuracy                         0.8268       179&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   macro avg     0.8243    0.8051    0.8122       179&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;weighted avg     0.8260    0.8268    0.8242       179&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Top Feature Importances: &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         feature  importance&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; adult_male_True    0.588332&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     class_Third    0.185393&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            fare    0.156906&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;             age    0.045641&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    class_Second    0.014194&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;           parch    0.009535&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      embarked_S    0.000000&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     alone_False    0.000000&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;adult_male_False    0.000000&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;       who_woman    0.000000&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;         who_man    0.000000&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;       who_child    0.000000&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      embarked_C    0.000000&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      embarked_Q    0.000000&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;     class_First    0.000000&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;結果評估&#34;&gt;結果評估&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;模型整體準確率尚可，但對「正類 (存活)」的 召回率僅 0.71，代表仍有 約 29% 的存活樣本被判成未存活；若你的業務目標重視「找出潛在存活 (或正類)」的能力，現況偏保守。&lt;/li&gt;&#xA;&lt;li&gt;對正類的錯失 (FN) 明顯多於將負類誤判為正類 (FP)。在成本敏感情境（例如「漏抓到的正類」代價更高）下，這是不理想的權衡。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;下一步建議&#34;&gt;下一步建議&lt;/h4&gt;&#xA;&lt;p&gt;我會先驗證的 6 件事:&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 13) 迴歸任務驗證指標</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_13/</link>
      <pubDate>Wed, 13 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_13/</guid>
      <description>&lt;p&gt;分類任務有混淆矩陣作為指標的核心基礎，迴歸任務則建立在誤差分佈 (Error Distribution) 之上。所有迴歸指標，都是在真實值與預測值的差異上進行數學運算。迴歸的評估相對分類簡單，沒有多種 TP、FP 的組合，但每個指標關注的面向、對異常值的敏感度、在商業決策上的意義卻各有不同。&lt;/p&gt;&#xA;&lt;h2 id=&#34;誤差的基本概念&#34;&gt;誤差的基本概念&lt;/h2&gt;&#xA;&lt;p&gt;回歸任務中，誤差 (Error) 定義為:&#xA;$$&#xA;e_i = y_i - \hat{y}_i&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;其中:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;$y_i$: 第 i 筆資料的真實值&lt;/li&gt;&#xA;&lt;li&gt;$\hat{y}_i$: 模型的預測值&lt;/li&gt;&#xA;&lt;li&gt;$e_i$: 第 i 筆的殘差 (Residual)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;所有回歸評估指標，都是將 $e_i$ 做數學運算後的結果。&lt;/p&gt;&#xA;&lt;h2 id=&#34;常見回歸驗證指標&#34;&gt;常見回歸驗證指標&lt;/h2&gt;&#xA;&lt;h3 id=&#34;mean-squared-error-mse&#34;&gt;Mean Squared Error (MSE)&lt;/h3&gt;&#xA;&lt;p&gt;將每個誤差平方後取平均。平方的動作會讓大誤差的影響成倍放大，因此 MSE 對異常值 (outlier) 非常敏感。&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;MSE = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;特性分析&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;誤差平方 → 大誤差懲罰重，小誤差影響相對被稀釋。&lt;/li&gt;&#xA;&lt;li&gt;單位為「原單位的平方」，如價格 (元) 預測的 MSE 單位是「元²」，因此不易直接解讀大小。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;優點&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;適合用在不能容忍大誤差的場景，例如財務風險控管 (預測錯 10 倍金額的後果極其嚴重)。&lt;/li&gt;&#xA;&lt;li&gt;在模型優化 (特別是最小平方法回歸) 中，MSE 作為損失函數具有良好數學性質 (平滑、可微分)。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;缺點&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 12) 多元分類任務驗證指標</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_12/</link>
      <pubDate>Tue, 12 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_12/</guid>
      <description>&lt;p&gt;多元分類任務驗證指標就只是從二元分類任務驗證指標延伸而來，核心概念一樣是二元分類任務驗證指標，而兩者只是在計算內容上有些許差異，所以指標仍然是 Accuracy、Recall、F1-score 等，所以請讀者先將二元分類任務驗證指標熟練後再來看。&lt;/p&gt;&#xA;&lt;h2 id=&#34;指標介紹&#34;&gt;指標介紹&lt;/h2&gt;&#xA;&lt;h3 id=&#34;混淆矩陣-confusion-matrix&#34;&gt;混淆矩陣 (Confusion Matrix)&lt;/h3&gt;&#xA;&lt;p&gt;假設我們有 3 個類別 [A, B, C]，模型的預測結果如下:&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;實際 \ 預測&lt;/th&gt;&#xA;          &lt;th&gt;A&lt;/th&gt;&#xA;          &lt;th&gt;B&lt;/th&gt;&#xA;          &lt;th&gt;C&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;A&lt;/td&gt;&#xA;          &lt;td&gt;50&lt;/td&gt;&#xA;          &lt;td&gt;2&lt;/td&gt;&#xA;          &lt;td&gt;3&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;B&lt;/td&gt;&#xA;          &lt;td&gt;4&lt;/td&gt;&#xA;          &lt;td&gt;45&lt;/td&gt;&#xA;          &lt;td&gt;1&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;C&lt;/td&gt;&#xA;          &lt;td&gt;5&lt;/td&gt;&#xA;          &lt;td&gt;2&lt;/td&gt;&#xA;          &lt;td&gt;43&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;列 (row) = 實際標籤&lt;/li&gt;&#xA;&lt;li&gt;行 (column) = 模型預測&lt;/li&gt;&#xA;&lt;li&gt;對角線 (50、45、43) = 預測正確的數量&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;從多元分類矩陣取出-tp--fp--fn--tn&#34;&gt;從多元分類矩陣取出 TP / FP / FN / TN&lt;/h3&gt;&#xA;&lt;p&gt;對單一類別 (One-vs-All)，例如要計算「類別 A」的指標:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;TP_A = 混淆矩陣中 A–A 的數字 = 50&lt;/li&gt;&#xA;&lt;li&gt;FP_A = 預測為 A 但實際不是 A 的數字總和 = 4 (B→A) + 5 (C→A) = 9&lt;/li&gt;&#xA;&lt;li&gt;FN_A = 實際為 A 但預測不是 A 的數字總和 = 2 (A→B) + 3 (A→C) = 5&lt;/li&gt;&#xA;&lt;li&gt;TN_A = 其他所有正確分類的數字 = 全部總數 - (TP_A + FP_A + FN_A)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;這樣每個類別都能得到對應的 TP、FP、FN、TN&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 11) 二元分類任務驗證指標</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_11/</link>
      <pubDate>Mon, 11 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_11/</guid>
      <description>&lt;p&gt;今天要介紹的是常見的分類任務驗證指標，會以二元分類問題為例，因為多元分類也是用相同的指標，只是計算方式會有所不同而已，預計會用 2-3 天的篇幅介紹完，分類與迴歸任務的驗證指標；先給各位讀者一個正確的觀念，選指標時必須回到業務背景與資料特性，不要迷信某個數值越高越好，真正有價值的模型評估，是能在技術表現與業務需求之間找到平衡。&lt;/p&gt;&#xA;&lt;h2 id=&#34;指標介紹&#34;&gt;指標介紹&lt;/h2&gt;&#xA;&lt;h3 id=&#34;混淆矩陣-confusion-matrix&#34;&gt;混淆矩陣 (Confusion Matrix)&lt;/h3&gt;&#xA;&lt;p&gt;分類任務的所有核心指標，幾乎都來自 Confusion Matrix，它是用來統計分類模型在測試集上的結果，Confusion Matrix 在 Binary Classification 問題上，它是一個 2x2 表格:&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;&lt;/th&gt;&#xA;          &lt;th&gt;True Condition - Positive&lt;/th&gt;&#xA;          &lt;th&gt;True Condition - Negative&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Predict Outcome - Positive&lt;/td&gt;&#xA;          &lt;td&gt;TP (True Positve)&lt;/td&gt;&#xA;          &lt;td&gt;FP (False Positve) (誤報)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Predict Outcome - Negative&lt;/td&gt;&#xA;          &lt;td&gt;FN (False Negative) (漏報)&lt;/td&gt;&#xA;          &lt;td&gt;TN (True Negative)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;TP: 實際是 Positive，模型也預測 Positive (預測正確)&lt;/li&gt;&#xA;&lt;li&gt;TN: 實際是 Negative，模型也預測 Negative (預測正確)&lt;/li&gt;&#xA;&lt;li&gt;FP: 實際是 Negative，但模型預測 Positive (誤報 / 假警報) (Type I error)&lt;/li&gt;&#xA;&lt;li&gt;FN: 實際是 Positive，但模型預測 Negative (漏報 / 漏檢) (Type II error)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;accuracy-準確率&#34;&gt;Accuracy (準確率)&lt;/h3&gt;&#xA;&lt;p&gt;$$&#xA;Accuracy = \frac{TP + TN}{TP + TN + FP + FN}&#xA;$$&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 10) 支援向量機 (Support Vector Machine)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_10/</link>
      <pubDate>Sun, 10 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_10/</guid>
      <description>&lt;p&gt;終於來到 SVM，這也是本系列介紹 Machine Learning 中分類演算法的最後一個，當然在機器學習中還有很多的監督式分類演算法，我個人認為相對沒我介紹的這幾個經典，就留給讀者自行學習。從明天開始到進入樹模型之前，我會補充一下，模型 Validation Index 的內容 (用來衡量模型結果好不好)，因為前面飆的有點快，後來有發現這部分也很重要，預計會花 2 ~ 3 天的篇幅來介紹。&lt;/p&gt;&#xA;&lt;p&gt;我們就進入正題，支援向量機 (Support Vector Machine) 是一種監督式學習演算法，泛指支援向量機演算法框架，透過在特徵空間中尋找最能分隔不同類別的超平面 (hyperplane)，並最大化分類邊界 (margin)，可應用於:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;分類 (Classification)&lt;/li&gt;&#xA;&lt;li&gt;回歸 (Regression)&lt;/li&gt;&#xA;&lt;li&gt;異常檢測 (Anomaly Detection)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;但是回歸的部分非常少用到 Support Vector Regression 本系列就不說明這塊；至於異常檢測的應用又稱 OneClass SVM 目前沒有規劃，這是一種無監督式學習的技術，專門在做 Anomaly Detection 的任務，因為本系列規劃在樹模型介紹完成後，會進入深度學習篇章，所以 OneClass SVM 的部分如果後續有篇幅的話會再補充，如果沒有也請讀者自行學習；所以本篇會以 SVM 應用在分類任務 (Support Vector Classification) 上來詳細說明。&lt;/p&gt;&#xA;&lt;h2 id=&#34;svm-解決了什麼問題&#34;&gt;SVM 解決了什麼問題?&lt;/h2&gt;&#xA;&lt;p&gt;在詳細介紹 SVM 之前，要先說明一下 SVM 到底要解決什麼問題，我們先回到 Day 5 介紹的 Logistic Regression，假設同一組數據做分類，可能會發生以下狀況，我們先看到 Logistic Regression 的部分，大家會發現看起來分類正確，但是那條線怎麼切得怪怪的，這也是 Logistic Regression 的問題，會造成模型泛化性不夠好，因為 Logistic Regression 對於這部分沒有進行處理。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/twcch/drive/raw/main/images/Image_2025-08-08_13-21-09.png&#34; alt=&#34;Image_2025-08-08_13-21-09.png&#34;&gt;&#xA;&lt;a href=&#34;https://b5031631512567.medium.com/logistic-regression-%E7%BE%85%E5%90%89%E6%96%AF%E5%9B%9E%E6%AD%B8-support-vector-machine-svm-%E5%81%9Aa-b%E5%88%86%E9%A1%9E-82aa5e5edaf8&#34;&gt;圖片來源: https://b5031631512567.medium.com/logistic-regression-羅吉斯回歸-support-vector-machine-svm-做a-b分類-82aa5e5edaf8&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 9) 樸素貝氏分類器 (Naive Bayes Classifier)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_9/</link>
      <pubDate>Sat, 09 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_9/</guid>
      <description>&lt;p&gt;前幾天的討論中，我們已經探討了迴歸分析、邏輯迴歸，以及最近兩天介紹的 K-Nearest Neighbors (KNN)。今天要討論的是另一種基礎且直覺性極強的分類演算法: 樸素貝氏分類器 (Naive Bayes Classifier)。儘管樸素貝氏分類器的基本原理非常簡單，甚至經常被視為基礎模型，但在實務應用中，它仍然是許多場合的首選，尤其是在文本分類領域，例如垃圾郵件分類與情感分析。&lt;/p&gt;&#xA;&lt;h2 id=&#34;模型介紹&#34;&gt;模型介紹&lt;/h2&gt;&#xA;&lt;h3 id=&#34;模型邏輯與核心概念&#34;&gt;模型邏輯與核心概念&lt;/h3&gt;&#xA;&lt;p&gt;Naive Bayes 的核心思想來自貝氏定理 (Bayes&amp;rsquo; Theorem):&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;P(y|X) = \frac{P(X|y)P(y)}{P(X)}&#xA;$$&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;$P(y|X)$: 在給定特徵 $X$ 下的目標 $y$ 的後驗機率 (posterior probability)&lt;/li&gt;&#xA;&lt;li&gt;$P(X|y)$: 在已知目標 $y$ 下觀察到特徵 $X$ 的可能性 (likelihood)&lt;/li&gt;&#xA;&lt;li&gt;$P(y)$: 目標 $y$ 的先驗機率 (prior probability)&lt;/li&gt;&#xA;&lt;li&gt;$P(X)$: 觀察到特徵 $X$ 的總體機率&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;但直接計算 $P(X|y)$ 是困難的，尤其當特徵數量龐大且互相關聯時。因此 Naive Bayes 做了一個極簡的假設——「條件獨立假設 (Conditional Independence Assumption)」，即假設特徵之間彼此獨立:&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;P(X|y) = P(x_1|y) \times P(x_2|y) \times \cdots \times P(x_n|y)&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;這個假設大幅簡化了問題，讓計算變得非常快速且易於實現。雖然這個假設在現實世界中往往不成立，但 Naive Bayes 的實務表現卻通常仍然相當穩健。&lt;/p&gt;&#xA;&lt;h4 id=&#34;naive-bayes-常見種類&#34;&gt;Naive Bayes 常見種類&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Gaussian Naive Bayes (高斯樸素貝氏): 假設特徵為連續數值，並服從高斯分布。&lt;/li&gt;&#xA;&lt;li&gt;Multinomial Naive Bayes (多項式樸素貝氏): 特別適用於文本數據，特徵通常為計數 (例如詞頻)。&lt;/li&gt;&#xA;&lt;li&gt;Bernoulli Naive Bayes (伯努利樸素貝氏): 特徵為二元變數 (例如詞的出現與否)。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;適用情境&#34;&gt;適用情境&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;特徵數量大且離散，尤其文本分類&lt;/li&gt;&#xA;&lt;li&gt;需要模型快速訓練與預測&lt;/li&gt;&#xA;&lt;li&gt;基準模型 (Baseline Model) 的建立&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;限制條件&#34;&gt;限制條件&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;特徵之間存在強烈相關性時，效果可能較差&lt;/li&gt;&#xA;&lt;li&gt;無法捕捉特徵之間的交互作用&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;模型實作&#34;&gt;模型實作&lt;/h2&gt;&#xA;&lt;p&gt;本次實作會以多項式 Naive Bayes 為例，因為它在文本分類中表現卓越，並且可展示 Naive Bayes 的強項: 速度快、表現穩定且容易理解。我們將使用經典的 SMS Spam Collection 資料集，透過 Naive Bayes 分辨垃圾訊息與正常訊息，這個過程就不過多敘述。&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 8) K-近鄰 (K-Nearest Neighbors)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_8/</link>
      <pubDate>Fri, 08 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_8/</guid>
      <description>&lt;p&gt;K-近鄰 (K-Nearest Neighbors; KNN) 是一種很直學的機器學習演算法。它沒有模型參數、沒有訓練過程，卻可以在某些任務上有不錯的效果。它的核心理念只有一句話: 「你是誰，由你周圍最像你的人決定」。&lt;/p&gt;&#xA;&lt;p&gt;K-近鄰的預測邏輯其實就是投票機制。當一筆新資料進來時，K-近鄰會計算它與訓練集中每一筆資料的距離，選出最近的 K 筆，根據這些鄰居的標籤來進行分類或回歸。&lt;/p&gt;&#xA;&lt;p&gt;舉個例子，如果你住進一個新的社區，而這個社區 5 戶人家中有 4 戶都是教師，那麼你很可能也被視為教師。這就是K-近鄰的基本邏輯：用「距離」定義相似度，用「投票」進行預測。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;無需訓練、實作簡單&lt;/li&gt;&#xA;&lt;li&gt;可處理多類別分類問題&lt;/li&gt;&#xA;&lt;li&gt;非常適合 baseline 模型或少量資料的場景&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;模型介紹&#34;&gt;模型介紹&lt;/h2&gt;&#xA;&lt;h3 id=&#34;模型邏輯與核心概念&#34;&gt;模型邏輯與核心概念&lt;/h3&gt;&#xA;&lt;h4 id=&#34;運作原理&#34;&gt;運作原理&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;定義距離度量: 最常見的是歐幾里得距離。&lt;/li&gt;&#xA;&lt;li&gt;標準化資料: 避免不同特徵尺度影響距離計算。&lt;/li&gt;&#xA;&lt;li&gt;選擇 K 值: K 值太小容易過擬合，太大容易欠擬合。&lt;/li&gt;&#xA;&lt;li&gt;查找最近鄰: 找出距離最近的 K 筆資料。&lt;/li&gt;&#xA;&lt;li&gt;分類或回歸: 分類就多數決，回歸就取平均。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;模型評估指標&#34;&gt;模型評估指標&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Accuracy: 整體正確率&lt;/li&gt;&#xA;&lt;li&gt;Precision / Recall / F1-score: 評估正例預測品質與召回&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;適用情境&#34;&gt;適用情境&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;資料量不大、特徵數量低的任務&lt;/li&gt;&#xA;&lt;li&gt;資料本身具備明顯群聚性質&lt;/li&gt;&#xA;&lt;li&gt;需要快速做出初步 baseline 的時候&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;限制條件&#34;&gt;限制條件&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;計算成本高 (尤其資料量大時)&lt;/li&gt;&#xA;&lt;li&gt;對資料標準化非常敏感&lt;/li&gt;&#xA;&lt;li&gt;高維度下效果會大幅下降 (維度災難)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;模型實作&#34;&gt;模型實作&lt;/h2&gt;&#xA;&lt;p&gt;這個 K-近鄰的案例，我們來聊聊簡單的操參數實驗，我們先準備一組資料，這個過程就不過多敘述。&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;numpy&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;np&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;plt&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;seaborn&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sns&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.datasets&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;make_classification&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train_test_split&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.preprocessing&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;StandardScaler&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.neighbors&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;KNeighborsClassifier&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;accuracy_score&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;classification_report&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cross_val_score&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 資料產生&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;make_classification&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;n_samples&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n_features&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n_informative&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n_redundant&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;n_clusters_per_class&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;class_sep&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;random_state&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;42&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 資料分割與標準化&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;X_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;X_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_test&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;train_test_split&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;test_size&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;random_state&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;42&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;scaler&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;StandardScaler&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;X_train_std&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;scaler&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit_transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;X_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在建模的部分就跟之前不一樣，而是在外層寫了一個迴圈，因為 K-近鄰的 K 值，沒有人知道要用多少，K=1 表示我只抓最近的一個來比，完全就沒有那種投票的概念，所以 k 不應該選 1，再來是怕有平票的問題所以 k 會以奇數為主，而且 k 如果太小會有個問題，容易過擬合，越小越準，那怎麼辦? 所以這邊搭配了 Cross Validation 做設計，可以避免這個問題 (Cross Validation 請讀者自行找資源學習)。&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 7) 回顧迴歸：從線性邏輯到學習本質</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_7/</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_7/</guid>
      <description>&lt;p&gt;前面 5 天我們聚焦於「回歸系列」模型: 線性迴歸 (Linear Regression)、多項式迴歸 (Polynomial Regression)、正則化迴歸 (Lasso / Ridge / ElasticNet Regression) 以及邏輯迴歸 (Logistic Regression)。雖然它們名稱上都掛著「Regression」，實則涵蓋了連續值預測與分類任務兩大主題。&lt;/p&gt;&#xA;&lt;p&gt;在正式進入其他學習範式前，我想透過這篇文章做一個小結，幫助讀者重新理解「迴歸模型的核心精神」，並進一步延伸思考「什麼是機器學習的學習」。&lt;/p&gt;&#xA;&lt;h2 id=&#34;迴歸模型統整與對比&#34;&gt;迴歸模型統整與對比&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;模型&lt;/th&gt;&#xA;          &lt;th&gt;任務類型&lt;/th&gt;&#xA;          &lt;th&gt;是否可擴展非線性&lt;/th&gt;&#xA;          &lt;th&gt;是否有正則化&lt;/th&gt;&#xA;          &lt;th&gt;適用場景&lt;/th&gt;&#xA;          &lt;th&gt;代表限制&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Linear Regression&lt;/td&gt;&#xA;          &lt;td&gt;迴歸&lt;/td&gt;&#xA;          &lt;td&gt;否&lt;/td&gt;&#xA;          &lt;td&gt;否&lt;/td&gt;&#xA;          &lt;td&gt;數據關係明確線性、特徵少時&lt;/td&gt;&#xA;          &lt;td&gt;對離群值、共線性敏感&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Polynomial Regression&lt;/td&gt;&#xA;          &lt;td&gt;迴歸&lt;/td&gt;&#xA;          &lt;td&gt;✅&lt;/td&gt;&#xA;          &lt;td&gt;否&lt;/td&gt;&#xA;          &lt;td&gt;存在非線性曲線關係時&lt;/td&gt;&#xA;          &lt;td&gt;過度擬合風險高&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Lasso / Ridge / ElasticNet&lt;/td&gt;&#xA;          &lt;td&gt;迴歸&lt;/td&gt;&#xA;          &lt;td&gt;✅&lt;/td&gt;&#xA;          &lt;td&gt;✅&lt;/td&gt;&#xA;          &lt;td&gt;高維度資料、需特徵選擇時&lt;/td&gt;&#xA;          &lt;td&gt;模型可解釋性略減&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Logistic Regression&lt;/td&gt;&#xA;          &lt;td&gt;分類&lt;/td&gt;&#xA;          &lt;td&gt;否&lt;/td&gt;&#xA;          &lt;td&gt;✅ (可搭配)&lt;/td&gt;&#xA;          &lt;td&gt;二元分類、機率預測、可解釋性要求高場景&lt;/td&gt;&#xA;          &lt;td&gt;不適合複雜非線性邊界&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;這四種模型本質上都假設資料可以被一個「參數化的函數」所建模，且可以透過某種「最小化損失」的方式來進行學習。而這種最小化行為，正是機器學習中最常見的學習模式: 梯度下降法 (Gradient Descent)。&lt;/p&gt;&#xA;&lt;h2 id=&#34;為什麼梯度下降能學習&#34;&gt;為什麼梯度下降能「學習」?&lt;/h2&gt;&#xA;&lt;p&gt;這是一個我自己也還在思考的問題。梯度下降看似只是數學上的最小化技巧，但其實它蘊含了學習的邏輯核心: 錯誤導向的自我修正。&lt;/p&gt;&#xA;&lt;p&gt;每一次模型的預測錯了，就利用這個錯誤的方向與程度，去修正模型的參數，使下一次預測更好。這種機制背後隱含的三個條件，值得特別點出:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;✅ 存在可微分的損失函數&lt;/li&gt;&#xA;&lt;li&gt;✅ 模型是參數化的 (parameters 可調整)&lt;/li&gt;&#xA;&lt;li&gt;✅ 可以反覆試誤 (迭代優化)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;符合上述條件，模型便可以「學習」。也正因如此，這四個回歸模型雖然類型不同 (分類 / 迴歸)、形式不同 (線性 / 非線性 / 正則化)，但都共享「透過梯度下降調整參數」這一關鍵本質。&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 6) 邏輯迴歸 (多項式 &#43; 正規化)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_6/</link>
      <pubDate>Wed, 06 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_6/</guid>
      <description>&lt;p&gt;在上一篇中，我們深入介紹了邏輯迴歸的模型邏輯、損失函數與分類行為。這篇則要進一步延伸這個經典模型，回答一個關鍵問題: 邏輯迴歸能否結合多項式特徵與正規化機制，來對抗非線性與過擬合問題?&lt;/p&gt;&#xA;&lt;p&gt;在實務中，這樣的需求非常常見，但你可能很少看到「多項式邏輯迴歸」或「正規化邏輯迴歸」這樣的說法。雖然命名不常見，但本質上邏輯迴歸完全可以與這兩個技巧結合使用，而且這種搭配在複雜資料下是極具威力的實務技巧。&lt;/p&gt;&#xA;&lt;h2 id=&#34;為什麼邏輯迴歸可以搭配多項式與正規化&#34;&gt;為什麼邏輯迴歸可以搭配多項式與正規化?&lt;/h2&gt;&#xA;&lt;h3 id=&#34;邏輯迴歸其實是線性模型&#34;&gt;邏輯迴歸其實是線性模型&lt;/h3&gt;&#xA;&lt;p&gt;邏輯迴歸雖然應用在分類任務f，但本質仍是一種「線性模型」:&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;\hat{y} = \sigma(\beta_0 + \mathbf{x}^\top \boldsymbol{\beta})&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;這表示它只能建構一條線性的 decision boundary。當你的資料本身具有非線性邊界時，例如 XOR 類型的資料，這條邏輯迴歸線就顯得力不從心。&lt;/p&gt;&#xA;&lt;p&gt;解法之一，就是在原始特徵上做多項式擴展 (Polynomial Feature Expansion)——也就是增加特徵空間的非線性組合，例如 $x_1^2$、$x_1 \cdot x_2$ 等，來幫助模型在更高維度中建立線性可分的邊界。&lt;/p&gt;&#xA;&lt;p&gt;這與之前我們在線性迴歸所談的邏輯迴歸原理一樣，只是這次應用在分類問題中。&lt;/p&gt;&#xA;&lt;h3 id=&#34;邏輯迴歸也容易過擬合&#34;&gt;邏輯迴歸也容易過擬合&lt;/h3&gt;&#xA;&lt;p&gt;一旦你使用多項式特徵，特徵數暴增，就可能發生過擬合，這時就需要正規化 (Regularization) 機制來抑制模型複雜度。&lt;/p&gt;&#xA;&lt;p&gt;與 Linear Regression 一樣，邏輯迴歸可以透過 L1 或 L2 懲罰項達到正規化的目的:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;L2 (Ridge): 抑制權重值變得太大&lt;/li&gt;&#xA;&lt;li&gt;L1 (Lasso): 推動部分權重變為 0，具有特徵選擇效果&lt;/li&gt;&#xA;&lt;li&gt;Elastic Net: L1 + L2 混合調整&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;值得注意的是，在 PyTorch 中，optimizer 的 weight_decay 只對應 L2，若要做 L1，則需自行加上額外的懲罰項。&lt;/p&gt;&#xA;&lt;h2 id=&#34;模型實作&#34;&gt;模型實作&lt;/h2&gt;&#xA;&lt;p&gt;這個案例也一樣，使用 PyTorch 來實現，透過這段程式碼來窺探 Logistic Regression 的細節。但是還是要再次聲明一下，不論是機器學習演算法，還是說什麼排序的那些算法，你自己寫的打概率打不過這種主流套件做出來的方法，因為這些方法可能經過 10 幾年以上的迭代，不斷地維護與優化產生的，所以如果是學習的話可以自己做，但是正式要使用的話還是建議直接用這些現成的方法，表現往往更加優秀。&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 5) 邏輯迴歸 (Logistic Regression)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_5/</link>
      <pubDate>Tue, 05 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_5/</guid>
      <description>&lt;p&gt;邏輯迴歸 (Logistic Regression) 是一種常見的分類模型，主要用於預測二元分類或多元分類，有別於先前的線性迴歸是用來預測無邊界的連數據值，而邏輯迴歸間單來說就是預測有邊界的不連續數值，如 [0, 1], [1, 2, 3]。&lt;/p&gt;&#xA;&lt;h2 id=&#34;模型介紹&#34;&gt;模型介紹&lt;/h2&gt;&#xA;&lt;h3 id=&#34;模型邏輯與核心概念&#34;&gt;模型邏輯與核心概念&lt;/h3&gt;&#xA;&lt;p&gt;那邏輯回歸是如何運作? 其實不論是哪種邏輯迴歸，底層都是先透過線性迴歸來預測，只是分別透過不同的激活函數與損失函數來處理，但是邏輯迴歸一般來說還是比較常用於二元分類，來看看以下流程:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;假設有一條線性迴歸方程式: $\hat{y} = \beta_0 + \mathbf{x}^\top \boldsymbol{\beta}$。(注意: 這條不是最佳的線性迴歸線)&lt;/li&gt;&#xA;&lt;li&gt;會針對前述的線性迴歸方程式結果，透過 sigmoid 函數，將結果轉換成 [0, 1]&lt;/li&gt;&#xA;&lt;li&gt;假設損失函數 (Cost Function): Binary Cross Entropy&lt;/li&gt;&#xA;&lt;li&gt;最後使用梯度下降 (Batch Gradient Descent) 來最小化損失函數，找出最佳的邏輯迴歸線&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;以上就是二元分類邏輯迴歸的原理，那麼我們來看看多元分類邏輯迴歸是如何處理&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;假設有一條線性迴歸方程式: $\hat{y} = \beta_0 + \mathbf{x}^\top \boldsymbol{\beta}$。(注意: 這條不是最佳的線性迴歸線)&lt;/li&gt;&#xA;&lt;li&gt;會針對前述的線性迴歸方程式結果，透過 softmax 函數，將結果轉換成機率總和為 1 的組合&lt;/li&gt;&#xA;&lt;li&gt;假設損失函數 (Cost Function): Categorical Cross Entropy&lt;/li&gt;&#xA;&lt;li&gt;最後使用梯度下降 (Batch Gradient Descent) 來最小化損失函數，找出最佳的邏輯迴歸線&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;可以看出不同的邏輯迴歸，只是分別透過不同的激活函數與損失函數來處理，雖然邏輯迴歸可以用於多元分類，但是一般來說還是比較常用於二元分類。&lt;/p&gt;&#xA;&lt;h4 id=&#34;模型評估指標&#34;&gt;模型評估指標&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Accuracy: 整體正確率&lt;/li&gt;&#xA;&lt;li&gt;Precision / Recall / F1-score: 評估正例預測品質與召回&lt;/li&gt;&#xA;&lt;li&gt;ROC-AUC: 考量不同閾值下模型分類能力&lt;/li&gt;&#xA;&lt;li&gt;Confusion Matrix: TP、TN、FP、FN 分佈&lt;/li&gt;&#xA;&lt;li&gt;Log Loss: 概率預測與實際標籤差異&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;適用情境&#34;&gt;適用情境&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Target 為二元分類 (0/1、是/否) 或多元分類&lt;/li&gt;&#xA;&lt;li&gt;需要同時獲得概率估計與可解釋性&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;限制條件&#34;&gt;限制條件&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;多重共線性: 高度相關特徵會影響係數穩定性&lt;/li&gt;&#xA;&lt;li&gt;極端值敏感: 離群點可能顯著扭曲模型&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;模型實作&#34;&gt;模型實作&lt;/h2&gt;&#xA;&lt;p&gt;這個案例開始為了讓讀者有更好的感覺模型的過程，會分別使用 sklearn 與 PyTorch 來建模。但是必須先聲明，無論是手動撰寫或是透過 PyTorch 來模擬出來，都不一定有辦法比 sklearn 提供的演算法來得更優秀，所以除非有特殊目的，否則使用 sklearn 提供的演算法效能與準確性都會較高。&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 4) 正規化迴歸 (Regularization Regression)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_4/</link>
      <pubDate>Mon, 04 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_4/</guid>
      <description>&lt;p&gt;延續昨日的多項式迴歸中，我們觀察到一個現象: 雖然二次特徵提升了模型的表現，但同時也引入過擬合 (Overfitting) 風險。這是因為當特徵數量暴增，模型就會變得過於「貪婪」，試圖將每個資料點都擬合得極好，結果反而喪失了在新資料上的泛化 (Generalization) 能力。&lt;/p&gt;&#xA;&lt;p&gt;那怎麼辦? 就是在多項式迴歸的基礎上，限制模型的自由度，也就是今天要介紹的——正則化回歸 (Regularized Regression)。&lt;/p&gt;&#xA;&lt;p&gt;這是一種透過在模型參數加上限制，以提升泛化能力 (該操作並非為了提高準確度)，讓它在「解釋資料」與「控制複雜度」間取得平衡。最常見的三種正則化技術分別為:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;套索回歸 (Lasso Regression): L1 Normalization&lt;/li&gt;&#xA;&lt;li&gt;脊回歸 (Ridge Regression): L2 Normalization&lt;/li&gt;&#xA;&lt;li&gt;Elastic Net Regression: L1 + L2 Normalization&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;模型介紹&#34;&gt;模型介紹&lt;/h2&gt;&#xA;&lt;h3 id=&#34;模型邏輯與核心概念&#34;&gt;模型邏輯與核心概念&lt;/h3&gt;&#xA;&lt;p&gt;先回到 Day 2 的線性迴歸，線性迴歸如何找出最佳的迴歸線?&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;先設定損失函數 (Cost Function) 假設為 $MSE = \frac{1}{2n} \sum\limits_{i=1}^{n} (y_{i} - \hat{y}_{i})^{2}$。&lt;/li&gt;&#xA;&lt;li&gt;再使用梯度下降 (Batch Gradient Descent) 來最小化損失函數。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;而所謂的正規化迴歸就是在損失函數加上懲罰項，而前述那些不同的正規化迴歸名稱，就只是懲罰項的差異而已，以下是正規化迴歸的懲罰項:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;套索迴歸: $\lambda \sum |\beta_i|$&lt;/li&gt;&#xA;&lt;li&gt;脊迴歸: $\lambda \sum \beta_i^2$&lt;/li&gt;&#xA;&lt;li&gt;Elastic Net Regression: $\lambda_1 \sum |\beta_i| + \lambda_2 \sum \beta_i^2$&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;我們先來看看這幾種正規化的效果差異:&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 3) 多項式迴歸 (Polynomial Regression)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_3/</link>
      <pubDate>Sun, 03 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_3/</guid>
      <description>&lt;p&gt;昨天介紹了線性迴歸 (Linear Regression)，它適合用來處理特徵與目標之間為線性關係的情境。然而，真實世界的資料往往並非純粹線性，而是呈現複雜的非線性關係，例如曲線、拋物線、甚至更複雜的波動趨勢。&lt;/p&gt;&#xA;&lt;p&gt;就有了多項式特徵 (Polynomial Feature) 的出現，而線性迴歸搭配多項式特徵，就是所謂的多項式迴歸 (Polynomial Regression)，便是為了解決線性模型難以處理的非線性問題。它的核心概念非常簡單就是透過對特徵進行多項式轉換，使模型能夠捕捉非線性趨勢。&lt;/p&gt;&#xA;&lt;h2 id=&#34;模型介紹&#34;&gt;模型介紹&lt;/h2&gt;&#xA;&lt;h3 id=&#34;模型邏輯與核心概念&#34;&gt;模型邏輯與核心概念&lt;/h3&gt;&#xA;&lt;p&gt;這塊幾乎與昨天介紹的線性迴歸一樣，重複的部分就不多做介紹。因為多項式迴歸本質上仍是線性迴歸，但特徵空間經過非線性轉換，讓模型能擬合更複雜的曲線。以下為多項式迴歸的公式:&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;\hat{y} = \beta_0 + \beta_1 x + \beta_2 x^2 + \dots + \beta_d x^d&#xA;$$&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;d 稱為 polynomial degree (多項式階數)，是模型中最重要的超參數之一。&lt;/li&gt;&#xA;&lt;li&gt;特徵不只可以加入單一變數的高次項，也可加入多個變數間的交互項 (例如 $x_1x_2$)。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;運作原理&#34;&gt;運作原理&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;假設方程式 (degree = 3): $\hat{y} = \beta_0 + \beta_1 x + \beta_2 x^2 + \beta_3 x^3$&#xA;&lt;ul&gt;&#xA;&lt;li&gt;透過將輸入特徵 $x$ 映射為高階次多項式 (如 $x^2, x^3, \dots$)，使模型能擬合彎曲或非線性趨勢，特徵會經過變換形成新的變數，然後再應用一般線性回歸模型進行估計。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;degree = 3 (對所有 features 做所有「總次數 ≤ 3」的項次組合)&#xA;&lt;ul&gt;&#xA;&lt;li&gt;多項式特徵的處理會產生新的特徵&lt;/li&gt;&#xA;&lt;li&gt;要特別注意，如果在特徵工程有人工建立交互項，不可直接使用 PolynomialFeatures 來處理，因為不會辨識你手動做出的交互項，會產生重複或邏輯不一致的問題，要特別處理。&#xA;&lt;ul&gt;&#xA;&lt;li&gt;舉例: 假設有一組資料，特徵有 [&amp;lsquo;x1&amp;rsquo;, &amp;lsquo;x2&amp;rsquo;]，設定 degree=3 做 PolynomialFeatures，這組資料的特徵會變成 [&amp;lsquo;x1&amp;rsquo;, &amp;lsquo;x2&amp;rsquo;, &amp;lsquo;x1^2&amp;rsquo;, &amp;lsquo;x1 x2&amp;rsquo;, &amp;lsquo;x2^2&amp;rsquo;, &amp;lsquo;x1^3&amp;rsquo;, &amp;lsquo;x1^2 x2&amp;rsquo;, &amp;lsquo;x1 x2^2&amp;rsquo;, &amp;lsquo;x2^3&amp;rsquo;]，他會自動做交互項處理，如果有手動生成交互項就不能再做 PolynomialFeatures&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;適用情境&#34;&gt;適用情境&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;當資料呈現曲線趨勢時，線性回歸無法捕捉其變化&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;限制條件&#34;&gt;限制條件&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;degree 過高，容易導致 Overfitting (尤其在資料量小時)&lt;/li&gt;&#xA;&lt;li&gt;高維度下容易產生特徵爆炸&lt;/li&gt;&#xA;&lt;li&gt;對比 Linear Regression 其模型可解釋性下降&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;模型實作&#34;&gt;模型實作&lt;/h2&gt;&#xA;&lt;h3 id=&#34;資料集介紹&#34;&gt;資料集介紹&lt;/h3&gt;&#xA;&lt;p&gt;將使用經典的 Boston Housing Dataset 為例。由於 scikit-learn 已移除該資料集，我們改採自 Carnegie Mellon University 所提供的公開版本。樣本內容如下:&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 2) 線性迴歸 (Linear Regression)</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_2/</link>
      <pubDate>Sat, 02 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_2/</guid>
      <description>&lt;p&gt;線性迴歸 (Linear Regression) 是統計學中的一種預測方法，主要分為簡單線性迴歸 (Simple Linear Regression) 與多元線性迴歸 (Multiple Linear Regression)，又稱複迴歸，以及其他變形的迴歸等，但在線性迴歸中，通常會有 1~N 個自變數 (Independent Variable) X，也可以稱作特徵 (Feature)；和 1 個因變數 (Dependent Variable) Y，也可以稱作目標 (Target)。而最終目的就是找出一條最佳迴歸線，來擬合這些數據點，便可以用來預測未來的數據點。&lt;/p&gt;&#xA;&lt;h2 id=&#34;模型介紹&#34;&gt;模型介紹&lt;/h2&gt;&#xA;&lt;h3 id=&#34;模型邏輯與核心概念&#34;&gt;模型邏輯與核心概念&lt;/h3&gt;&#xA;&lt;h4 id=&#34;線性迴歸假設&#34;&gt;線性迴歸假設&lt;/h4&gt;&#xA;&lt;p&gt;統計學線性迴歸的經典的五大假設:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;線性關係: 自變數與因變數之間存在線性關係&lt;/li&gt;&#xA;&lt;li&gt;誤差項獨立 (Independence): 誤差項之間沒有相互關係&lt;/li&gt;&#xA;&lt;li&gt;同標準差性 (Homoscedasticity): 對於所有的自變數，誤差項具有相同的標準差&lt;/li&gt;&#xA;&lt;li&gt;誤差項常態性 (Normality of Errors): 誤差項應該成常態分佈&lt;/li&gt;&#xA;&lt;li&gt;高度共線性 (Multicollinearity): 自變數間無高度線性相關&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;看到這邊會想說，為什麼要特別註明統計學? 跟機器學習無關? 先記住一句話「統計學重推論，機器學習重預測」，很多假設跟機器學習中的線性迴歸模型還真的沒有太大的關係，但是也不代表，機器學習模型完全沒有假設，但是相對比較不重要，這也是為什麼很多仿間的機器學習教材都會忽略假設這塊。&lt;/p&gt;&#xA;&lt;p&gt;總而言之，機器學習模型不像統計學模型需要那麼嚴謹的假設，但是若違反某些假設，也是會影響機器學習模型的表現，也會使得模型只能用於預測，無法用於推論，以下簡單整理假設對統計模型與機器學習模型的影響:&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;假設&lt;/th&gt;&#xA;          &lt;th&gt;對傳統統計模型影響&lt;/th&gt;&#xA;          &lt;th&gt;對機器學習影響&lt;/th&gt;&#xA;          &lt;th&gt;建議處理方式&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;線性關係&lt;/td&gt;&#xA;          &lt;td&gt;✅ 極高 (核心假設)&lt;/td&gt;&#xA;          &lt;td&gt;❌ 可忽略 (可透過特徵轉換處理)&lt;/td&gt;&#xA;          &lt;td&gt;用非線性模型 / 特徵轉換&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;誤差獨立性&lt;/td&gt;&#xA;          &lt;td&gt;✅ 高 (推論與解釋需此條件支持)&lt;/td&gt;&#xA;          &lt;td&gt;✅ 高 (對 generalization 有直接影響)&lt;/td&gt;&#xA;          &lt;td&gt;使用適當資料分割策略&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;同變異性&lt;/td&gt;&#xA;          &lt;td&gt;✅ 中高 (影響參數估計的信度)&lt;/td&gt;&#xA;          &lt;td&gt;❌ 可忽略 (模型的估計值仍然準，但 p-value、CI 失真)&lt;/td&gt;&#xA;          &lt;td&gt;變數轉換、加權最小平方法&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;誤差常態性&lt;/td&gt;&#xA;          &lt;td&gt;✅ 中高 (特定推論工具須常態性支持)&lt;/td&gt;&#xA;          &lt;td&gt;❌ 可忽略&lt;/td&gt;&#xA;          &lt;td&gt;若僅做預測可忽略&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;共線性&lt;/td&gt;&#xA;          &lt;td&gt;✅ 高 (嚴重影響模型可解釋性與推論)&lt;/td&gt;&#xA;          &lt;td&gt;❌ 可忽略 (但建議修正以利解釋)&lt;/td&gt;&#xA;          &lt;td&gt;VIF、降維、正則化&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h4 id=&#34;運作原理&#34;&gt;運作原理&lt;/h4&gt;&#xA;&lt;p&gt;我們先回到線性迴歸的用途與目的，簡單來說就是「找出一條最佳直線，來擬合這些數據點，便可以用來預測未來的數據點」，如何找出最佳直線? 本文會簡單的介紹一下，詳細過程與原理，再請讀者自行尋找其他資源暸解。&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 1) 介紹與準備</title>
      <link>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_1/</link>
      <pubDate>Fri, 01 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/column_articles/ironman_2025/30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/ironman_25_1_1/</guid>
      <description>&lt;p&gt;在學習機器學習 (Machine Learning) 的過程中，可能會陷入兩種極端，一種是只會調用套件 (套模)，模型背後的機制一知半解，遇到問題只能「換模型試試看」，或者是過度陷入數學細節，花大量時間推導公式，卻無法轉化為實際應用與模型選擇能力。&lt;/p&gt;&#xA;&lt;p&gt;我本身是從商業分析背景轉入人工智慧領域的研究者。這段轉型過程中，逐漸體會到: 真正困難的不是學會用模型，而是理解模型為什麼有效、什麼時候該用、什麼時候該換、用了之後該觀察什麼訊號。這促使我開始重新梳理各類常見演算法的行為與應用邏輯。&lt;/p&gt;&#xA;&lt;p&gt;因此，我決定透過這次 iThome 鐵人賽的機會，整理與統整常見演算法的核心概念，並將每一篇視為一場與模型的深度對談。&lt;/p&gt;&#xA;&lt;h2 id=&#34;系列架構說明&#34;&gt;系列架構說明&lt;/h2&gt;&#xA;&lt;p&gt;本系列分為兩大部分:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;經典機器學習模型: 聚焦於 Regression、Classification、Clustering 等常見方法，強調模型背後的核心邏輯、適用情境與評估指標。&lt;/li&gt;&#xA;&lt;li&gt;深度學習模型: 介紹常見神經網路架構，如全連接神經網路 (FCNN)、CNN、RNN、Transformer 等，並探討它們對資料型態、任務種類的適應性與限制。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;每篇文章皆會包含模型概念說明與簡潔的 Python 範例實作，並聚焦於模型本身的行為與選擇策略，不深入探討資料前處理、特徵工程、模型調參、數學推導等高階內容，以避免模糊焦點。&lt;/p&gt;&#xA;&lt;h2 id=&#34;技術範圍與預期對象&#34;&gt;技術範圍與預期對象&lt;/h2&gt;&#xA;&lt;p&gt;本系列預設讀者已具備以下條件:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;具備基礎統計學與資料科學知識&lt;/li&gt;&#xA;&lt;li&gt;具備基本 Python 語法能力&lt;/li&gt;&#xA;&lt;li&gt;具備 scikit-learn, PyTorch, TensorFlow, Keras 基本建模流程&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;學習深度定位-聚焦在-level-23-之間&#34;&gt;學習深度定位: 聚焦在 Level 2–3 之間&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;等級&lt;/th&gt;&#xA;          &lt;th&gt;定義&lt;/th&gt;&#xA;          &lt;th&gt;在本系列的實踐目標&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Level 1&lt;/td&gt;&#xA;          &lt;td&gt;會用套件建模&lt;/td&gt;&#xA;          &lt;td&gt;✅ 使用 sklearn 等工具快速建模&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Level 2&lt;/td&gt;&#xA;          &lt;td&gt;理解模型的概念與原理&lt;/td&gt;&#xA;          &lt;td&gt;✅ 說得出每個模型的邏輯與核心機制&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Level 3&lt;/td&gt;&#xA;          &lt;td&gt;能比較模型優劣與應用場景選擇&lt;/td&gt;&#xA;          &lt;td&gt;✅ 理解適用時機、模型之間的 trade-off&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Level 4+&lt;/td&gt;&#xA;          &lt;td&gt;深入優化與理論推導&lt;/td&gt;&#xA;          &lt;td&gt;🚫 本系列不會深入涵蓋，建議另尋高階資源&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2 id=&#34;系列預告與進展節奏&#34;&gt;系列預告與進展節奏&lt;/h2&gt;&#xA;&lt;p&gt;本系列將以「一日一模型」為目標，每篇聚焦於一個經典或常見模型，從實用視角出發說明其:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;核心邏輯與設計理念&lt;/li&gt;&#xA;&lt;li&gt;適用情境與限制條件&lt;/li&gt;&#xA;&lt;li&gt;與其他模型的比較與選擇策略&lt;/li&gt;&#xA;&lt;li&gt;Python 範例實作與評估觀察&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;預計涵蓋模型範圍包括: Linear Regression、Polynomial Regression、Logistic Regression、SVM、KNN、Decision Tree、Random Forest、XGBoost、PCA、KMeans、FCNN、CNN、RNN、Transformer &amp;hellip; 等。&lt;/p&gt;</description>
    </item>
    <item>
      <title>學歷無用: 我仍相信學習的價值</title>
      <link>http://twcch.io/posts/2025/articles_25071601/</link>
      <pubDate>Wed, 16 Jul 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/2025/articles_25071601/</guid>
      <description>&lt;p&gt;近年來，我觀察到無論在台灣還是中國，「學歷無用論」的聲音愈發強烈。許多人開始質疑讀書是否還有意義，認為不靠學歷反而更能致富，網紅、直播、投資客、白手起家的商人充斥版面，讀書人反倒被視為落後者、被剝削者、社會規訓的犧牲品，但我有不同的看法。&lt;/p&gt;&#xA;&lt;h2 id=&#34;為什麼學歷無用論會出現&#34;&gt;為什麼「學歷無用論」會出現？&lt;/h2&gt;&#xA;&lt;p&gt;我認為這不是單純的個人選擇，而是結構性問題:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;教育擴張讓學歷貶值，碩博士已成基本門檻&lt;/li&gt;&#xA;&lt;li&gt;階級複製讓弱勢者難以翻身，「努力不再保證回報」&lt;/li&gt;&#xA;&lt;li&gt;高回報的機會集中在少數風口行業，炒短線者當道&lt;/li&gt;&#xA;&lt;li&gt;社群媒體製造「一夜暴富」神話，反智氛圍蔓延&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;「讀書沒用」已經不只是判斷，更是一種情緒&lt;strong&gt;對制度失望、對未來無感、對努力失信&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;h2 id=&#34;那讀書究竟還有沒有價值&#34;&gt;那讀書究竟還有沒有價值?&lt;/h2&gt;&#xA;&lt;p&gt;如果只探討「賺多少錢」作為唯一標準，那的確讀書沒有用，因為讀書不一定有最即時的回報。但若把時間尺度拉長、把價值層次拉高，會發現：「學習不是為了立刻賺錢，而是為了讓你能夠分辨真偽、建立邏輯、理解世界、保有尊嚴地思考與行動」。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;工具層面: 讓你擁有專業能力，立足於社會&lt;/li&gt;&#xA;&lt;li&gt;認知層面: 訓練你思辨、整合、表達的能力&lt;/li&gt;&#xA;&lt;li&gt;存在層面: 引導你認識自己、世界與人生的關係&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;簡單來說，我 30 年的人生觀告訴我，讀書可以讓我的境界提升，能夠自我昇華&lt;/p&gt;&#xA;&lt;h2 id=&#34;我們為什麼會覺得努力應該有回報&#34;&gt;我們為什麼會覺得「努力應該有回報」?&lt;/h2&gt;&#xA;&lt;p&gt;許多陷入犬儒的人會說: 「我不是不努力，我努力過了，沒用。」&lt;/p&gt;&#xA;&lt;p&gt;這恰恰反映出對努力的誤解，努力是會失敗的，而且也從來不會立即兌現，它更像是一種長期累積的複利，過程中你會改變視角、強化心智，最終與眾不同&lt;/p&gt;&#xA;&lt;p&gt;真正的努力，不只是行為上的執行，更是認知上的轉變。不是用熱血硬幹，而是用策略、用反思、用節奏走出自己的路。&lt;/p&gt;&#xA;&lt;h2 id=&#34;那我們應該怎麼做&#34;&gt;那我們應該怎麼做？&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;不要盲目追求文憑，但也不要過早放棄學習&lt;/li&gt;&#xA;&lt;li&gt;看懂社會結構的變動，但也要打造自己可控的核心能力&lt;/li&gt;&#xA;&lt;li&gt;知道短期內「投機」可能勝出，但&lt;strong&gt;長期是價值與認知力的勝利&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;一段送給未來自己的話&#34;&gt;一段送給未來自己的話&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;讀書不是為了成功，而是為了不被世界輕易騙走&lt;/li&gt;&#xA;&lt;li&gt;當社會用最廉價的快樂來交換你一生的時間時&lt;/li&gt;&#xA;&lt;li&gt;教育與自省，是你最後的防線&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;哪怕這個時代看起來對知識不再禮遇，我仍願意選擇學習，因為&lt;strong&gt;我相信厚積才能薄發，深耕才能穿透表象，真正理解世界，並在其中活出自己的姿態&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>實戰專案 - Titanic 生存預測專案</title>
      <link>http://twcch.io/posts/projects/articles_25063001/</link>
      <pubDate>Mon, 30 Jun 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/projects/articles_25063001/</guid>
      <description>&lt;p&gt;這是一個資料科學專案，目標是透過 Kaggle 經典的 Titanic 生存預測題目，建立一套結構清晰、模組化的預測系統。我不只是想交出一份準確的預測結果，更希望藉由這個專案練習:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;如何設計可擴充、可維護的資料分析架構&lt;/li&gt;&#xA;&lt;li&gt;如何把模型訓練與推論流程標準化&lt;/li&gt;&#xA;&lt;li&gt;如何用設定檔 (config-driven) 控制整個 pipeline&lt;/li&gt;&#xA;&lt;li&gt;如何實踐工程導向的資料科學流程&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;GitHub 原始碼: &lt;a href=&#34;https://github.com/twcch/TitanicSurvivalPrediction&#34;&gt;https://github.com/twcch/TitanicSurvivalPrediction&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;專案定位不只是解題而是設計一套解法系統&#34;&gt;專案定位：不只是「解題」，而是「設計一套解法系統」&lt;/h2&gt;&#xA;&lt;p&gt;我不滿足於單純把資料丟進模型調整參數。我希望打造的是一個「可重複使用的機器學習預測框架」，因此我做了以下幾點設計:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;架構模組化: 依照功能拆分為 data/, features/, models/, utils/，程式碼清楚分工&lt;/li&gt;&#xA;&lt;li&gt;流程自動化: 所有步驟都由 main.py 控制，方便一鍵執行與重現實驗&lt;/li&gt;&#xA;&lt;li&gt;設定檔驅動: 核心設定集中管理於 config.json，可以快速切換特徵、模型參數與輸出路徑&lt;/li&gt;&#xA;&lt;li&gt;可擴充性設計: 未來若要換模型、加特徵、改評估指標，幾乎不需改動主程式碼&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;這些設計不只是在技術上提升效率，也讓我在做資料科學時，更接近實務工作者的思維模式&lt;/p&gt;&#xA;&lt;h2 id=&#34;資料前處理與特徵工程-每個欄位都要能解釋&#34;&gt;資料前處理與特徵工程: 每個欄位都要能「解釋」&lt;/h2&gt;&#xA;&lt;p&gt;我對特徵的要求是: 不只要對模型有用，更要有邏輯、可解釋&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;處理缺失值&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Age 用中位數填補&lt;/li&gt;&#xA;&lt;li&gt;Embarked 用眾數填補&lt;/li&gt;&#xA;&lt;li&gt;Fare 缺值極少，仍完整處理&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;創造新特徵&#xA;&lt;ul&gt;&#xA;&lt;li&gt;FamilySize = SibSp + Parch: 模擬家庭是否有互助效果&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;選定使用特徵&#xA;&lt;ul&gt;&#xA;&lt;li&gt;類別型: Pclass, Sex, Embarked, Title&lt;/li&gt;&#xA;&lt;li&gt;數值型: Age, Fare, FamilySize&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;模型設定-我選擇-xgboost但更重視可控性&#34;&gt;模型設定: 我選擇 XGBoost，但更重視可控性&lt;/h2&gt;&#xA;&lt;p&gt;雖然這個任務可以用很多模型解，但我選擇以 XGBoost 為主模型，理由如下:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Tree-based 模型不需要特徵標準化，工程處理更簡潔&lt;/li&gt;&#xA;&lt;li&gt;對類別特徵與數值特徵的混合表現良好&lt;/li&gt;&#xA;&lt;li&gt;在 Kaggle 類似任務中表現穩定，可作為 baseline&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;模型訓練與推論流程&#34;&gt;模型訓練與推論流程&lt;/h2&gt;&#xA;&lt;p&gt;整個流程包含以下幾步，由 main.py 控制:&lt;/p&gt;</description>
    </item>
    <item>
      <title>當老師只靠 ChatGPT 回信：我們期待的不是答案，而是理解</title>
      <link>http://twcch.io/posts/2025/articles_25062501/</link>
      <pubDate>Wed, 25 Jun 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/2025/articles_25062501/</guid>
      <description>&lt;p&gt;最近，我正在參加一門職訓課程。本來對這堂課滿懷期待，尤其是對某位老師的專業背景很感興趣。不過，隨著課程進行，我漸漸感到一股說不出的落差感：每當我主動提出深入問題，收到的回信卻幾乎都像是 ChatGPT 生成的答案——格式漂亮、邏輯完整、語氣中立，但就是少了「人味」與「針對性」。&lt;/p&gt;&#xA;&lt;p&gt;是的，我知道他不是完全照抄。他有修改、有加註、有整合，但整體感受依然強烈：「這不是一個人對我問題的理解回應，而是一個工具對所有人都能複製的輸出」。&lt;/p&gt;&#xA;&lt;p&gt;這讓我很困惑，甚至有些失望。&lt;/p&gt;&#xA;&lt;h2 id=&#34;我不是反對使用-ai事實上我自己也在用&#34;&gt;我不是反對使用 AI，事實上我自己也在用&lt;/h2&gt;&#xA;&lt;p&gt;先聲明，我並不是那種抗拒 AI 的人。相反地，我本身就是資料分析背景，也有使用 ChatGPT 作為輔助工具的習慣。無論是整理技術架構、釐清概念、或產出初步內容，我完全理解 LLM 在學習與知識組織方面的強大價值。&lt;/p&gt;&#xA;&lt;p&gt;但關鍵在於：「角色不同、責任也不同。」&lt;/p&gt;&#xA;&lt;p&gt;身為學習者，我使用 AI 是為了提升效率與學習深度。但作為老師、講師、顧問，使用 AI 不應該只是「產生回答」這麼簡單。&lt;/p&gt;&#xA;&lt;h2 id=&#34;教學不是交付答案而是理解問題的脈絡&#34;&gt;教學不是交付答案，而是理解問題的脈絡&lt;/h2&gt;&#xA;&lt;p&gt;作為學生，我真正期待的，不是單純的一段知識回答，而是來自老師對我所處困境的共鳴與理解。我希望老師能理解我提問背後的「背景」、「盲點」與「問題設計的目的」，並根據這些脈絡回應，而不是直接貼上一段 ChatGPT 輸出的技術解釋。&lt;/p&gt;&#xA;&lt;p&gt;因為我相信，一個真正理解我問題的老師，會根據我當下的能力、背景、甚至目標給出回應——這種回應，不是任何一個 AI 可以「直接」產出的。&lt;/p&gt;&#xA;&lt;p&gt;而當老師只是當 ChatGPT 是一個快捷鍵，那麼學生也很快會意識到：你不是在回答我，你只是在轉寄一份資訊而已。&lt;/p&gt;&#xA;&lt;h2 id=&#34;當教學淪為貼文產出學生會停止問問題&#34;&gt;當教學淪為「貼文產出」，學生會停止問問題&lt;/h2&gt;&#xA;&lt;p&gt;更嚴重的影響是：這樣的互動會直接打擊學生的提問動力。&lt;/p&gt;&#xA;&lt;p&gt;當我發現提問後收到的回應只是套用模板、換個措辭、格式一致卻無深入探討時，我會懷疑：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;我這麼認真思考的問題，真的值得你花時間思考嗎？&lt;/li&gt;&#xA;&lt;li&gt;還是我只是你輸入框中的另一個 prompt？&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;久而久之，學生開始不再問問題，也不再相信提問能帶來真正的理解與對話。這對整個學習場域，是一種靜默但致命的傷害。&lt;/p&gt;&#xA;&lt;h2 id=&#34;ai-是輔助不是教學本體&#34;&gt;AI 是輔助，不是教學本體&lt;/h2&gt;&#xA;&lt;p&gt;AI 可以作為老師教學的輔助工具：幫助蒐集資料、釐清知識、快速構思。但它不應該代替老師對學習者的思考與理解責任。在這個知識容易複製的年代，真正無法取代的價值，其實是「對個別學習者的回應能力」。&lt;/p&gt;&#xA;&lt;p&gt;我們當然不會要求每個老師都要一封封親筆手寫、寫出三千字的回信。但至少請不要用 ChatGPT 當成唯一的內容產出來源，更不要用它來「掩蓋」缺乏投入的回應。學習者看得出來，也感受得到。&lt;/p&gt;&#xA;&lt;h2 id=&#34;我寫這篇文章不是為了批評老師而是為了保護教學&#34;&gt;我寫這篇文章，不是為了批評老師，而是為了保護教學&lt;/h2&gt;&#xA;&lt;p&gt;我知道那位老師並不是惡意。他可能工作繁忙、學生太多、壓力很大。我甚至相信他是出於「想要給一個完整答案」的好意才選擇這樣回覆。但我們必須正視一件事：當我們過度依賴工具，而忘記了教學的本質是人與人之間的理解與連結，那麼再強大的 AI 也只會讓教育變得更冷漠、更廉價。&lt;/p&gt;&#xA;&lt;p&gt;我寫這篇文章，是希望提醒每一位教學者：你的價值，不在於你給的答案有多完整，而在於你有多願意理解學生的問題。因為 AI 可以幫你教知識，但唯有你能教會「怎麼成長」。&lt;/p&gt;</description>
    </item>
    <item>
      <title>為什麼用 AI 技術檢測企業舞弊，比想像中更困難?</title>
      <link>http://twcch.io/posts/2025/articles_25060201/</link>
      <pubDate>Mon, 02 Jun 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/2025/articles_25060201/</guid>
      <description>&lt;p&gt;在資料科學領域中，對企業進行舞弊檢測 (Fraud Detection) 被視為是一種分類問題: 輸入企業相關的數據，輸出舞弊或非舞弊。然而，真正投入研究後會發現，這個問題很難解決，非常具挑戰性。&lt;/p&gt;&#xA;&lt;p&gt;我目前主要研究方向，是運用人工智慧 (Artificial Intelligence) 技術，來解決企業進行財務報表舞弊的問題。這類型的議題與銀行信用卡詐欺、保險業中的理賠舞弊、甚至洗錢行為有相似之處，都是稀有事件、後知後覺、動態進化的「敵對性問題」。&lt;/p&gt;&#xA;&lt;h2 id=&#34;為什麼這不是一個單純的分類問題&#34;&gt;為什麼這不是一個單純的分類問題？&lt;/h2&gt;&#xA;&lt;p&gt;在傳統機器學習框架下，分類問題的成功往往來自於充足的標記數據、清晰的邊界條件與相對穩定的資料分佈。然而，舞弊行為恰恰違反了這三項假設。&lt;/p&gt;&#xA;&lt;p&gt;可以從以下幾點具體說明：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;極度不平衡的資料 (Class Imbalance)&lt;/p&gt;&#xA;&lt;p&gt;在實務資料中，舞弊案件往往只佔所有資料的極小比例，可能是千分之一、甚至萬分之一。這意味著如果你採用傳統的精確度 (accuracy) 作為衡量指標，模型即使完全忽略舞弊也能達到 99% 以上的準確率，但這顯然毫無意義。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;標籤不完整且滯後揭露 (Label Latency &amp;amp; Missing Labels)&lt;/p&gt;&#xA;&lt;p&gt;很多舞弊行為要經過數月、甚至數年後才會被調查揭露，更遑論那些永遠未被發現的案件。這使得訓練資料的標籤具有高度不確定性，導致模型容易學到錯誤的決策邊界。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;舞弊技術持續演化 (Concept Drift)&lt;/p&gt;&#xA;&lt;p&gt;犯罪者會根據監管與模型檢測方式持續更新手法，導致模型在部署後迅速失效。這使得即使當下訓練準確的模型，也難以長期維持效能。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;異常並非來自單一特徵，而是整體脈絡的矛盾 (Contextual Inconsistency)&lt;/p&gt;&#xA;&lt;p&gt;財報舞弊往往不是單一財務指標異常，而是多個指標之間出現結構性不一致。例如: 營收大增但現金流卻大減、獲利提升但存貨異常膨脹。這種多變量脈絡異常，遠比簡單的 outlier detection 更為複雜。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;問題不是模型選得不夠好而是問題設定錯了&#34;&gt;問題不是模型選得不夠好，而是問題設定錯了&lt;/h2&gt;&#xA;&lt;p&gt;如果僅停留在「用哪個模型比較準」、「要不要用 XGBoost 還是 LSTM」這種層級的思考，只會陷入技術細節的死胡同，無法解決核心困難。相反地，我認為更關鍵的兩個研究方向是:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;如何讓 AI 自己找到潛在的舞弊標籤？&lt;/p&gt;&#xA;&lt;p&gt;採用自監督學習 (Self-Supervised Learning)，不依賴人工標註，而是讓模型自行從大量正常樣本中學習「常態結構」，再對偏離常態的資料進行異常評分，進一步推論出可能的舞弊行為。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;如何讓深度模型的決策可以被人類審計人員理解？&lt;/p&gt;&#xA;&lt;p&gt;深度學習模型雖然強大，但往往是黑箱。導入可解釋性方法 (如 SHAP、LIME、Attention 可視化)，可以提升金融監理與內部稽核部門的信任與採用意願，也為模型導入實務場域鋪路。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;這不只是建模問題更是科學問題&#34;&gt;這不只是建模問題，更是科學問題&lt;/h2&gt;&#xA;&lt;p&gt;用 AI 解決舞弊，不是一場簡單的技術堆疊競賽，而是對整個金融風險邏輯、舞弊行為模式、以及資料特性深刻理解的綜合挑戰。這將是我博士研究的起點，從理解問題本質出發，探索如何用 AI 技術建立可行的風險偵測系統，不只是要「分類得準」，更要讓人「信得過」。我認為這是一條難走的路，但也因此充滿價值。&lt;/p&gt;</description>
    </item>
    <item>
      <title>為什麼 AI 正在快速削弱低階 Business Analyst 的價值?</title>
      <link>http://twcch.io/posts/2025/articles_25040701/</link>
      <pubDate>Mon, 07 Apr 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/2025/articles_25040701/</guid>
      <description>&lt;p&gt;五年前，我踏入壽險產業，成為一名 Business Analyst (BA)。當時的工作內容相當清晰: 需求文件撰寫、報表製作、簡單的數據分析與溝通協調，是我每天的日常。那時候，這些任務仍需靠人力一項一項完成，效率與品質全憑個人經驗與熟練度。但如今，這些「核心能力」正快速被人工智慧工具重塑，甚至取代。&lt;/p&gt;&#xA;&lt;h2 id=&#34;我親身感受到的衝擊工具進步得比我想像中快&#34;&gt;我親身感受到的衝擊：工具進步得比我想像中快&lt;/h2&gt;&#xA;&lt;p&gt;回到 2022 年底，當我首次使用生成式 AI 工具進行報告撰寫與 Python 代碼產出時，內心的震撼難以言喻。曾經需要數小時才能完成的分析報告，在幾分鐘內生成雛形；曾經為了釐清邏輯關係而反覆修改的流程圖，如今只需一句指令就能完成。&lt;/p&gt;&#xA;&lt;p&gt;我逐漸意識到，這並不是單一任務被加速，而是整個 BA 工作流程正被結構性重塑。換言之，AI 正在壓縮 BA 的邊際價值。這不只是主觀體感，更有明確的研究支持。根據美國 OpenAI 與賓州大學的聯合研究，約有 80% 的職業至少有 10% 的工作內容將受到 LLM 工具的影響；其中，高達 19% 的職業，其超過一半的工作可由 AI 完成。而 BA 尤其是負責初階文件處理、標準報表、流程規劃等工作的分析師，被列為高曝險族群。&lt;/p&gt;&#xA;&lt;p&gt;原因很明確因為 BA 所擅長的文字組織、資料彙整與需求敘述，正是 AI 最擅長模仿與執行的任務。&lt;/p&gt;&#xA;&lt;h2 id=&#34;市場變化正在發生不是未來式而是現在進行式&#34;&gt;市場變化正在發生，不是未來式，而是現在進行式&lt;/h2&gt;&#xA;&lt;p&gt;這樣的趨勢已經開始反映在勞動市場上：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;BA 的職缺增速放緩&lt;/p&gt;&#xA;&lt;p&gt;企業在內部導入 LLM 工具後，發現許多重複性任務可由 AI 初步完成，人力需求自然下降。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;初階 BA 的薪資競爭力下降&lt;/p&gt;&#xA;&lt;p&gt;對於只熟悉基本分析任務、無法主動創造洞察的人才，企業的願意支付薪資上升空間有限。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;高階 BA 的需求反而上升&lt;/p&gt;&#xA;&lt;p&gt;企業更看重能駕馭 AI 工具、快速整合資訊、提出具策略意義建議的分析人才。所謂「會用 AI 的人」，正逐步取代「被 AI 取代的人」。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;這代表，AI 並不是取代所有 BA，而是取代了不進化的 BA。&lt;/p&gt;&#xA;&lt;h2 id=&#34;我的轉型從反應式執行者到主動創造者&#34;&gt;我的轉型：從反應式執行者，到主動創造者&lt;/h2&gt;&#xA;&lt;p&gt;面對這樣的劇變，我無法視若無睹。&lt;/p&gt;&#xA;&lt;p&gt;於是我開始盤點自己的能力，明白單靠產業 Know-how 或不夠專精的技能，將難以應對未來的競爭。因此，我選擇投入更深層的技能學習: 博士班訓練，深度的掌握資料科學、機器學習與深度學習領域，建立自身的核心競爭力。不只是會用工具或套模，而是要能理解這些如何運作、能應用在哪些情境、又有何種侷限。這樣的技能，不僅能讓我在日常分析中脫穎而出，也為我開啟進入 AI 應用領域的可能性。&lt;/p&gt;</description>
    </item>
    <item>
      <title>視覺化專案 - 200 個國家 200 百年 4 分鐘</title>
      <link>http://twcch.io/posts/projects/articles_25040702/</link>
      <pubDate>Mon, 07 Apr 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/projects/articles_25040702/</guid>
      <description>&lt;p&gt;這是一個資料視覺化專案——「Dynamic Visualization: 200 Countries, 200 Years, 4 Minutes」。它將涵蓋 1816 至 2016 年，200 個國家的歷史變遷以互動動畫呈現，整體動畫長度約四分鐘，旨在結合「時間」與「地理」維度，提供用戶沉浸式的歷史視覺體驗。&lt;/p&gt;&#xA;&lt;p&gt;成品呈現頁面: &lt;a href=&#34;https://twcch.io/TwoHundredYearsTwoHundredCountries/views.html&#34;&gt;https://twcch.io/TwoHundredYearsTwoHundredCountries/views.html&lt;/a&gt;&lt;br&gt;&#xA;GitHub 原始碼: &lt;a href=&#34;https://github.com/twcch/TwoHundredYearsTwoHundredCountries&#34;&gt;https://github.com/twcch/TwoHundredYearsTwoHundredCountries&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;專案目標-動態傳遞跨時代趨勢&#34;&gt;專案目標: 動態傳遞跨時代趨勢&lt;/h2&gt;&#xA;&lt;p&gt;我這次的核心目的，是打造一段「高品質又美觀」的互動式動畫。相比靜態圖表，此動畫能讓使用者更直覺地感受到全球歷史變化的脈絡與節奏。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;跨國維度: 一次呈現 200 國家在相同指標上的變化&lt;/li&gt;&#xA;&lt;li&gt;跨年代視角: 覆蓋整整兩個世紀&lt;/li&gt;&#xA;&lt;li&gt;互動與美感: 最終以 Plotly Express 強化動畫的動態感與互動性&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;這是一個典型的「Proof of Concept」，驗證我能用純 Python 開源工具在本地完成動態資料視覺化，而不是依賴商業軟體。&lt;/p&gt;&#xA;&lt;h2 id=&#34;處理流程解析&#34;&gt;處理流程解析&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;資料擷取與清理&#xA;&lt;ul&gt;&#xA;&lt;li&gt;使用 pandas 從 Gapminder 或其他開源來源讀入年份、國家與指標。&lt;/li&gt;&#xA;&lt;li&gt;透過 core/data.py 標準化欄位名稱、處理缺值、並轉換為長型結構，以利後續分析。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;寫入 SQLite&#xA;&lt;ul&gt;&#xA;&lt;li&gt;為了方便查詢與存取，我用 core/sqlite_db.py 將清理後的資料匯入 SQLite 資料庫，一併記錄 metadata。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;產生視覺化資料表&#xA;&lt;ul&gt;&#xA;&lt;li&gt;scripts/build_view_table.py 將資料按年與國家展開，組合成完整用於視覺化的 DataFrame。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;動態驗證：matplotlib 原型&#xA;&lt;ul&gt;&#xA;&lt;li&gt;在 proof_of_concept.py 中，以 matplotlib 建立由靜態圖逐幀拼湊的基本動畫，確認播放邏輯與視覺節奏。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;互動動畫：Plotly Express&#xA;&lt;ul&gt;&#xA;&lt;li&gt;最終在 plot_with_px.py 中改以 Plotly Express，產出包含滑動條、國家標籤、時間軸與音效的四分鐘互動畫面，並輸出至 docs/views.html。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;技術選擇與實務考量&#34;&gt;技術選擇與實務考量&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;資料處理: pandas 濾除缺值、重塑表格、處理 metadata，全套操作都在 pandas 中完成。&lt;/li&gt;&#xA;&lt;li&gt;儲存管理: 使用 SQLite 儲存資料，方便查詢與重複執行，而不用每次都從頭開 CSV。&lt;/li&gt;&#xA;&lt;li&gt;動畫原型: matplotlib 可迅速驗證概念、調整幀率與時間間隔。&lt;/li&gt;&#xA;&lt;li&gt;互動視覺化: Plotly Express 能更快速加入滑桿、hover 標籤，動畫更加流暢美觀，也更適合網頁展示。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;展示成果&#34;&gt;展示成果&lt;/h2&gt;&#xA;&lt;p&gt;最終輸出是一個 HTML 檔，內嵌動態 html5 視覺化:&lt;/p&gt;</description>
    </item>
    <item>
      <title>作品</title>
      <link>http://twcch.io/project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://twcch.io/project/</guid>
      <description>&lt;p&gt;(資料整理中)&lt;/p&gt;&#xA;&lt;h2 id=&#34;data-science&#34;&gt;Data Science&lt;/h2&gt;&#xA;&lt;table border=&#34;1&#34; cellspacing=&#34;0&#34; cellpadding=&#34;8&#34; style=&#34;width:100%; border-collapse: collapse; text-align: center;&#34;&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;th style=&#34;width:10%;&#34;&gt;年份&lt;/th&gt;&#xA;    &lt;th style=&#34;width:70%;&#34;&gt;名稱&lt;/th&gt;&#xA;    &lt;th style=&#34;width:20%;&#34;&gt;連結&lt;/th&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;2025&lt;/td&gt;&#xA;    &lt;td&gt;Titanic 生存預測專案&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/projects/articles_25063001&#34;&gt;Blog&lt;/a&gt; / Github&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2 id=&#34;data-visualization&#34;&gt;Data Visualization&lt;/h2&gt;&#xA;&lt;table border=&#34;1&#34; cellspacing=&#34;0&#34; cellpadding=&#34;8&#34; style=&#34;width:100%; border-collapse: collapse; text-align: center;&#34;&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;th style=&#34;width:10%;&#34;&gt;年份&lt;/th&gt;&#xA;    &lt;th style=&#34;width:70%;&#34;&gt;名稱&lt;/th&gt;&#xA;    &lt;th style=&#34;width:20%;&#34;&gt;連結&lt;/th&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;2025&lt;/td&gt;&#xA;    &lt;td&gt;200 個國家 200 百年 4 分鐘&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/projects/articles_25040702&#34; target=&#34;_blank&#34;&gt;Blog&lt;/a&gt; / Github&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2 id=&#34;application-programming-interface&#34;&gt;Application Programming Interface&lt;/h2&gt;&#xA;&lt;table border=&#34;1&#34; cellspacing=&#34;0&#34; cellpadding=&#34;8&#34; style=&#34;width:100%; border-collapse: collapse; text-align: center;&#34;&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;th style=&#34;width:10%;&#34;&gt;年份&lt;/th&gt;&#xA;    &lt;th style=&#34;width:70%;&#34;&gt;名稱&lt;/th&gt;&#xA;    &lt;th style=&#34;width:20%;&#34;&gt;連結&lt;/th&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;2025&lt;/td&gt;&#xA;    &lt;td&gt;FinAPI&lt;/td&gt;&#xA;    &lt;td&gt;Blog / Github&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2 id=&#34;game&#34;&gt;Game&lt;/h2&gt;&#xA;&lt;table border=&#34;1&#34; cellspacing=&#34;0&#34; cellpadding=&#34;8&#34; style=&#34;width:100%; border-collapse: collapse; text-align: center;&#34;&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;th style=&#34;width:10%;&#34;&gt;年份&lt;/th&gt;&#xA;    &lt;th style=&#34;width:70%;&#34;&gt;名稱&lt;/th&gt;&#xA;    &lt;th style=&#34;width:20%;&#34;&gt;連結&lt;/th&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;2025&lt;/td&gt;&#xA;    &lt;td&gt;Construction Bloodbath&lt;/td&gt;&#xA;    &lt;td&gt;Blog / &lt;a href=&#34;https://github.com/twcch/ConstructionBloodbath&#34; target=&#34;_blank&#34;&gt;Github&lt;/a&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;&lt;/table&gt;</description>
    </item>
    <item>
      <title>專欄文章</title>
      <link>http://twcch.io/column_article/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://twcch.io/column_article/</guid>
      <description>&lt;p&gt;(資料整理中)&lt;/p&gt;&#xA;&lt;h2 id=&#34;ithome-鐵人賽-2025&#34;&gt;iThome 鐵人賽 2025&lt;/h2&gt;&#xA;&lt;h3 id=&#34;快速掌握資料結構與演算法&#34;&gt;快速掌握資料結構與演算法&lt;/h3&gt;&#xA;&lt;table border=&#34;1&#34; cellspacing=&#34;0&#34; cellpadding=&#34;8&#34; style=&#34;width:100%; border-collapse: collapse; text-align: center;&#34;&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;th style=&#34;width:10%;&#34;&gt;天數&lt;/th&gt;&#xA;    &lt;th style=&#34;width:70%;&#34;&gt;標題&lt;/th&gt;&#xA;    &lt;th style=&#34;width:20%;&#34;&gt;連結&lt;/th&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 1&lt;/td&gt;&#xA;    &lt;td&gt;(Day 1) 介紹與準備&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/快速掌握資料結構與演算法/ironman_25_2_1&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 2&lt;/td&gt;&#xA;    &lt;td&gt;(Day 2) 陣列 (Array)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/快速掌握資料結構與演算法/ironman_25_2_2&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 3&lt;/td&gt;&#xA;    &lt;td&gt;(Day 3) 矩陣 (Matrix)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/快速掌握資料結構與演算法/ironman_25_2_3&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 4&lt;/td&gt;&#xA;    &lt;td&gt;(Day 4) 鏈表 (Linked List)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/快速掌握資料結構與演算法/ironman_25_2_4&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 5&lt;/td&gt;&#xA;    &lt;td&gt;(Day 5) 堆疊 (Stack)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/快速掌握資料結構與演算法/ironman_25_2_5&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 6&lt;/td&gt;&#xA;    &lt;td&gt;(Day 6) 隊列 (Queue)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/快速掌握資料結構與演算法/ironman_25_2_6&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 7&lt;/td&gt;&#xA;    &lt;td&gt;(Day 7) 二元樹 (Binary Tree)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/快速掌握資料結構與演算法/ironman_25_2_7&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 8&lt;/td&gt;&#xA;    &lt;td&gt;(Day 8) 平衡樹 (Balanced Tree)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/快速掌握資料結構與演算法/ironman_25_2_8&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 9&lt;/td&gt;&#xA;    &lt;td&gt;(Day 9) 其他樹 (Other Trees)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;#&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 10&lt;/td&gt;&#xA;    &lt;td&gt;(Day 10) 圖 (Graph)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;#&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;&lt;/table&gt;&#xA;&lt;h3 id=&#34;30-天入門常見的機器學習演算法&#34;&gt;30 天入門常見的機器學習演算法&lt;/h3&gt;&#xA;&lt;table border=&#34;1&#34; cellspacing=&#34;0&#34; cellpadding=&#34;8&#34; style=&#34;width:100%; border-collapse: collapse; text-align: center;&#34;&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;th style=&#34;width:10%;&#34;&gt;天數&lt;/th&gt;&#xA;    &lt;th style=&#34;width:70%;&#34;&gt;標題&lt;/th&gt;&#xA;    &lt;th style=&#34;width:20%;&#34;&gt;連結&lt;/th&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 1&lt;/td&gt;&#xA;    &lt;td&gt;(Day 1) 介紹與準備&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_1&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 2&lt;/td&gt;&#xA;    &lt;td&gt;(Day 2) 線性迴歸 (Linear Regression)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_2&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 3&lt;/td&gt;&#xA;    &lt;td&gt;(Day 3) 多項式迴歸 (Polynomial Regression)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_3&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 4&lt;/td&gt;&#xA;    &lt;td&gt;(Day 4) 正規化迴歸 (Regularization Regression)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_4&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 5&lt;/td&gt;&#xA;    &lt;td&gt;(Day 5) 邏輯迴歸 (Logistic Regression)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_5&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 6&lt;/td&gt;&#xA;    &lt;td&gt;(Day 6) 邏輯迴歸 (多項式 + 正規化)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_6&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 7&lt;/td&gt;&#xA;    &lt;td&gt;(Day 7) 回顧迴歸：從線性邏輯到學習本質&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_7&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 8&lt;/td&gt;&#xA;    &lt;td&gt;(Day 8) K-近鄰 (K-Nearest Neighbors)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_8&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 9&lt;/td&gt;&#xA;    &lt;td&gt;(Day 9) 樸素貝氏分類器 (Naive Bayes Classifier)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_9&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 10&lt;/td&gt;&#xA;    &lt;td&gt;(Day 10) 支援向量機 (Support Vector Machine)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_10&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 11&lt;/td&gt;&#xA;    &lt;td&gt;(Day 11) 二元分類任務驗證指標&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_11&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 12&lt;/td&gt;&#xA;    &lt;td&gt;(Day 12) 多元分類任務驗證指標&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_12&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 13&lt;/td&gt;&#xA;    &lt;td&gt;(Day 13) 迴歸任務驗證指標&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_13&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 14&lt;/td&gt;&#xA;    &lt;td&gt;(Day 14) 決策樹 (Decision Tree)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_14&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 15&lt;/td&gt;&#xA;    &lt;td&gt;(Day 15) 隨機森林 (Random Forest)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_15&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 16&lt;/td&gt;&#xA;    &lt;td&gt;(Day 16) K-Means&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_16&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 17&lt;/td&gt;&#xA;    &lt;td&gt;(Day 17) 淺談深度學習 (Deep Learning)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_17&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 18&lt;/td&gt;&#xA;    &lt;td&gt;(Day 18) 全連接神經網絡 (Fully Connected Neural Network)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_18&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 19&lt;/td&gt;&#xA;    &lt;td&gt;(Day 19) 神經元 (Neuron)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_19&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 20&lt;/td&gt;&#xA;    &lt;td&gt;(Day 20) 激活函數 (Activation Function)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_20&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 21&lt;/td&gt;&#xA;    &lt;td&gt;(Day 21) 卷積神經網絡 (Convolutional Neural Network)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_21&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 22&lt;/td&gt;&#xA;    &lt;td&gt;(Day 22) 深度學習中的正規化與正則化 (Regularization in Deep Learning)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_22&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 23&lt;/td&gt;&#xA;    &lt;td&gt;(Day 23) 深度學習中的優化方法 (Optimization in Deep Learning)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_23&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 24&lt;/td&gt;&#xA;    &lt;td&gt;(Day 24) Adam 優化器 (Adaptive Moment Estimation)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_24&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 25&lt;/td&gt;&#xA;    &lt;td&gt;(Day 25) 循環神經網路 (Recurrent Neural Network)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_25&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 26&lt;/td&gt;&#xA;    &lt;td&gt;(Day 26) 長短期記憶 (Long Short-Term Memory)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_26&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 27&lt;/td&gt;&#xA;    &lt;td&gt;(Day 27) 閘控循環單元 (Gated Recurrent Unit)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_27&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 28&lt;/td&gt;&#xA;    &lt;td&gt;(Day 28) Seq2Seq (Encoder Decoder with RNN, LSTM, GRU)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_28&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 29&lt;/td&gt;&#xA;    &lt;td&gt;(Day 29) 注意力機制 (Attention Mechanism)&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_29&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;Day 30&lt;/td&gt;&#xA;    &lt;td&gt;(Day 30) 系列結尾&lt;/td&gt;&#xA;    &lt;td&gt;&lt;a href=&#34;../posts/column_articles/ironman_2025/30天入門常見的機器學習演算法/ironman_25_1_30&#34;&gt;Blog&lt;/a&gt; / iThome&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;&lt;/table&gt;</description>
    </item>
    <item>
      <title>教材</title>
      <link>http://twcch.io/textbook/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://twcch.io/textbook/</guid>
      <description>&lt;p&gt;(資料整理中)&lt;/p&gt;</description>
    </item>
    <item>
      <title>研究經歷</title>
      <link>http://twcch.io/research/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://twcch.io/research/</guid>
      <description>&lt;h2 id=&#34;academic-thesis&#34;&gt;Academic Thesis&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Hsieh, C. C.&lt;/strong&gt; and Hsu, F. J. (2018). A firm’s financial risk and tax avoidance behavior. Master’s thesis, Department of Insurance and&#xA;Finance, National Taichung University of Science and Technology, Taichung, Taiwan.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;research-presentations&#34;&gt;Research Presentations&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Hsu, F. J., Chen, S. H., and &lt;strong&gt;Hsieh, C. C.&lt;/strong&gt; (2020). Sweet candy or bitter poison: The default risk under US Federal&#xA;Reserve’s quantitative easing. The International Conference on Innovative Computing and Management Science (ICMS&#xA;2020), July 29, 2020, Yilan, Taiwan.&lt;/li&gt;&#xA;&lt;li&gt;Hsu, F. J., Chen, S. H., and &lt;strong&gt;Hsieh, C. C.&lt;/strong&gt; (2020). Corporate financial risk, financial market conditions, and firm’s&#xA;tax avoidance behavior. The International Conference on Innovative Computing and Management Science (ICMS 2020), July&#xA;29, 2020, Yilan, Taiwan.&lt;/li&gt;&#xA;&lt;li&gt;Hsu, F. J., and &lt;strong&gt;Hsieh, C. C.&lt;/strong&gt; (2018). Financial risk and tax avoidance. The 21st Conference of Finance Theory and&#xA;Practice, May 30, 2018, Taichung, Taiwan.&lt;/li&gt;&#xA;&lt;li&gt;Hsu, F. J., and &lt;strong&gt;Hsieh, C. C.&lt;/strong&gt; (2018). Macroeconomic conditions and firm’s tax avoidance behavior. The Annual Conference&#xA;of Modern Accounting Literature Association, May 4, 2018, Taichung, Taiwan.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;research-projects&#34;&gt;Research Projects&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;以巨量探勘與科研能量為基礎之我國金融科技架構發展(1/2)，科技部計畫編號 MOST 106-2634-F-025-001-，計畫參與人員，執行期間 2017/07/01–2018/06/30。&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>聯絡我</title>
      <link>http://twcch.io/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://twcch.io/contact/</guid>
      <description>&lt;p&gt;如果你有任何問題，或是想要交流，可以透過 email 與我聯繫。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Email: &lt;a href=&#34;mailto:contact@twcch.io&#34; target=&#34;_blank&#34;&gt;contact [at] twcch.io&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>謝志謙 Chih-Chien Hsieh</title>
      <link>http://twcch.io/cv/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://twcch.io/cv/</guid>
      <description>&lt;img src=&#34;https://avatars.githubusercontent.com/u/24428408?v=4&#34; alt=&#34;About Me&#34; width=&#34;240px&#34;&gt;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;學歷&#34;&gt;學歷&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;(2025.09 – Present) 國立成功大學 工程科學系 資訊工程與應用組 博士生&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;(2016.09 – 2018.06) 國立臺中科技大學 保險金融管理系 碩士&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;研究領域: 統計模型分析企業的財務風險與避稅行為。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;(2014.09 – 2016.06) 國立臺中科技大學 保險金融管理系 學士&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;工作經驗&#34;&gt;工作經驗&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;(2022.04 – 2025.06) 富邦人壽保險股份有限公司 專案襄理 (商業分析師)&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;負責理賠系統規劃，將業務邏輯轉化為結構化、可驗證且可擴展的系統規則，參與保險理賠核心系統的現代化重構計畫，主要協助推動保險理賠核心系統轉換與系統資料整合相關事宜。&lt;/li&gt;&#xA;&lt;li&gt;主要職責:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;使用 Python 進行資料驗證、分析與清理，並支援業務決策與優化系統運作。&lt;/li&gt;&#xA;&lt;li&gt;分析保險商品的理賠給付規則，確保其系統符合要求。&lt;/li&gt;&#xA;&lt;li&gt;與開發團隊及精算團隊合作，定義並釐清相關邏輯，以確保系統的準確性。&lt;/li&gt;&#xA;&lt;li&gt;參與使用者驗收測試 (UAT)，設計驗證流程以確保模組邏輯的正確性與一致性。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;(2020.04 – 2022.03) 南山人壽保險股份有限公司 專員 (商業分析師)&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;負責理賠系統規劃，將業務邏輯轉化為結構化、可驗證且可擴展的系統規則。&lt;/li&gt;&#xA;&lt;li&gt;主要職責:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;分析保險商品的理賠給付規則，確保其系統符合要求。&lt;/li&gt;&#xA;&lt;li&gt;與開發團隊及精算團隊合作，定義並釐清相關邏輯，以確保系統的準確性。&lt;/li&gt;&#xA;&lt;li&gt;參與使用者驗收測試 (UAT)，設計驗證流程以確保模組邏輯的正確性與一致性。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;專長與技能&#34;&gt;專長與技能&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;結構化與半結構化大數據分析&#xA;&lt;ul&gt;&#xA;&lt;li&gt;具備獨立完成資料建模全流程 (資料探索、清理、前處理、特徵工程、模型訓練與評估)。&lt;/li&gt;&#xA;&lt;li&gt;具備應用 Python、Scikit-Learn、PyTorch 建構機器學習與深度學習模型，解決實務數據分析問題。&lt;/li&gt;&#xA;&lt;li&gt;具備模型效能評估，涵蓋 AUC、Precision、Recall、F1 等多元指標，確保模型具備全面性表現。&lt;/li&gt;&#xA;&lt;li&gt;具備 SQL 與資料庫設計，能處理大規模結構化/半結構化資料，並透過數據視覺化轉化為決策洞察。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Java Web 全端開發&#xA;&lt;ul&gt;&#xA;&lt;li&gt;後端: Java, Spring Boot, Spring Data JPA, Spring Security&lt;/li&gt;&#xA;&lt;li&gt;前端: HTML, CSS, JavaScript&lt;/li&gt;&#xA;&lt;li&gt;資料庫: PostgreSQL, MySQL&lt;/li&gt;&#xA;&lt;li&gt;其他: Git&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;其他&#xA;&lt;ul&gt;&#xA;&lt;li&gt;辦公軟體: Microsoft Office&lt;/li&gt;&#xA;&lt;li&gt;資料視覺化: Tableau Public&lt;/li&gt;&#xA;&lt;li&gt;程式語言: C, C++&lt;/li&gt;&#xA;&lt;li&gt;統計軟體: SAS, SPSS&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;專業認證&#34;&gt;專業認證&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;(2025) 美國壽險管理師 (FLMI), LOMA&lt;/li&gt;&#xA;&lt;li&gt;(2024) 國際專案管理師 (PMP), PMI&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;專案經歷&#34;&gt;專案經歷&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;(2022.04 – 2025.06) 富邦人壽保險股份有限公司&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;(2023.05 – 2025.06) 理賠應用系統現代化專案 – 理賠保險金計算規則盤點與規劃&#xA;&lt;ul&gt;&#xA;&lt;li&gt;帶領跨單位的 13 位成員的團隊，全面性評估各種商品的理賠規則與理賠系統給付規則，進行調整或重構系統邏輯架構規劃，並與 IT 團隊協同，確保規則與系統重構方向一致。&lt;/li&gt;&#xA;&lt;li&gt;主要成果:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;主導業務邏輯清查與規則文件結構化歸檔，為日後系統需求規則奠定基礎。&lt;/li&gt;&#xA;&lt;li&gt;標準化不同保單商品的計算規則，建立統一邏輯的完整知識庫。&lt;/li&gt;&#xA;&lt;li&gt;促進跨部門利害關係人之間的溝通，提升對模糊規則的共識與認知一致性。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;(2024.08 – 2025.06) 理賠應用系統現代化專案 – 資料維護功能設計與整合&#xA;&lt;ul&gt;&#xA;&lt;li&gt;負責新理賠系統的商品維護功能介面規劃，分析舊系統規則與資料數據，並設計可擴展的系統介面與進行資料清洗與轉換，提升資料一致性與作業穩定性。&lt;/li&gt;&#xA;&lt;li&gt;主要成果:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;完成跨異質系統的欄位對應與資料結構整併。&lt;/li&gt;&#xA;&lt;li&gt;設計並導入新的資料維護功能，提升系統維運性並減少人為錯誤。&lt;/li&gt;&#xA;&lt;li&gt;建立資料欄位定義與驗證邏輯，強化長期的資料品質治理能力。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>關於我</title>
      <link>http://twcch.io/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://twcch.io/about/</guid>
      <description>&lt;img src=&#34;https://avatars.githubusercontent.com/u/24428408?v=4&#34; alt=&#34;About Me&#34; width=&#34;240px&#34;&gt;&#xA;&lt;!-- &lt;img src=&#34;../images/common/avatar.jpeg&#34; alt=&#34;About Me&#34; style=&#34;width:240px&#34;&gt; --&gt;&#xA;&lt;p&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;學歷&#34;&gt;學歷&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;(2025 – Present) 國立成功大學 工程科學系 博士生&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;工作經驗&#34;&gt;工作經驗&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;(2022 – 2025) 富邦人壽保險股份有限公司 專案襄理 (商業分析師)&lt;/li&gt;&#xA;&lt;li&gt;(2020 – 2022) 南山人壽保險股份有限公司 專員 (商業分析師)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;專長&#34;&gt;專長&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;結構化大數據分析&lt;/li&gt;&#xA;&lt;li&gt;機器學習&lt;/li&gt;&#xA;&lt;li&gt;深度學習&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;技能&#34;&gt;技能&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Python (Scikit-learn, PyTorch, Flask)&lt;/li&gt;&#xA;&lt;li&gt;Java (Spring Framework)&lt;/li&gt;&#xA;&lt;li&gt;SQL (PostgreSQL, MySQL)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;專業認證&#34;&gt;專業認證&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;(2025) 美國壽險管理師 (FLMI), LOMA&lt;/li&gt;&#xA;&lt;li&gt;(2024) 國際專案管理師 (PMP), PMI&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
  </channel>
</rss>
