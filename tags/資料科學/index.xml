<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>資料科學 on 志謙&#39;s Blog</title>
    <link>http://localhost:1313/tags/%E8%B3%87%E6%96%99%E7%A7%91%E5%AD%B8/</link>
    <description>Recent content in 資料科學 on 志謙&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>zh-tw</language>
    <lastBuildDate>Mon, 02 Jun 2025 00:00:00 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/%E8%B3%87%E6%96%99%E7%A7%91%E5%AD%B8/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>為什麼用 AI 檢測舞弊，比你想的更困難？</title>
      <link>http://localhost:1313/posts/article_20250625001/</link>
      <pubDate>Mon, 02 Jun 2025 00:00:00 +0800</pubDate>
      <guid>http://localhost:1313/posts/article_20250625001/</guid>
      <description>&lt;p&gt;在資料科學領域中，企業舞弊偵測（Fraud Detection）經常被視為一個分類問題：輸入財務數據，輸出舞弊或非舞弊。然而，真正深入研究後你會發現，這個問題遠比表面上的「二元分類」來得複雜，也更具挑戰性。&lt;/p&gt;&#xA;&lt;p&gt;我目前的研究焦點，就是運用資料科學與人工智慧方法，解決財務報表舞弊偵測的問題。這個議題與銀行中的信用卡詐欺、保險業中的理賠舞弊、甚至洗錢行為有相似之處：都是稀有事件、後知後覺、動態進化的「敵對性問題」。&lt;/p&gt;&#xA;&lt;p&gt;為什麼這不是一個單純的分類問題？&lt;/p&gt;&#xA;&lt;p&gt;在傳統機器學習框架下，分類問題的成功往往來自於充足的標註數據、清晰的邊界條件與相對穩定的資料分佈。然而，舞弊行為恰恰違反了這三項假設。&lt;/p&gt;&#xA;&lt;p&gt;我們可以從以下幾點具體說明：&#xA;•&#x9;極度不平衡的資料（Class Imbalance）&#xA;在實務資料中，舞弊案件往往只佔所有資料的極小比例，可能是千分之一、甚至萬分之一。這意味著如果你採用傳統的精確度（accuracy）作為衡量指標，模型即使完全忽略舞弊也能達到99%以上的準確率，但這顯然毫無意義。&#xA;•&#x9;標籤不完整且滯後揭露（Label Latency &amp;amp; Missing Labels）&#xA;很多舞弊行為要經過數月、甚至數年後才會被調查揭露，更遑論那些永遠未被發現的案件。這使得訓練資料的標籤具有高度不確定性，導致模型容易學到錯誤的決策邊界。&#xA;•&#x9;舞弊技術持續演化（Concept Drift）&#xA;犯罪者會根據監管與模型檢測方式持續更新手法，導致模型在部署後迅速失效。這使得即使當下訓練準確的模型，也難以長期維持效能。&#xA;•&#x9;異常並非來自單一特徵，而是整體脈絡的矛盾（Contextual Inconsistency）&#xA;財報舞弊往往不是單一財務指標異常，而是多個指標之間出現結構性不一致。例如：營收大增但現金流卻大減、獲利提升但存貨異常膨脹。這種多變量脈絡異常，遠比簡單的 outlier detection 更為複雜。&lt;/p&gt;&#xA;&lt;p&gt;⸻&lt;/p&gt;&#xA;&lt;p&gt;問題不是模型選得不夠好，而是問題設定錯了&lt;/p&gt;&#xA;&lt;p&gt;因此，如果僅停留在「用哪個模型比較準」、「要不要用 XGBoost 還是 LSTM」這種層級的思考，只會陷入技術細節的死胡同，無法解決核心困難。&lt;/p&gt;&#xA;&lt;p&gt;相反地，我認為更關鍵的兩個研究方向是：&#xA;•&#x9;如何讓 AI 自己找到潛在的舞弊標籤？&#xA;採用自監督學習（Self-Supervised Learning），不依賴人工標註，而是讓模型自行從大量正常樣本中學習「常態結構」，再對偏離常態的資料進行異常評分，進一步推論出可能的舞弊行為。&#xA;•&#x9;如何讓深度模型的決策可以被人類審計人員理解？&#xA;深度學習模型雖然強大，但往往是黑箱。導入可解釋性方法（如 SHAP、LIME、Attention 可視化），可以提升金融監理與內部稽核部門的信任與採用意願，也為模型導入實務場域鋪路。&lt;/p&gt;&#xA;&lt;p&gt;⸻&lt;/p&gt;&#xA;&lt;p&gt;這不只是建模問題，更是科學問題&lt;/p&gt;&#xA;&lt;p&gt;用 AI 解決舞弊，不是一場簡單的技術堆疊競賽，而是對整個金融風險邏輯、犯罪行為模式、以及資料特性深刻理解的綜合挑戰。&lt;/p&gt;&#xA;&lt;p&gt;這將是我博士研究的起點：&#xA;從理解問題本質出發，探索如何用 AI 技術建立可行的風險偵測系統，不只是要「分類得準」，更要讓人「信得過」。&lt;/p&gt;&#xA;&lt;p&gt;這是一條難走的路，但也因此充滿價值。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
