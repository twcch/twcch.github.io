<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>IThome 鐵人賽 2025 on 志謙&#39;s Blog</title>
    <link>http://twcch.io/tags/ithome-%E9%90%B5%E4%BA%BA%E8%B3%BD-2025/</link>
    <description>Recent content in IThome 鐵人賽 2025 on 志謙&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>zh-tw</language>
    <lastBuildDate>Fri, 01 Aug 2025 00:00:00 +0800</lastBuildDate>
    <atom:link href="http://twcch.io/tags/ithome-%E9%90%B5%E4%BA%BA%E8%B3%BD-2025/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>(Day 1) 介紹與準備</title>
      <link>http://twcch.io/posts/ironman_2025/articles_25072801/</link>
      <pubDate>Fri, 01 Aug 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/ironman_2025/articles_25072801/</guid>
      <description>&lt;p&gt;在學習機器學習 (Machine Learning) 的過程中，可能會陷入兩種極端，一種是只會調用套件 (套膜)，模型背後的機制一知半解，遇到問題只能「換模型試試看」，或者是過度陷入數學細節，花大量時間推導公式，卻無法轉化為實際應用與模型選擇能力。&lt;/p&gt;&#xA;&lt;p&gt;我本身是從商業分析背景轉入人工智慧領域的研究者。這段轉型過程中，逐漸體會到: 真正困難的不是學會用模型，而是理解模型為什麼有效、什麼時候該用、什麼時候該換、用了之後該觀察什麼訊號。這促使我開始重新梳理各類常見演算法的行為與應用邏輯。&lt;/p&gt;&#xA;&lt;p&gt;因此，我決定透過這次 iThome 鐵人賽的機會，整理與統整常見演算法的核心概念，並將每一篇視為一場與模型的深度對談。&lt;/p&gt;&#xA;&lt;h2 id=&#34;系列架構說明&#34;&gt;系列架構說明&lt;/h2&gt;&#xA;&lt;p&gt;本系列分為兩大部分:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;經典機器學習模型: 聚焦於 Regression、Classification、Clustering 等常見方法，強調模型背後的核心邏輯、適用情境與評估指標。&lt;/li&gt;&#xA;&lt;li&gt;深度學習模型: 介紹常見神經網路架構，如全連接神經網路 (FCNN)、CNN、RNN、Transformer 等，並探討它們對資料型態、任務種類的適應性與限制。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;每篇文章皆會包含模型概念說明與簡潔的 Python 範例實作，並聚焦於模型本身的行為與選擇策略，不深入探討資料前處理、特徵工程、模型調參、數學推導等高階內容，以避免模糊焦點。&lt;/p&gt;&#xA;&lt;h2 id=&#34;技術範圍與預期對象&#34;&gt;技術範圍與預期對象&lt;/h2&gt;&#xA;&lt;p&gt;本系列預設讀者已具備以下條件:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;具備基本 Python 語法能力&lt;/li&gt;&#xA;&lt;li&gt;具備 scikit-learn 基本建模流程&lt;/li&gt;&#xA;&lt;li&gt;對模型訓練、預測、評估具備初步理解&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;實作部分主要使用 scikit-learn、matplotlib 等工具。每篇將以簡單模擬資料為例，從建模、預測、評估到可視化依序進行，幫助讀者觀察模型行為並建立直覺。&lt;/p&gt;&#xA;&lt;h2 id=&#34;學習深度定位-聚焦在-level-23-之間&#34;&gt;學習深度定位: 聚焦在 Level 2–3 之間&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;等級&lt;/th&gt;&#xA;          &lt;th&gt;定義&lt;/th&gt;&#xA;          &lt;th&gt;在本系列的實踐目標&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Level 1&lt;/td&gt;&#xA;          &lt;td&gt;會用套件建模&lt;/td&gt;&#xA;          &lt;td&gt;✅ 使用 sklearn 等工具快速建模&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Level 2&lt;/td&gt;&#xA;          &lt;td&gt;理解模型的概念與原理&lt;/td&gt;&#xA;          &lt;td&gt;✅ 說得出每個模型的邏輯與核心機制&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Level 3&lt;/td&gt;&#xA;          &lt;td&gt;能比較模型優劣與應用場景選擇&lt;/td&gt;&#xA;          &lt;td&gt;✅ 理解適用時機、模型之間的 trade-off&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Level 4+&lt;/td&gt;&#xA;          &lt;td&gt;深入優化與理論推導&lt;/td&gt;&#xA;          &lt;td&gt;🚫 本系列不會深入涵蓋，建議另尋高階資源&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2 id=&#34;系列預告與進展節奏&#34;&gt;系列預告與進展節奏&lt;/h2&gt;&#xA;&lt;p&gt;本系列將以「一日一模型」為目標，每篇聚焦於一個經典或常見模型，從實用視角出發說明其:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;核心邏輯與設計理念&lt;/li&gt;&#xA;&lt;li&gt;適用情境與限制條件&lt;/li&gt;&#xA;&lt;li&gt;與其他模型的比較與選擇策略&lt;/li&gt;&#xA;&lt;li&gt;Python 範例實作與評估觀察&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;預計涵蓋模型範圍包括: Linear Regression、Polynomial Regression、Logistic Regression、SVM、KNN、Decision Tree、Random Forest、XGBoost、PCA、KMeans、FCNN、CNN、RNN、Transformer &amp;hellip; 等。&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 3) 多項式迴歸 (Polynomial Regression)</title>
      <link>http://twcch.io/posts/ironman_2025/articles_25073001/</link>
      <pubDate>Wed, 30 Jul 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/ironman_2025/articles_25073001/</guid>
      <description>&lt;p&gt;線性迴歸雖然簡單、實用，但它有一個明顯限制: 只能處理「線性關係」。一旦資料呈現彎曲、非線性趨勢，線性迴歸的預測能力會急劇下降，所以可以將 Linear Regression 搭配 Polynomial Features 的處理，來彌補這缺點，將線性迴歸擴展成多項式迴歸 (Polynomial Regression)，本文章會從三個部分來介紹多項式迴歸:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;多項式迴歸的核心概念與與線性模型的關聯&lt;/li&gt;&#xA;&lt;li&gt;模型行為與應用場景&lt;/li&gt;&#xA;&lt;li&gt;Python 實作與視覺化說明&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;-為什麼要學-polynomial-regression&#34;&gt;✅ 為什麼要學 Polynomial Regression?&lt;/h2&gt;&#xA;&lt;p&gt;在真實世界中，多數資料並非線性結構，例如:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;房價與面積: 可能呈現遞減邊際效應&lt;/li&gt;&#xA;&lt;li&gt;醫療劑量與治療效果: 過高或過低都可能無效&lt;/li&gt;&#xA;&lt;li&gt;財務指標與預測目標: 存在高階非線性關係&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Polynomial Regression 可以有效擴展線性模型的表現力，仍保有易解釋、易實作的優點，是進入非線性模型的重要第一站。&lt;/p&gt;&#xA;&lt;h2 id=&#34;-模型邏輯與核心概念&#34;&gt;🧠 模型邏輯與核心概念&lt;/h2&gt;&#xA;&lt;h3 id=&#34;-將線性模型升維&#34;&gt;📌 將線性模型「升維」&lt;/h3&gt;&#xA;&lt;p&gt;Polynomial Regression 並非建立新的模型，而是將原始特徵做「非線性轉換」，再使用線性迴歸進行學習。例如：&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;\hat{y} = \beta_0 + \beta_1 x + \beta_2 x^2 + \beta_3 x^3 + \dots + \beta_n x^n&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;這個模型仍然是線性模型 (對係數是線性的)，只是資料經過「多項式擴展」後可以擬合曲線。&lt;/p&gt;&#xA;&lt;h3 id=&#34;-使用-polynomialfeatures-進行轉換&#34;&gt;📌 使用 PolynomialFeatures 進行轉換&lt;/h3&gt;&#xA;&lt;p&gt;在 Python 中，可以透過 sklearn.preprocessing.PolynomialFeatures 將資料升維，然後套用 LinearRegression 模型。&lt;/p&gt;&#xA;&lt;h2 id=&#34;-適用場景與判斷指標&#34;&gt;🎯 適用場景與判斷指標&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;當資料有明顯的非線性趨勢 (彎曲形狀)&lt;/li&gt;&#xA;&lt;li&gt;需要一個可解釋、簡單但能處理非線性問題的模型&lt;/li&gt;&#xA;&lt;li&gt;可作為非線性問題的 baseline 模型，與樹模型或 XGBoost 進行比較&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;-模型評估指標&#34;&gt;📊 模型評估指標&lt;/h2&gt;&#xA;&lt;p&gt;與線性回歸相同:&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 2) 線性迴歸 (Linear Regression)</title>
      <link>http://twcch.io/posts/ironman_2025/articles_25072901/</link>
      <pubDate>Tue, 29 Jul 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/ironman_2025/articles_25072901/</guid>
      <description>&lt;p&gt;機器學習中的線性迴歸 (Linear Regression) 模型是最基礎、也最經典的機器學習模型之一，雖然它簡單，但是它是許多模型都是由線性迴歸模型延伸的，也是所有預測模型的入門門檻，本文章會從三個部分來介紹線性迴歸:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;為什麼要學 Linear Regression?&lt;/li&gt;&#xA;&lt;li&gt;線性迴歸的核心概念與行為特徵&lt;/li&gt;&#xA;&lt;li&gt;Python 實作與分析&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;-為什麼要學-linear-regression&#34;&gt;✅ 為什麼要學 Linear Regression?&lt;/h2&gt;&#xA;&lt;p&gt;雖然線性模型簡單，但它不僅存在於理論書本中。以下是幾個學習 Linear Regression 的現實理由:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;所有迴歸模型的基礎，包括 Ridge、Lasso、Elastic Net 都是它的延伸 (後續會介紹)&lt;/li&gt;&#xA;&lt;li&gt;許多商業應用中仍具有價值 (如: 預測銷售額、估算財務變數、解釋變數影響力)&lt;/li&gt;&#xA;&lt;li&gt;適合作為 baseline 模型&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;簡單來說，學好 Linear Regression，不只是學會一個模型，而是學會觀察資料與模型行為之間的互動。&lt;/p&gt;&#xA;&lt;h2 id=&#34;-模型邏輯與核心概念&#34;&gt;🧠 模型邏輯與核心概念&lt;/h2&gt;&#xA;&lt;h3 id=&#34;-目標是什麼&#34;&gt;📌 目標是什麼?&lt;/h3&gt;&#xA;&lt;p&gt;回歸模型有一個假設在於，資料集與所有其他未知的點會位於一個超平面之上 (即為線性關係)；若資料集為非線性關係，可能就必須要考慮其他模型。所以我們想要學一個函數 $f(x)$，這個函數是「線性的」，也就是:&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;\hat{y} = \beta_0 + \mathbf{x}^\top \boldsymbol{\beta}&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;其中:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;$\mathbf{x} = [x_1, x_2, \ldots, x_m]^\top \in \mathbb{R}^m$ 為特徵向量&lt;/li&gt;&#xA;&lt;li&gt;$\beta = [\beta_1, \beta_2, \ldots, \beta_m]^\top \in \mathbb{R}^m$ 為對應的係數向量&lt;/li&gt;&#xA;&lt;li&gt;$\beta_0 \in \mathbb{R}$ 為截距項 (intercept)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;這表示我們相信「每個變數的影響是線性可加的」。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
