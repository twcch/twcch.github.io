<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on 志謙&#39;s Blog</title>
    <link>http://localhost:1313/tags/machine-learning/</link>
    <description>Recent content in Machine Learning on 志謙&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>zh-tw</language>
    <lastBuildDate>Mon, 30 Jun 2025 00:00:00 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Machine Learning - Linear Regression 線性迴歸模型</title>
      <link>http://localhost:1313/projects/articles_25063001/</link>
      <pubDate>Mon, 30 Jun 2025 00:00:00 +0800</pubDate>
      <guid>http://localhost:1313/projects/articles_25063001/</guid>
      <description>&lt;p&gt;線性迴歸 (Linear Regression) 是機器學習中最經典且最基礎的模型之一。雖然它簡單，但在實務中仍廣泛應用於預測與解釋變數間的線性關係，是資料分析、商業預測與建模的入門第一步。本文將從概念、數學推導到 Python 實作，一步步帶你理解線性迴歸的運作邏輯與應用情境。&lt;/p&gt;&#xA;&lt;h1 id=&#34;為什麼要學線性迴歸&#34;&gt;為什麼要學線性迴歸?&lt;/h1&gt;&#xA;&lt;p&gt;在進入複雜模型之前，我們需要能「看懂資料」和「解釋預測結果」。線性迴歸具備以下優點：&#xA;•&#x9;模型可解釋性強：每個係數都能代表一個變數的影響方向與強度&#xA;•&#x9;訓練速度快：不需大量計算資源&#xA;•&#x9;是進階模型的基礎：許多模型（如 Logistic Regression、Ridge、Lasso）都可視為線性迴歸的變體&lt;/p&gt;&#xA;&lt;h1 id=&#34;線性迴歸的基本概念&#34;&gt;線性迴歸的基本概念&lt;/h1&gt;&#xA;&lt;p&gt;線性迴歸的目標，是找到一條最佳直線，讓它能最小化預測值與真實值之間的誤差。&lt;/p&gt;&#xA;&lt;p&gt;假設有一筆資料:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;輸入特徵 (feature): x&lt;/li&gt;&#xA;&lt;li&gt;目標變數 (target): y&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;線性迴歸模型可寫作:&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;\hat{y} = w x + b&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;其中:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;$\hat{y}$ 為模型預測值&lt;/li&gt;&#xA;&lt;li&gt;$w$ 為權重 (斜率)&lt;/li&gt;&#xA;&lt;li&gt;$b$ 為偏差項 (截距)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;對於多變數情況 (Multivariate Linear Regression):&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;\hat{y} = w_1 x_1 + w_2 x_2 + \cdots + w_n x_n + b = \mathbf{w}^T \mathbf{x} + b&#xA;$$&lt;/p&gt;&#xA;&lt;h1 id=&#34;模型學習原理-最小化損失函數&#34;&gt;模型學習原理: 最小化損失函數&lt;/h1&gt;&#xA;&lt;p&gt;線性迴歸的學習過程是「找出一組參數 $(w, b)$ 使預測值 $\hat{y}$ 盡可能接近真實值 $y$」。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
