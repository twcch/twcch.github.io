<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Science on 志謙&#39;s Blog</title>
    <link>http://twcch.io/tags/data-science/</link>
    <description>Recent content in Data Science on 志謙&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>zh-tw</language>
    <lastBuildDate>Thu, 31 Jul 2025 00:00:00 +0800</lastBuildDate>
    <atom:link href="http://twcch.io/tags/data-science/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>(Day 2) 線性迴歸 (Linear Regression)</title>
      <link>http://twcch.io/posts/ironman_2025/articles_25073101/</link>
      <pubDate>Thu, 31 Jul 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/ironman_2025/articles_25073101/</guid>
      <description>&lt;p&gt;線性迴歸 (Linear Regression) 是統計學中的一種預測方法，主要分為簡單線性迴歸 (Simple Linear Regression) 與多元線性迴歸 (Multiple Linear Regression)，又稱複迴歸，以及其他變形的迴歸等，但在線性迴歸中，通常會有 1~N 個自變數 (Independent Variable) X，也可以稱作特徵 (Feature)；和 1 個因變數 (Dependent Variable) Y，也可以稱作目標 (Target)。而最終目的就是找出一條最佳迴歸線，來擬合這些數據點，便可以用來預測未來的數據點。&lt;/p&gt;&#xA;&lt;h2 id=&#34;模型介紹&#34;&gt;模型介紹&lt;/h2&gt;&#xA;&lt;h3 id=&#34;模型邏輯與核心概念&#34;&gt;模型邏輯與核心概念&lt;/h3&gt;&#xA;&lt;h4 id=&#34;線性迴歸假設&#34;&gt;線性迴歸假設&lt;/h4&gt;&#xA;&lt;p&gt;統計學線性迴歸的經典的五大假設:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;線性關係: 自變數與因變數之間存在線性關係&lt;/li&gt;&#xA;&lt;li&gt;誤差項獨立 (Independence): 誤差項之間沒有相互關係&lt;/li&gt;&#xA;&lt;li&gt;同標準差性 (Homoscedasticity): 對於所有的自變數，誤差項具有相同的標準差&lt;/li&gt;&#xA;&lt;li&gt;誤差項常態性 (Normality of Errors): 誤差項應該成常態分佈&lt;/li&gt;&#xA;&lt;li&gt;高度共線性 (Multicollinearity): 自變數間高度線性相關&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;看到這邊會想說，為什麼要特別註明統計學? 跟機器學習無關? 先記住一句話「統計學重推論，機器學習重預測」，很多假設跟機器學習中的線性迴歸模型還真的沒有太大的關係，但是也不代表，機器學習模型完全沒有假設，但是相對比較不重要，這也是為什麼很多仿間的機器學習教材都會忽略假設這塊。&lt;/p&gt;&#xA;&lt;p&gt;總而言之，機器學習模型不像統計學模型需要那麼嚴謹的假設，但是若違反某些假設，也是會影響機器學習模型的表現，也會使得模型只能用於預測，無法用於推論，以下簡單整理假設對統計模型與機器學習模型的影響:&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;假設&lt;/th&gt;&#xA;          &lt;th&gt;對傳統統計模型影響&lt;/th&gt;&#xA;          &lt;th&gt;對機器學習影響&lt;/th&gt;&#xA;          &lt;th&gt;建議處理方式&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;線性關係&lt;/td&gt;&#xA;          &lt;td&gt;✅ 極高 (核心假設)&lt;/td&gt;&#xA;          &lt;td&gt;❌ 可忽略 (可透過特徵轉換處理)&lt;/td&gt;&#xA;          &lt;td&gt;用非線性模型 / 特徵轉換&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;誤差獨立性&lt;/td&gt;&#xA;          &lt;td&gt;✅ 高 (推論與解釋需此條件支持)&lt;/td&gt;&#xA;          &lt;td&gt;✅ 高 (對 generalization 有直接影響)&lt;/td&gt;&#xA;          &lt;td&gt;使用適當資料分割策略&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;同變異性&lt;/td&gt;&#xA;          &lt;td&gt;✅ 中高 (影響參數估計的信度)&lt;/td&gt;&#xA;          &lt;td&gt;❌ 可忽略 (模型的估計值仍然準，但 p-value、CI 失真)&lt;/td&gt;&#xA;          &lt;td&gt;變數轉換、加權最小平方法&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;誤差常態性&lt;/td&gt;&#xA;          &lt;td&gt;✅ 中高 (特定推論工具須常態性支持)&lt;/td&gt;&#xA;          &lt;td&gt;❌ 可忽略&lt;/td&gt;&#xA;          &lt;td&gt;若僅做預測可忽略&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;共線性&lt;/td&gt;&#xA;          &lt;td&gt;✅ 高 (嚴重影響模型可解釋性與推論)&lt;/td&gt;&#xA;          &lt;td&gt;❌ 可忽略 (但建議修正以利解釋)&lt;/td&gt;&#xA;          &lt;td&gt;VIF、降維、正則化&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h4 id=&#34;運作原理&#34;&gt;運作原理&lt;/h4&gt;&#xA;&lt;p&gt;我們先回到線性迴歸的用途與目的，簡單來說就是「找出一條最佳直線，來擬合這些數據點，便可以用來預測未來的數據點」，如何找出最佳直線? 本文會簡單的介紹一下，詳細過程與原理，再請讀者自行尋找其他資源暸解。&lt;/p&gt;</description>
    </item>
    <item>
      <title>(Day 1) 介紹與準備</title>
      <link>http://twcch.io/posts/ironman_2025/articles_25073001/</link>
      <pubDate>Wed, 30 Jul 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/ironman_2025/articles_25073001/</guid>
      <description>&lt;p&gt;在學習機器學習 (Machine Learning) 的過程中，可能會陷入兩種極端，一種是只會調用套件 (套膜)，模型背後的機制一知半解，遇到問題只能「換模型試試看」，或者是過度陷入數學細節，花大量時間推導公式，卻無法轉化為實際應用與模型選擇能力。&lt;/p&gt;&#xA;&lt;p&gt;我本身是從商業分析背景轉入人工智慧領域的研究者。這段轉型過程中，逐漸體會到: 真正困難的不是學會用模型，而是理解模型為什麼有效、什麼時候該用、什麼時候該換、用了之後該觀察什麼訊號。這促使我開始重新梳理各類常見演算法的行為與應用邏輯。&lt;/p&gt;&#xA;&lt;p&gt;因此，我決定透過這次 iThome 鐵人賽的機會，整理與統整常見演算法的核心概念，並將每一篇視為一場與模型的深度對談。&lt;/p&gt;&#xA;&lt;h2 id=&#34;系列架構說明&#34;&gt;系列架構說明&lt;/h2&gt;&#xA;&lt;p&gt;本系列分為兩大部分:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;經典機器學習模型: 聚焦於 Regression、Classification、Clustering 等常見方法，強調模型背後的核心邏輯、適用情境與評估指標。&lt;/li&gt;&#xA;&lt;li&gt;深度學習模型: 介紹常見神經網路架構，如全連接神經網路 (FCNN)、CNN、RNN、Transformer 等，並探討它們對資料型態、任務種類的適應性與限制。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;每篇文章皆會包含模型概念說明與簡潔的 Python 範例實作，並聚焦於模型本身的行為與選擇策略，不深入探討資料前處理、特徵工程、模型調參、數學推導等高階內容，以避免模糊焦點。&lt;/p&gt;&#xA;&lt;h2 id=&#34;技術範圍與預期對象&#34;&gt;技術範圍與預期對象&lt;/h2&gt;&#xA;&lt;p&gt;本系列預設讀者已具備以下條件:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;具備基礎統計學與資料科學知識&lt;/li&gt;&#xA;&lt;li&gt;具備基本 Python 語法能力&lt;/li&gt;&#xA;&lt;li&gt;具備 scikit-learn, PyTorch, TensorFlow, Keras 基本建模流程&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;學習深度定位-聚焦在-level-23-之間&#34;&gt;學習深度定位: 聚焦在 Level 2–3 之間&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;等級&lt;/th&gt;&#xA;          &lt;th&gt;定義&lt;/th&gt;&#xA;          &lt;th&gt;在本系列的實踐目標&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Level 1&lt;/td&gt;&#xA;          &lt;td&gt;會用套件建模&lt;/td&gt;&#xA;          &lt;td&gt;✅ 使用 sklearn 等工具快速建模&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Level 2&lt;/td&gt;&#xA;          &lt;td&gt;理解模型的概念與原理&lt;/td&gt;&#xA;          &lt;td&gt;✅ 說得出每個模型的邏輯與核心機制&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Level 3&lt;/td&gt;&#xA;          &lt;td&gt;能比較模型優劣與應用場景選擇&lt;/td&gt;&#xA;          &lt;td&gt;✅ 理解適用時機、模型之間的 trade-off&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Level 4+&lt;/td&gt;&#xA;          &lt;td&gt;深入優化與理論推導&lt;/td&gt;&#xA;          &lt;td&gt;🚫 本系列不會深入涵蓋，建議另尋高階資源&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2 id=&#34;系列預告與進展節奏&#34;&gt;系列預告與進展節奏&lt;/h2&gt;&#xA;&lt;p&gt;本系列將以「一日一模型」為目標，每篇聚焦於一個經典或常見模型，從實用視角出發說明其:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;核心邏輯與設計理念&lt;/li&gt;&#xA;&lt;li&gt;適用情境與限制條件&lt;/li&gt;&#xA;&lt;li&gt;與其他模型的比較與選擇策略&lt;/li&gt;&#xA;&lt;li&gt;Python 範例實作與評估觀察&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;預計涵蓋模型範圍包括: Linear Regression、Polynomial Regression、Logistic Regression、SVM、KNN、Decision Tree、Random Forest、XGBoost、PCA、KMeans、FCNN、CNN、RNN、Transformer &amp;hellip; 等。&lt;/p&gt;</description>
    </item>
    <item>
      <title>為什麼用 AI 技術檢測企業舞弊，比想像中更困難？</title>
      <link>http://twcch.io/posts/articles_25060201/</link>
      <pubDate>Mon, 02 Jun 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/articles_25060201/</guid>
      <description>&lt;p&gt;在資料科學領域中，對企業進行舞弊檢測 (Fraud Detection) 被視為是一種分類問題: 輸入企業相關的數據，輸出舞弊或非舞弊。然而，真正投入研究後會發現，這個問題很難解決，非常具挑戰性。&lt;/p&gt;&#xA;&lt;p&gt;我目前主要研究方向，是運用人工智慧 (Artificial Intelligence) 技術，來解決企業進行財務報表舞弊的問題。這類型的議題與銀行信用卡詐欺、保險業中的理賠舞弊、甚至洗錢行為有相似之處，都是稀有事件、後知後覺、動態進化的「敵對性問題」。&lt;/p&gt;&#xA;&lt;h2 id=&#34;為什麼這不是一個單純的分類問題&#34;&gt;為什麼這不是一個單純的分類問題？&lt;/h2&gt;&#xA;&lt;p&gt;在傳統機器學習框架下，分類問題的成功往往來自於充足的標記數據、清晰的邊界條件與相對穩定的資料分佈。然而，舞弊行為恰恰違反了這三項假設。&lt;/p&gt;&#xA;&lt;p&gt;可以從以下幾點具體說明：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;極度不平衡的資料 (Class Imbalance)&lt;/p&gt;&#xA;&lt;p&gt;在實務資料中，舞弊案件往往只佔所有資料的極小比例，可能是千分之一、甚至萬分之一。這意味著如果你採用傳統的精確度 (accuracy) 作為衡量指標，模型即使完全忽略舞弊也能達到 99% 以上的準確率，但這顯然毫無意義。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;標籤不完整且滯後揭露 (Label Latency &amp;amp; Missing Labels)&lt;/p&gt;&#xA;&lt;p&gt;很多舞弊行為要經過數月、甚至數年後才會被調查揭露，更遑論那些永遠未被發現的案件。這使得訓練資料的標籤具有高度不確定性，導致模型容易學到錯誤的決策邊界。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;舞弊技術持續演化 (Concept Drift)&lt;/p&gt;&#xA;&lt;p&gt;犯罪者會根據監管與模型檢測方式持續更新手法，導致模型在部署後迅速失效。這使得即使當下訓練準確的模型，也難以長期維持效能。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;異常並非來自單一特徵，而是整體脈絡的矛盾 (Contextual Inconsistency)&lt;/p&gt;&#xA;&lt;p&gt;財報舞弊往往不是單一財務指標異常，而是多個指標之間出現結構性不一致。例如: 營收大增但現金流卻大減、獲利提升但存貨異常膨脹。這種多變量脈絡異常，遠比簡單的 outlier detection 更為複雜。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;問題不是模型選得不夠好而是問題設定錯了&#34;&gt;問題不是模型選得不夠好，而是問題設定錯了&lt;/h2&gt;&#xA;&lt;p&gt;如果僅停留在「用哪個模型比較準」、「要不要用 XGBoost 還是 LSTM」這種層級的思考，只會陷入技術細節的死胡同，無法解決核心困難。相反地，我認為更關鍵的兩個研究方向是：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;如何讓 AI 自己找到潛在的舞弊標籤？&lt;/p&gt;&#xA;&lt;p&gt;採用自監督學習 (Self-Supervised Learning)，不依賴人工標註，而是讓模型自行從大量正常樣本中學習「常態結構」，再對偏離常態的資料進行異常評分，進一步推論出可能的舞弊行為。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;如何讓深度模型的決策可以被人類審計人員理解？&lt;/p&gt;&#xA;&lt;p&gt;深度學習模型雖然強大，但往往是黑箱。導入可解釋性方法 (如 SHAP、LIME、Attention 可視化)，可以提升金融監理與內部稽核部門的信任與採用意願，也為模型導入實務場域鋪路。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;這不只是建模問題更是科學問題&#34;&gt;這不只是建模問題，更是科學問題&lt;/h2&gt;&#xA;&lt;p&gt;用 AI 解決舞弊，不是一場簡單的技術堆疊競賽，而是對整個金融風險邏輯、舞弊行為模式、以及資料特性深刻理解的綜合挑戰。這將是我博士研究的起點，從理解問題本質出發，探索如何用 AI 技術建立可行的風險偵測系統，不只是要「分類得準」，更要讓人「信得過」。我認為這是一條難走的路，但也因此充滿價值。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
