<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Science on 志謙&#39;s Blog</title>
    <link>http://twcch.io/tags/data-science/</link>
    <description>Recent content in Data Science on 志謙&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>zh-tw</language>
    <lastBuildDate>Fri, 18 Jul 2025 00:00:00 +0800</lastBuildDate>
    <atom:link href="http://twcch.io/tags/data-science/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>(Day 1) 為什麼我想使用機器學習技術建構企業風險預測模型?</title>
      <link>http://twcch.io/posts/ironman/2025/articles_25071801/</link>
      <pubDate>Fri, 18 Jul 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/ironman/2025/articles_25071801/</guid>
      <description>&lt;p&gt;我是 Alan，目前正準備投入博士班的人，研究主題聚焦在「使用透過機器學習與深度學習技術，預測企業是否有潛在的財務報表舞弊或信用風險」，在進行研究架構的構思過程中，我觀察到一個有趣的現象「這類風險預測問題，長期以來幾乎都是以學術研究的角度在探討」。&lt;/p&gt;&#xA;&lt;p&gt;然而在學術界重視模型的數學嚴謹性與實驗指標：AUC、F1-score、p-value、顯著性，但依照我的工作經驗告訴我，這些指標並不足以說服一位企業主管採用這個模型，因為現實世界中的使用者真正關心的是:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;模型的依據是什麼?&lt;/li&gt;&#xA;&lt;li&gt;預測結果可否追溯與解釋?&lt;/li&gt;&#xA;&lt;li&gt;它如何輔助我做更好、更快、更有依據的決策?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;我意識到模型的解釋性與決策可用性，才是風控模型從學術走向實務的關鍵缺口。因此，我決定&lt;strong&gt;利用 iThome 鐵人賽&lt;/strong&gt;，這 30 天的時間，啟動這項構想與驗證計畫:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;✅ 從公開財務報表資料出發（以 SimFin 為主）&lt;/li&gt;&#xA;&lt;li&gt;✅ 使用 Python、機器學習與深度學習技術建構預測模型&lt;/li&gt;&#xA;&lt;li&gt;✅ 特別強調模型的可解釋性 (Explainability)，以及其在決策輔助上的實際應用&lt;/li&gt;&#xA;&lt;li&gt;✅ 打造一個完整流程雛型: 從資料處理 → 特徵建構 → 模型訓練 → 結果輸出 → 風險報告生成&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;這不只是我的技術訓練計畫，更是一個結合博士研究構想、資料科學實踐力、與職涯戰略的整合起點。我希望透過這 30 天，把抽象的研究問題具象化、模組化，建立出一套可驗證、可調整、可延伸的 AI 預測原型。過程中，我不會隱藏失敗與低準確率，而是會如實紀錄與反思，並逐步優化整體架構。&lt;/p&gt;&#xA;&lt;h2 id=&#34;-為什麼要自己動手建構一個風險模型&#34;&gt;🧠 為什麼要「自己動手建構一個風險模型」?&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;1. 📉 財務風險其實到處都是，但沒有警示系統&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;企業財務狀況的惡化，是一個漸進的過程，如:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;當企業營收持續下降，毛利率走低，負債比上升，現金流緊縮 …&lt;/li&gt;&#xA;&lt;li&gt;這些早就能預告潛在風險，但沒有一個系統能&lt;strong&gt;量化風險程度&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;我希望建立一個系統: 看到財務報表，就能給出一個風險分數，甚至指出主要的危險因子。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;2. 🛠 學機器學習、深度學習，不能只看書和跑範例&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;很多人學機器學習都停留在:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;用 scikit-learn 跑跑 Titanic&lt;/li&gt;&#xA;&lt;li&gt;用 XGBoost 分類紅酒或鳶尾花&lt;/li&gt;&#xA;&lt;li&gt;DL 只用來跑圖像辨識或玩 ChatGPT API&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;但我認為成為能解決真實問題的資料科學家或是機器學習工程師等，就必須從「問題定義 → 資料建構 → 模型選擇 → 可解釋性分析 → 應用輸出」來進行一個完整的流程。&lt;/p&gt;</description>
    </item>
    <item>
      <title>為什麼用 AI 技術檢測企業舞弊，比想像中更困難？</title>
      <link>http://twcch.io/posts/articles_25060201/</link>
      <pubDate>Mon, 02 Jun 2025 00:00:00 +0800</pubDate>
      <guid>http://twcch.io/posts/articles_25060201/</guid>
      <description>&lt;p&gt;在資料科學領域中，對企業進行舞弊檢測 (Fraud Detection) 被視為是一種分類問題: 輸入企業相關的數據，輸出舞弊或非舞弊。然而，真正投入研究後會發現，這個問題很難解決，非常具挑戰性。&lt;/p&gt;&#xA;&lt;p&gt;我目前主要研究方向，是運用人工智慧 (Artificial Intelligence) 技術，來解決企業進行財務報表舞弊的問題。這類型的議題與銀行信用卡詐欺、保險業中的理賠舞弊、甚至洗錢行為有相似之處，都是稀有事件、後知後覺、動態進化的「敵對性問題」。&lt;/p&gt;&#xA;&lt;h2 id=&#34;為什麼這不是一個單純的分類問題&#34;&gt;為什麼這不是一個單純的分類問題？&lt;/h2&gt;&#xA;&lt;p&gt;在傳統機器學習框架下，分類問題的成功往往來自於充足的標記數據、清晰的邊界條件與相對穩定的資料分佈。然而，舞弊行為恰恰違反了這三項假設。&lt;/p&gt;&#xA;&lt;p&gt;可以從以下幾點具體說明：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;極度不平衡的資料 (Class Imbalance)&lt;/p&gt;&#xA;&lt;p&gt;在實務資料中，舞弊案件往往只佔所有資料的極小比例，可能是千分之一、甚至萬分之一。這意味著如果你採用傳統的精確度 (accuracy) 作為衡量指標，模型即使完全忽略舞弊也能達到 99% 以上的準確率，但這顯然毫無意義。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;標籤不完整且滯後揭露 (Label Latency &amp;amp; Missing Labels)&lt;/p&gt;&#xA;&lt;p&gt;很多舞弊行為要經過數月、甚至數年後才會被調查揭露，更遑論那些永遠未被發現的案件。這使得訓練資料的標籤具有高度不確定性，導致模型容易學到錯誤的決策邊界。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;舞弊技術持續演化 (Concept Drift)&lt;/p&gt;&#xA;&lt;p&gt;犯罪者會根據監管與模型檢測方式持續更新手法，導致模型在部署後迅速失效。這使得即使當下訓練準確的模型，也難以長期維持效能。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;異常並非來自單一特徵，而是整體脈絡的矛盾 (Contextual Inconsistency)&lt;/p&gt;&#xA;&lt;p&gt;財報舞弊往往不是單一財務指標異常，而是多個指標之間出現結構性不一致。例如: 營收大增但現金流卻大減、獲利提升但存貨異常膨脹。這種多變量脈絡異常，遠比簡單的 outlier detection 更為複雜。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;問題不是模型選得不夠好而是問題設定錯了&#34;&gt;問題不是模型選得不夠好，而是問題設定錯了&lt;/h2&gt;&#xA;&lt;p&gt;如果僅停留在「用哪個模型比較準」、「要不要用 XGBoost 還是 LSTM」這種層級的思考，只會陷入技術細節的死胡同，無法解決核心困難。相反地，我認為更關鍵的兩個研究方向是：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;如何讓 AI 自己找到潛在的舞弊標籤？&lt;/p&gt;&#xA;&lt;p&gt;採用自監督學習 (Self-Supervised Learning)，不依賴人工標註，而是讓模型自行從大量正常樣本中學習「常態結構」，再對偏離常態的資料進行異常評分，進一步推論出可能的舞弊行為。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;如何讓深度模型的決策可以被人類審計人員理解？&lt;/p&gt;&#xA;&lt;p&gt;深度學習模型雖然強大，但往往是黑箱。導入可解釋性方法 (如 SHAP、LIME、Attention 可視化)，可以提升金融監理與內部稽核部門的信任與採用意願，也為模型導入實務場域鋪路。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;這不只是建模問題更是科學問題&#34;&gt;這不只是建模問題，更是科學問題&lt;/h2&gt;&#xA;&lt;p&gt;用 AI 解決舞弊，不是一場簡單的技術堆疊競賽，而是對整個金融風險邏輯、舞弊行為模式、以及資料特性深刻理解的綜合挑戰。這將是我博士研究的起點，從理解問題本質出發，探索如何用 AI 技術建立可行的風險偵測系統，不只是要「分類得準」，更要讓人「信得過」。我認為這是一條難走的路，但也因此充滿價值。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
