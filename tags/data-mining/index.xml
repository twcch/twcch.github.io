<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Mining on 志謙&#39;s Blog</title>
    <link>https://twcch.github.io/tags/data-mining/</link>
    <description>Recent content in Data Mining on 志謙&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>zh-heat</language>
    <lastBuildDate>Sat, 06 Sep 2025 00:00:00 +0800</lastBuildDate>
    <atom:link href="https://twcch.github.io/tags/data-mining/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>數據分析師的洞察之眼關聯分析</title>
      <link>https://twcch.github.io/posts/2025/when-data-starts-to-connect/</link>
      <pubDate>Sat, 06 Sep 2025 00:00:00 +0800</pubDate>
      <guid>https://twcch.github.io/posts/2025/when-data-starts-to-connect/</guid>
      <description>&lt;p&gt;關聯規則探勘，是一門讓資料自己開口說話的技術。它不預測未來，也不分類人群，而是靜靜地從無數筆交易中，尋找那些「總是一起出現」的痕跡。對數據分析師而言，這是一種不同於統計假設的思考方式——它不帶偏見，不設方向，只追隨共現的規律。&lt;/p&gt;&#xA;&lt;h2 id=&#34;啤酒與尿布的啟示&#34;&gt;啤酒與尿布的啟示&lt;/h2&gt;&#xA;&lt;p&gt;許多人第一次聽到「關聯規則探勘」 (Association Rule Mining) 這個名詞時，總會想起那個幾乎被引用成神話的故事。美國某家超市在分析顧客購物資料時，發現一個奇特的現象: 購買尿布的男性顧客，常常會順手買一瓶啤酒。&lt;/p&gt;&#xA;&lt;p&gt;當時的分析師並沒有先入為主地設定假設，他們只是單純讓演算法在龐大的交易資料中尋找共現的規律。結果揭露了一種不易察覺的生活節奏——年輕父親在深夜購物時，會同時買尿布與啤酒。這個行為的背後，不是消費理性，而是情緒的慰藉。&lt;/p&gt;&#xA;&lt;p&gt;這便是關聯規則探勘的精神所在: 它讓資料說話，而不是讓人去強迫資料符合預設的故事。在數據分析的世界裡，這種從共現關係中發現行為模式的方法，被廣泛應用於零售、金融、醫療、甚至網路內容推薦系統中。&lt;/p&gt;&#xA;&lt;h2 id=&#34;從購物籃看行為&#34;&gt;從購物籃看行為&lt;/h2&gt;&#xA;&lt;p&gt;想像一間超市的銷售資料表，每一筆交易就像一個購物籃 (basket)，裡面放著當次顧客購買的所有商品。我們想知道的問題其實很簡單:「哪些商品會經常一起被買走?」在資料的語言裡，這樣的問題就是「項目之間的共現關係」。&lt;/p&gt;&#xA;&lt;div class=&#34;callout note &#34;&gt;&#xA;  &lt;p&gt;若 20% 的交易同時出現牛奶與麵包，那麼這個組合的支持度 (support) 就是 0.2。如果在所有買牛奶的顧客中，有 80% 也買了麵包，則這條規則的信賴度 (confidence) 是 0.8。&lt;/p&gt;&#xA;&lt;p&gt;但僅憑這兩個數值，我們還無法判斷這是否只是巧合。因此分析師還會觀察第三個指標「提升度 (lift)」，即實際共現機率與隨機共現機率的比值。&lt;/p&gt;&#xA;&lt;p&gt;當 lift 大於 1，代表兩個項目之間的關聯比隨機還強；若小於 1，則可能互斥。這三個指標——support、confidence、lift——構成了關聯規則探勘的基礎語彙。&lt;/p&gt;&#xA;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;h2 id=&#34;apriori-從最常見的開始&#34;&gt;Apriori: 從最常見的開始&lt;/h2&gt;&#xA;&lt;p&gt;在技術層面上，最經典的演算法是 Apriori。它的核心思想很直觀:「若一個項目集是頻繁的 (Frequent Itemset)，那麼它的子集一定也是頻繁的。」&lt;/p&gt;&#xA;&lt;p&gt;這個原則讓我們得以從最基本的一項商品開始，逐步生成兩項、三項組合，並在每一層過濾不常見的組合，直到再也無法擴展。&lt;/p&gt;&#xA;&lt;p&gt;舉例來說，我們可以用 Python 的 mlxtend 套件進行實作:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pandas&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;pd&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;mlxtend.frequent_patterns&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;apriori&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;association_rules&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 模擬交易資料 (每列為一筆交易，每欄為商品)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;DataFrame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;columns&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;milk&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;bread&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;beer&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;butter&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;diaper&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Step 1: 找出頻繁項集&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;frequent_itemsets&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;apriori&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;df&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;min_support&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;use_colnames&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Step 2: 產生關聯規則&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;rules&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;association_rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;frequent_itemsets&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;metric&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;lift&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;min_threshold&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;rules&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;lift&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;antecedents&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;consequents&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;support&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;confidence&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;lift&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]])&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;輸出結果可能如下:&lt;/p&gt;</description>
    </item>
    <item>
      <title>在數據中尋找秩序，資料探勘的藝術</title>
      <link>https://twcch.github.io/posts/2025/order-in-the-chaos-of-data/</link>
      <pubDate>Sat, 02 Aug 2025 00:00:00 +0800</pubDate>
      <guid>https://twcch.github.io/posts/2025/order-in-the-chaos-of-data/</guid>
      <description>&lt;p&gt;資料探勘 (Data Mining) 是一場從混沌到洞察的旅程，它的核心不只是技術，而是一種思考方式——如何讓資料自己說話，如何從龐大的資訊中找出值得理解的模式，對數據分析師而言，資料探勘不只是「處理資料」，而是「與資料對話」。&lt;/p&gt;&#xA;&lt;h2 id=&#34;資料探勘的先備知識&#34;&gt;資料探勘的先備知識&lt;/h2&gt;&#xA;&lt;p&gt;在開始資料探勘之前，我們需要理解它的理論基礎，資料探勘並非單一技術，而是多個學科的交會點:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;統計學 (Statistics): 提供對資料分佈、變異與相關的量化理解，確保模型結果具可解釋性。&lt;/li&gt;&#xA;&lt;li&gt;機器學習 (Machine Learning): 提供自動化演算法，從資料中學習模式並進行預測。&lt;/li&gt;&#xA;&lt;li&gt;資料庫系統 (Database Systems): 讓我們能有效率地儲存、檢索與處理大規模資料。&lt;/li&gt;&#xA;&lt;li&gt;資訊視覺化 (Data Visualization): 幫助分析師以直覺方式觀察結構與異常，將複雜資料轉化為可理解的圖像。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;這些領域共同構成資料探勘的基礎，使分析師既能理解數學邏輯，也能掌握資料結構與商業語境，換言之，資料探勘的專業是「跨界的知識整合」。&lt;/p&gt;&#xA;&lt;h2 id=&#34;從資料到知識-探勘的本質&#34;&gt;從資料到知識: 探勘的本質&lt;/h2&gt;&#xA;&lt;p&gt;在商業世界裡，資料無所不在，交易紀錄、網站點擊、感測器訊號、醫療紀錄、社群互動——  這些原始資料就像尚未雕琢的石塊，只有經過提煉與建模，才能顯露出價值。&lt;/p&gt;&#xA;&lt;p&gt;資料探勘的任務，正是讓這些看似無序的碎片，拼出意義的圖像，我認為資料探勘的終極目標，不是找到答案，而是找到能啟發問題的模式，這種模式可能是一個潛在客群、一種異常行為、一組重複的事件序列，或是一個被忽略的關聯。它們都是資料在對我們說：「這裡有值得關注的事。」&lt;/p&gt;&#xA;&lt;h2 id=&#34;資料建模流程-從混沌到結構&#34;&gt;資料建模流程: 從混沌到結構&lt;/h2&gt;&#xA;&lt;p&gt;一個成熟的資料探勘專案，通常包含以下五個階段，這不僅是一套技術流程，更是一種分析思維的框架:&lt;/p&gt;&#xA;&lt;h3 id=&#34;問題定義-problem-definition&#34;&gt;問題定義 (Problem Definition)&lt;/h3&gt;&#xA;&lt;p&gt;資料探勘的起點從來不是資料，而是問題，分析師必須明確回答：「我要解決什麼？」、「我關心的現象是什麼？」，因為清晰的問題定義是所有模型的方向盤。&lt;/p&gt;&#xA;&lt;p&gt;如在商業場景中，這可能是「提高留存率」、「預測顧客流失」或「辨識詐欺行為」；在研究場景中，則可能是「發現新的疾病特徵」或「理解群體行為模式」。&lt;/p&gt;&#xA;&lt;h3 id=&#34;資料蒐集與整合-data-collection--integration&#34;&gt;資料蒐集與整合 (Data Collection &amp;amp; Integration)&lt;/h3&gt;&#xA;&lt;p&gt;資料通常分散在不同來源: 資料庫、API、感測器、或外部平台，探勘的第一步是將這些異質資料整合成可用的結構。&lt;/p&gt;&#xA;&lt;p&gt;這個階段強調資料的「廣度」，因為只有跨域整合，才能看見真正的關聯，正確的資料架構，是所有建模的基礎。&lt;/p&gt;&#xA;&lt;h3 id=&#34;資料清理與前處理-data-cleaning--preprocessing&#34;&gt;資料清理與前處理 (Data Cleaning &amp;amp; Preprocessing)&lt;/h3&gt;&#xA;&lt;p&gt;在現實中，資料是混亂的: 有缺失值、重複值、異常點與不一致的格式，分析師必須進行去噪、正規化、轉換與編碼，使資料能夠被模型正確理解，這個階段決定模型的「穩定性」，就像建築的地基——看不見，但至關重要。&lt;/p&gt;&#xA;&lt;h3 id=&#34;建模與探勘-modeling--mining&#34;&gt;建模與探勘 (Modeling &amp;amp; Mining)&lt;/h3&gt;&#xA;&lt;p&gt;當資料準備就緒，真正的探勘才開始，依照問題性質，我們可能採用不同的建模策略:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;描述性模型 (Descriptive Models) 揭示資料的結構，如分群與關聯規則。&lt;/li&gt;&#xA;&lt;li&gt;預測性模型 (Predictive Models) 預測未來行為，如分類與回歸分析。&lt;/li&gt;&#xA;&lt;li&gt;異常偵測模型 (Anomaly Detection Models) 找出與常態不同的模式，用於詐欺或風險預警。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;在這一階段，分析師不僅選擇演算法，更要確保模型的假設與資料特性相符，演算法只是工具，理解資料才是核心。&lt;/p&gt;&#xA;&lt;h3 id=&#34;評估與詮釋-evaluation--interpretation&#34;&gt;評估與詮釋 (Evaluation &amp;amp; Interpretation)&lt;/h3&gt;&#xA;&lt;p&gt;一個模型的成功，取決於它能否「解釋現實」，而不僅是數學上的優越，因此，我們不僅評估準確率或 AUC，更關心模型是否能轉化為可行的洞察。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
