

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

[{"content":"多元分類任務驗證指標就只是從二元分類任務驗證指標延伸而來，核心概念一樣是二元分類任務驗證指標，而兩者只是在計算內容上有些許差異，所以指標仍然是 Accuracy、Recall、F1-score 等，所以請讀者先將二元分類任務驗證指標熟練後再來看。\n指標介紹 混淆矩陣 (Confusion Matrix) 假設我們有 3 個類別 [A, B, C]，模型的預測結果如下:\n實際 \\ 預測 A B C A 50 2 3 B 4 45 1 C 5 2 43 列 (row) = 實際標籤 行 (column) = 模型預測 對角線 (50、45、43) = 預測正確的數量 從多元分類矩陣取出 TP / FP / FN / TN 對單一類別 (One-vs-All)，例如要計算「類別 A」的指標:\nTP_A = 混淆矩陣中 A–A 的數字 = 50 FP_A = 預測為 A 但實際不是 A 的數字總和 = 4 (B→A) + 5 (C→A) = 9 FN_A = 實際為 A 但預測不是 A 的數字總和 = 2 (A→B) + 3 (A→C) = 5 TN_A = 其他所有正確分類的數字 = 全部總數 - (TP_A + FP_A + FN_A) 這樣每個類別都能得到對應的 TP、FP、FN、TN\n","date":"10 August 2025","permalink":"http://twcch.io/posts/column_article/ironman_2025_30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/articles_25081001/","title":"(Day 12) 多元分類任務驗證指標"},{"content":"分類任務有混淆矩陣作為指標的核心基礎，迴歸任務則建立在誤差分佈 (Error Distribution) 之上。所有迴歸指標，都是在真實值與預測值的差異上進行數學運算。迴歸的評估相對分類簡單，沒有多種 TP、FP 的組合，但每個指標關注的面向、對異常值的敏感度、在商業決策上的意義卻各有不同。\n誤差的基本概念 回歸任務中，誤差 (Error) 定義為: $$ e_i = y_i - \\hat{y}_i $$\n其中:\n$y_i$: 第 i 筆資料的真實值 $\\hat{y}_i$: 模型的預測值 $e_i$: 第 i 筆的殘差 (Residual) 所有回歸評估指標，都是將 $e_i$ 做數學運算後的結果。\n常見回歸驗證指標 Mean Squared Error (MSE) 將每個誤差平方後取平均。平方的動作會讓大誤差的影響成倍放大，因此 MSE 對異常值 (outlier) 非常敏感。\n$$ MSE = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 $$\n特性分析\n誤差平方 → 大誤差懲罰重，小誤差影響相對被稀釋。 單位為「原單位的平方」，如價格 (元) 預測的 MSE 單位是「元²」，因此不易直接解讀大小。 優點\n適合用在不能容忍大誤差的場景，例如財務風險控管 (預測錯 10 倍金額的後果極其嚴重)。 在模型優化 (特別是最小平方法回歸) 中，MSE 作為損失函數具有良好數學性質 (平滑、可微分)。 缺點\n","date":"10 August 2025","permalink":"http://twcch.io/posts/column_article/ironman_2025_30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/articles_25081101-copy/","title":"(Day 13) 迴歸任務驗證指標"},{"content":"今天要介紹的是常見的分類任務驗證指標，會以二元分類問題為例，因為多元分類也是用相同的指標，只是計算方式會有所不同而已，預計會用 2-3 天的篇幅介紹完，分類與迴歸任務的驗證指標；先給各位讀者一個正確的觀念，選指標時必須回到業務背景與資料特性，不要迷信某個數值越高越好，真正有價值的模型評估，是能在技術表現與業務需求之間找到平衡。\n指標介紹 混淆矩陣 (Confusion Matrix) 分類任務的所有核心指標，幾乎都來自 Confusion Matrix，它是用來統計分類模型在測試集上的結果，Confusion Matrix 在 Binary Classification 問題上，它是一個 2x2 表格:\nTrue Condition - Positive True Condition - Negative Predict Outcome - Positive TP (True Positve) FP (False Positve) (誤報) Predict Outcome - Negative FN (False Negative) (漏報) TN (True Negative) TP: 實際是 Positive，模型也預測 Positive (預測正確) TN: 實際是 Negative，模型也預測 Negative (預測正確) FP: 實際是 Negative，但模型預測 Positive (誤報 / 假警報) (Type I error) FN: 實際是 Positive，但模型預測 Negative (漏報 / 漏檢) (Type II error) Accuracy (準確率) $$ Accuracy = \\frac{TP + TN}{TP + TN + FP + FN} $$\n","date":"9 August 2025","permalink":"http://twcch.io/posts/column_article/ironman_2025_30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/articles_25080901/","title":"(Day 11) 二元分類任務驗證指標"},{"content":"終於來到 SVM，這也是本系列介紹 Machine Learning 中分類演算法的最後一個，當然在機器學習中還有很多的監督式分類演算法，我個人認為相對沒我介紹的這幾個經典，就留給讀者自行學習。從明天開始到進入樹模型之前，我會補充一下，模型 Validation Index 的內容 (用來衡量模型結果好不好)，因為前面飆的有點快，後來有發現這部分也很重要，預計會花 2 ~ 3 天的篇幅來介紹。\n我們就進入正題，支援向量機 (Support Vector Machine) 是一種監督式學習演算法，泛指支援向量機演算法框架，透過在特徵空間中尋找最能分隔不同類別的超平面 (hyperplane)，並最大化分類邊界 (margin)，可應用於:\n分類 (Classification) 回歸 (Regression) 異常檢測 (Anomaly Detection) 但是回歸的部分非常少用到 Support Vector Regression 本系列就不說明這塊；至於異常檢測的應用又稱 OneClass SVM 目前沒有規劃，這是一種無監督式學習的技術，專門在做 Anomaly Detection 的任務，因為本系列規劃在樹模型介紹完成後，會進入深度學習篇章，所以 OneClass SVM 的部分如果後續有篇幅的話會再補充，如果沒有也請讀者自行學習；所以本篇會以 SVM 應用在分類任務 (Support Vector Classification) 上來詳細說明。\nSVM 解決了什麼問題? 在詳細介紹 SVM 之前，要先說明一下 SVM 到底要解決什麼問題，我們先回到 Day 5 介紹的 Logistic Regression，假設同一組數據做分類，可能會發生以下狀況，我們先看到 Logistic Regression 的部分，大家會發現看起來分類正確，但是那條線怎麼切得怪怪的，這也是 Logistic Regression 的問題，會造成模型泛化性不夠好，因為 Logistic Regression 對於這部分沒有進行處理。\n圖片來源: https://b5031631512567.medium.com/logistic-regression-羅吉斯回歸-support-vector-machine-svm-做a-b分類-82aa5e5edaf8\n","date":"8 August 2025","permalink":"http://twcch.io/posts/column_article/ironman_2025_30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/articles_25080801/","title":"(Day 10) 支援向量機 (Support Vector Machine)"},{"content":"前幾天的討論中，我們已經探討了迴歸分析、邏輯迴歸，以及最近兩天介紹的 K-Nearest Neighbors (KNN)。今天要討論的是另一種基礎且直覺性極強的分類演算法: 樸素貝氏分類器 (Naive Bayes Classifier)。儘管樸素貝氏分類器的基本原理非常簡單，甚至經常被視為基礎模型，但在實務應用中，它仍然是許多場合的首選，尤其是在文本分類領域，例如垃圾郵件分類與情感分析。\n模型介紹 模型邏輯與核心概念 Naive Bayes 的核心思想來自貝氏定理 (Bayes\u0026rsquo; Theorem):\n$$ P(y|X) = \\frac{P(X|y)P(y)}{P(X)} $$\n$P(y|X)$: 在給定特徵 $X$ 下的目標 $y$ 的後驗機率 (posterior probability) $P(X|y)$: 在已知目標 $y$ 下觀察到特徵 $X$ 的可能性 (likelihood) $P(y)$: 目標 $y$ 的先驗機率 (prior probability) $P(X)$: 觀察到特徵 $X$ 的總體機率 但直接計算 $P(X|y)$ 是困難的，尤其當特徵數量龐大且互相關聯時。因此 Naive Bayes 做了一個極簡的假設——「條件獨立假設 (Conditional Independence Assumption)」，即假設特徵之間彼此獨立:\n$$ P(X|y) = P(x_1|y) \\times P(x_2|y) \\times \\cdots \\times P(x_n|y) $$\n這個假設大幅簡化了問題，讓計算變得非常快速且易於實現。雖然這個假設在現實世界中往往不成立，但 Naive Bayes 的實務表現卻通常仍然相當穩健。\nNaive Bayes 常見種類 Gaussian Naive Bayes (高斯樸素貝氏): 假設特徵為連續數值，並服從高斯分布。 Multinomial Naive Bayes (多項式樸素貝氏): 特別適用於文本數據，特徵通常為計數 (例如詞頻)。 Bernoulli Naive Bayes (伯努利樸素貝氏): 特徵為二元變數 (例如詞的出現與否)。 適用情境 特徵數量大且離散，尤其文本分類 需要模型快速訓練與預測 基準模型 (Baseline Model) 的建立 限制條件 特徵之間存在強烈相關性時，效果可能較差 無法捕捉特徵之間的交互作用 模型實作 本次實作會以多項式 Naive Bayes 為例，因為它在文本分類中表現卓越，並且可展示 Naive Bayes 的強項: 速度快、表現穩定且容易理解。我們將使用經典的 SMS Spam Collection 資料集，透過 Naive Bayes 分辨垃圾訊息與正常訊息，這個過程就不過多敘述。\n","date":"7 August 2025","permalink":"http://twcch.io/posts/column_article/ironman_2025_30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/articles_25080701/","title":"(Day 9) 樸素貝氏分類器 (Naive Bayes Classifier)"},{"content":"K-近鄰 (K-Nearest Neighbors; KNN) 是一種很直學的機器學習演算法。它沒有模型參數、沒有訓練過程，卻可以在某些任務上有不錯的效果。它的核心理念只有一句話: 「你是誰，由你周圍最像你的人決定。」\nK-近鄰的預測邏輯其實就是投票機制。當一筆新資料進來時，K-近鄰會計算它與訓練集中每一筆資料的距離，選出最近的 K 筆，根據這些鄰居的標籤來進行分類或回歸。\n舉個例子，如果你住進一個新的社區，而這個社區 5 戶人家中有 4 戶都是教師，那麼你很可能也被視為教師。這就是K-近鄰的基本邏輯：用「距離」定義相似度，用「投票」進行預測。\n無需訓練、實作簡單 可處理多類別分類問題 非常適合 baseline 模型或少量資料的場景 模型介紹 模型邏輯與核心概念 運作原理 定義距離度量: 最常見的是歐幾里得距離。 標準化資料: 避免不同特徵尺度影響距離計算。 選擇 K 值: K 值太小容易過擬合，太大容易欠擬合。 查找最近鄰: 找出距離最近的 K 筆資料。 分類或回歸: 分類就多數決，回歸就取平均。 模型評估指標 Accuracy: 整體正確率 Precision / Recall / F1-score: 評估正例預測品質與召回 適用情境 資料量不大、特徵數量低的任務 資料本身具備明顯群聚性質 需要快速做出初步 baseline 的時候 限制條件 計算成本高 (尤其資料量大時) 對資料標準化非常敏感 高維度下效果會大幅下降 (維度災難) 模型實作 這個 K-近鄰的案例，我們來聊聊簡單的操參數實驗，我們先準備一組資料，這個過程就不過多敘述。\nimport numpy as np import matplotlib.pyplot as plt import seaborn as sns from sklearn.datasets import make_classification from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn.neighbors import KNeighborsClassifier from sklearn.metrics import accuracy_score, classification_report from sklearn.model_selection import cross_val_score # 資料產生 X, y = make_classification( n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, class_sep=1.2, random_state=42 ) # 資料分割與標準化 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) scaler = StandardScaler() X_train_std = scaler.fit_transform(X_train) 在建模的部分就跟之前不一樣，而是在外層寫了一個迴圈，因為 K-近鄰的 K 值，沒有人知道要用多少，K=1 表示我只抓最近的一個來比，完全就沒有那種投票的概念，所以 k 不應該選 1，再來是怕有平票的問題所以 k 會以奇數為主，而且 k 如果太小會有個問題，容易過擬合，越小越準，那怎麼辦? 所以這邊搭配了 Cross Validation 做設計，可以避免這個問題 (Cross Validation 請讀者自行找資源學習)。\n","date":"6 August 2025","permalink":"http://twcch.io/posts/column_article/ironman_2025_30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/articles_25080601/","title":"(Day 8) K-近鄰 (K-Nearest Neighbors)"},{"content":"前面 5 天我們聚焦於「回歸系列」模型: 線性迴歸 (Linear Regression)、多項式迴歸 (Polynomial Regression)、正則化迴歸 (Lasso / Ridge / ElasticNet Regression) 以及邏輯迴歸 (Logistic Regression)。雖然它們名稱上都掛著「Regression」，實則涵蓋了連續值預測與分類任務兩大主題。\n在正式進入其他學習範式前，我想透過這篇文章做一個小結，幫助讀者重新理解「迴歸模型的核心精神」，並進一步延伸思考「什麼是機器學習的學習」。\n迴歸模型統整與對比 模型 任務類型 是否可擴展非線性 是否有正則化 適用場景 代表限制 Linear Regression 迴歸 否 否 數據關係明確線性、特徵少時 對離群值、共線性敏感 Polynomial Regression 迴歸 ✅ 否 存在非線性曲線關係時 過度擬合風險高 Lasso / Ridge / ElasticNet 迴歸 ✅ ✅ 高維度資料、需特徵選擇時 模型可解釋性略減 Logistic Regression 分類 否 ✅ (可搭配) 二元分類、機率預測、可解釋性要求高場景 不適合複雜非線性邊界 這四種模型本質上都假設資料可以被一個「參數化的函數」所建模，且可以透過某種「最小化損失」的方式來進行學習。而這種最小化行為，正是機器學習中最常見的學習模式: 梯度下降法 (Gradient Descent)。\n為什麼梯度下降能「學習」? 這是一個我自己也還在思考的問題。梯度下降看似只是數學上的最小化技巧，但其實它蘊含了學習的邏輯核心: 錯誤導向的自我修正。\n每一次模型的預測錯了，就利用這個錯誤的方向與程度，去修正模型的參數，使下一次預測更好。這種機制背後隱含的三個條件，值得特別點出:\n✅ 存在可微分的損失函數 ✅ 模型是參數化的 (parameters 可調整) ✅ 可以反覆試誤 (迭代優化) 符合上述條件，模型便可以「學習」。也正因如此，這四個回歸模型雖然類型不同 (分類 / 迴歸)、形式不同 (線性 / 非線性 / 正則化)，但都共享「透過梯度下降調整參數」這一關鍵本質。\n","date":"5 August 2025","permalink":"http://twcch.io/posts/column_article/ironman_2025_30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/articles_25080501/","title":"(Day 7) 回顧迴歸：從線性邏輯到學習本質"},{"content":"在上一篇中，我們深入介紹了邏輯迴歸的模型邏輯、損失函數與分類行為。這篇則要進一步延伸這個經典模型，回答一個關鍵問題: 邏輯迴歸能否結合多項式特徵與正規化機制，來對抗非線性與過擬合問題?\n在實務中，這樣的需求非常常見，但你可能很少看到「多項式邏輯迴歸」或「正規化邏輯迴歸」這樣的說法。雖然命名不常見，但本質上邏輯迴歸完全可以與這兩個技巧結合使用，而且這種搭配在複雜資料下是極具威力的實務技巧。\n為什麼邏輯迴歸可以搭配多項式與正規化? 邏輯迴歸其實是線性模型 邏輯迴歸雖然應用在分類任務f，但本質仍是一種「線性模型」:\n$$ \\hat{y} = \\sigma(\\beta_0 + \\mathbf{x}^\\top \\boldsymbol{\\beta}) $$\n這表示它只能建構一條線性的 decision boundary。當你的資料本身具有非線性邊界時，例如 XOR 類型的資料，這條邏輯迴歸線就顯得力不從心。\n解法之一，就是在原始特徵上做多項式擴展 (Polynomial Feature Expansion)——也就是增加特徵空間的非線性組合，例如 $x_1^2$、$x_1 \\cdot x_2$ 等，來幫助模型在更高維度中建立線性可分的邊界。\n這與之前我們在線性迴歸所談的邏輯迴歸原理一樣，只是這次應用在分類問題中。\n邏輯迴歸也容易過擬合 一旦你使用多項式特徵，特徵數暴增，就可能發生過擬合，這時就需要正規化 (Regularization) 機制來抑制模型複雜度。\n與 Linear Regression 一樣，邏輯迴歸可以透過 L1 或 L2 懲罰項達到正規化的目的:\nL2 (Ridge): 抑制權重值變得太大 L1 (Lasso): 推動部分權重變為 0，具有特徵選擇效果 Elastic Net: L1 + L2 混合調整 值得注意的是，在 PyTorch 中，optimizer 的 weight_decay 只對應 L2，若要做 L1，則需自行加上額外的懲罰項。\n模型實作 這個案例也一樣，使用 PyTorch 來實現，透過這段程式碼來窺探 Logistic Regression 的細節。但是還是要再次聲明一下，不論是機器學習演算法，還是說什麼排序的那些算法，你自己寫的打概率打不過這種主流套件做出來的方法，因為這些方法可能經過 10 幾年以上的迭代，不斷地維護與優化產生的，所以如果是學習的話可以自己做，但是正式要使用的話還是建議直接用這些現成的方法，表現往往更加優秀。\n","date":"4 August 2025","permalink":"http://twcch.io/posts/column_article/ironman_2025_30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/articles_25080401/","title":"(Day 6) 邏輯迴歸 (多項式 + 正規化)"},{"content":"邏輯迴歸 (Logistic Regression) 是一種常見的分類模型，主要用於預測二元分類或多元分類，有別於先前的線性迴歸是用來預測無邊界的連數據值，而邏輯迴歸間單來說就是預測有邊界的不連續數值，如 [0, 1], [1, 2, 3]。\n模型介紹 模型邏輯與核心概念 那邏輯回歸是如何運作? 其實不論是哪種邏輯迴歸，底層都是先透過線性迴歸來預測，只是分別透過不同的激活函數與損失函數來處理，但是邏輯迴歸一般來說還是比較常用於二元分類，來看看以下流程:\n假設有一條線性迴歸方程式: $\\hat{y} = \\beta_0 + \\mathbf{x}^\\top \\boldsymbol{\\beta}$。(注意: 這條不是最佳的線性迴歸線) 會針對前述的線性迴歸方程式結果，透過 sigmoid 函數，將結果轉換成 [0, 1] 假設損失函數 (Cost Function): Binary Cross Entropy 最後使用梯度下降 (Batch Gradient Descent) 來最小化損失函數，找出最佳的邏輯迴歸線 以上就是二元分類邏輯迴歸的原理，那麼我們來看看多元分類邏輯迴歸是如何處理\n假設有一條線性迴歸方程式: $\\hat{y} = \\beta_0 + \\mathbf{x}^\\top \\boldsymbol{\\beta}$。(注意: 這條不是最佳的線性迴歸線) 會針對前述的線性迴歸方程式結果，透過 softmax 函數，將結果轉換成機率總和為 1 的組合 假設損失函數 (Cost Function): Categorical Cross Entropy 最後使用梯度下降 (Batch Gradient Descent) 來最小化損失函數，找出最佳的邏輯迴歸線 可以看出不同的邏輯迴歸，只是分別透過不同的激活函數與損失函數來處理，雖然邏輯迴歸可以用於多元分類，但是一般來說還是比較常用於二元分類。\n模型評估指標 Accuracy: 整體正確率 Precision / Recall / F1-score: 評估正例預測品質與召回 ROC-AUC: 考量不同閾值下模型分類能力 Confusion Matrix: TP、TN、FP、FN 分佈 Log Loss: 概率預測與實際標籤差異 適用情境 Target 為二元分類 (0/1、是/否) 或多元分類 需要同時獲得概率估計與可解釋性 限制條件 多重共線性: 高度相關特徵會影響係數穩定性 極端值敏感: 離群點可能顯著扭曲模型 模型實作 這個案例開始為了讓讀者有更好的感覺模型的過程，會分別使用 sklearn 與 PyTorch 來建模。但是必須先聲明，無論是手動撰寫或是透過 PyTorch 來模擬出來，都不一定有辦法比 sklearn 提供的演算法來得更優秀，所以除非有特殊目的，否則使用 sklearn 提供的演算法效能與準確性都會較高。\n","date":"3 August 2025","permalink":"http://twcch.io/posts/column_article/ironman_2025_30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/articles_25080301/","title":"(Day 5) 邏輯迴歸 (Logistic Regression)"},{"content":"延續昨日的多項式迴歸中，我們觀察到一個現象: 雖然二次特徵提升了模型的表現，但同時也引入過擬合 (Overfitting) 風險。這是因為當特徵數量暴增，模型就會變得過於「貪婪」，試圖將每個資料點都擬合得極好，結果反而喪失了在新資料上的泛化 (Generalization) 能力。\n那怎麼辦? 就是在多項式迴歸的基礎上，限制模型的自由度，也就是今天要介紹的——正則化回歸 (Regularized Regression)。\n這是一種透過在模型參數加上限制，以提升泛化能力 (該操作並非為了提高準確度)，讓它在「解釋資料」與「控制複雜度」間取得平衡。最常見的三種正則化技術分別為:\n套索回歸 (Lasso Regression): L1 Normalization 脊回歸 (Ridge Regression): L2 Normalization Elastic Net Regression: L1 + L2 Normalization 模型介紹 模型邏輯與核心概念 先回到 Day 2 的線性迴歸，線性迴歸如何找出最佳的迴歸線?\n先設定損失函數 (Cost Function) 假設為 $MSE = \\frac{1}{2n} \\sum\\limits_{i=1}^{n} (y_{i} - \\hat{y}_{i})^{2}$。 再使用梯度下降 (Batch Gradient Descent) 來最小化損失函數。 而所謂的正規化迴歸就是在損失函數加上懲罰項，而前述那些不同的正規化迴歸名稱，就只是懲罰項的差異而已，以下是正規化迴歸的懲罰項:\n套索迴歸: $\\lambda \\sum |\\beta_i|$ 脊迴歸: $\\lambda \\sum \\beta_i^2$ Elastic Net Regression: $\\lambda_1 \\sum |\\beta_i| + \\lambda_2 \\sum \\beta_i^2$ 我們先來看看這幾種正規化的效果差異:\n","date":"2 August 2025","permalink":"http://twcch.io/posts/column_article/ironman_2025_30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/articles_25080201/","title":"(Day 4) 正規化迴歸 (Regularization Regression)"},{"content":"昨天介紹了線性迴歸 (Linear Regression)，它適合用來處理特徵與目標之間為線性關係的情境。然而，真實世界的資料往往並非純粹線性，而是呈現複雜的非線性關係，例如曲線、拋物線、甚至更複雜的波動趨勢。\n就有了多項式特徵 (Polynomial Feature) 的出現，而線性迴歸搭配多項式特徵，就是所謂的多項式迴歸 (Polynomial Regression)，便是為了解決線性模型難以處理的非線性問題。它的核心概念非常簡單就是透過對特徵進行多項式轉換，使模型能夠捕捉非線性趨勢。\n模型介紹 模型邏輯與核心概念 這塊幾乎與昨天介紹的線性迴歸一樣，重複的部分就不多做介紹。因為多項式迴歸本質上仍是線性迴歸，但特徵空間經過非線性轉換，讓模型能擬合更複雜的曲線。以下為多項式迴歸的公式:\n$$ \\hat{y} = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\dots + \\beta_d x^d $$\nd 稱為 polynomial degree (多項式階數)，是模型中最重要的超參數之一。 特徵不只可以加入單一變數的高次項，也可加入多個變數間的交互項 (例如 $x_1x_2$)。 運作原理 假設方程式 (degree = 3): $\\hat{y} = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\beta_3 x^3$ 透過將輸入特徵 $x$ 映射為高階次多項式 (如 $x^2, x^3, \\dots$)，使模型能擬合彎曲或非線性趨勢，特徵會經過變換形成新的變數，然後再應用一般線性回歸模型進行估計。 degree = 3 (對所有 features 做所有「總次數 ≤ 3」的項次組合) 多項式特徵的處理會產生新的特徵 要特別注意，如果在特徵工程有人工建立交互項，不可直接使用 PolynomialFeatures 來處理，因為不會辨識你手動做出的交互項，會產生重複或邏輯不一致的問題，要特別處理。 舉例: 假設有一組資料，特徵有 [\u0026lsquo;x1\u0026rsquo;, \u0026lsquo;x2\u0026rsquo;]，設定 degree=3 做 PolynomialFeatures，這組資料的特徵會變成 [\u0026lsquo;x1\u0026rsquo;, \u0026lsquo;x2\u0026rsquo;, \u0026lsquo;x1^2\u0026rsquo;, \u0026lsquo;x1 x2\u0026rsquo;, \u0026lsquo;x2^2\u0026rsquo;, \u0026lsquo;x1^3\u0026rsquo;, \u0026lsquo;x1^2 x2\u0026rsquo;, \u0026lsquo;x1 x2^2\u0026rsquo;, \u0026lsquo;x2^3\u0026rsquo;]，他會自動做交互項處理，如果有手動生成交互項就不能再做 PolynomialFeatures 適用情境 當資料呈現曲線趨勢時，線性回歸無法捕捉其變化 限制條件 degree 過高，容易導致 Overfitting (尤其在資料量小時) 高維度下容易產生特徵爆炸 對比 Linear Regression 其模型可解釋性下降 模型實作 資料集介紹 將使用經典的 Boston Housing Dataset 為例。由於 scikit-learn 已移除該資料集，我們改採自 Carnegie Mellon University 所提供的公開版本。樣本內容如下:\n","date":"1 August 2025","permalink":"http://twcch.io/posts/column_article/ironman_2025_30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/articles_25080101/","title":"(Day 3) 多項式迴歸 (Polynomial Regression)"},{"content":"線性迴歸 (Linear Regression) 是統計學中的一種預測方法，主要分為簡單線性迴歸 (Simple Linear Regression) 與多元線性迴歸 (Multiple Linear Regression)，又稱複迴歸，以及其他變形的迴歸等，但在線性迴歸中，通常會有 1~N 個自變數 (Independent Variable) X，也可以稱作特徵 (Feature)；和 1 個因變數 (Dependent Variable) Y，也可以稱作目標 (Target)。而最終目的就是找出一條最佳迴歸線，來擬合這些數據點，便可以用來預測未來的數據點。\n模型介紹 模型邏輯與核心概念 線性迴歸假設 統計學線性迴歸的經典的五大假設:\n線性關係: 自變數與因變數之間存在線性關係 誤差項獨立 (Independence): 誤差項之間沒有相互關係 同標準差性 (Homoscedasticity): 對於所有的自變數，誤差項具有相同的標準差 誤差項常態性 (Normality of Errors): 誤差項應該成常態分佈 高度共線性 (Multicollinearity): 自變數間高度線性相關 看到這邊會想說，為什麼要特別註明統計學? 跟機器學習無關? 先記住一句話「統計學重推論，機器學習重預測」，很多假設跟機器學習中的線性迴歸模型還真的沒有太大的關係，但是也不代表，機器學習模型完全沒有假設，但是相對比較不重要，這也是為什麼很多仿間的機器學習教材都會忽略假設這塊。\n總而言之，機器學習模型不像統計學模型需要那麼嚴謹的假設，但是若違反某些假設，也是會影響機器學習模型的表現，也會使得模型只能用於預測，無法用於推論，以下簡單整理假設對統計模型與機器學習模型的影響:\n假設 對傳統統計模型影響 對機器學習影響 建議處理方式 線性關係 ✅ 極高 (核心假設) ❌ 可忽略 (可透過特徵轉換處理) 用非線性模型 / 特徵轉換 誤差獨立性 ✅ 高 (推論與解釋需此條件支持) ✅ 高 (對 generalization 有直接影響) 使用適當資料分割策略 同變異性 ✅ 中高 (影響參數估計的信度) ❌ 可忽略 (模型的估計值仍然準，但 p-value、CI 失真) 變數轉換、加權最小平方法 誤差常態性 ✅ 中高 (特定推論工具須常態性支持) ❌ 可忽略 若僅做預測可忽略 共線性 ✅ 高 (嚴重影響模型可解釋性與推論) ❌ 可忽略 (但建議修正以利解釋) VIF、降維、正則化 運作原理 我們先回到線性迴歸的用途與目的，簡單來說就是「找出一條最佳直線，來擬合這些數據點，便可以用來預測未來的數據點」，如何找出最佳直線? 本文會簡單的介紹一下，詳細過程與原理，再請讀者自行尋找其他資源暸解。\n","date":"31 July 2025","permalink":"http://twcch.io/posts/column_article/ironman_2025_30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/articles_25073101/","title":"(Day 2) 線性迴歸 (Linear Regression)"},{"content":"在學習機器學習 (Machine Learning) 的過程中，可能會陷入兩種極端，一種是只會調用套件 (套模)，模型背後的機制一知半解，遇到問題只能「換模型試試看」，或者是過度陷入數學細節，花大量時間推導公式，卻無法轉化為實際應用與模型選擇能力。\n我本身是從商業分析背景轉入人工智慧領域的研究者。這段轉型過程中，逐漸體會到: 真正困難的不是學會用模型，而是理解模型為什麼有效、什麼時候該用、什麼時候該換、用了之後該觀察什麼訊號。這促使我開始重新梳理各類常見演算法的行為與應用邏輯。\n因此，我決定透過這次 iThome 鐵人賽的機會，整理與統整常見演算法的核心概念，並將每一篇視為一場與模型的深度對談。\n系列架構說明 本系列分為兩大部分:\n經典機器學習模型: 聚焦於 Regression、Classification、Clustering 等常見方法，強調模型背後的核心邏輯、適用情境與評估指標。 深度學習模型: 介紹常見神經網路架構，如全連接神經網路 (FCNN)、CNN、RNN、Transformer 等，並探討它們對資料型態、任務種類的適應性與限制。 每篇文章皆會包含模型概念說明與簡潔的 Python 範例實作，並聚焦於模型本身的行為與選擇策略，不深入探討資料前處理、特徵工程、模型調參、數學推導等高階內容，以避免模糊焦點。\n技術範圍與預期對象 本系列預設讀者已具備以下條件:\n具備基礎統計學與資料科學知識 具備基本 Python 語法能力 具備 scikit-learn, PyTorch, TensorFlow, Keras 基本建模流程 學習深度定位: 聚焦在 Level 2–3 之間 等級 定義 在本系列的實踐目標 Level 1 會用套件建模 ✅ 使用 sklearn 等工具快速建模 Level 2 理解模型的概念與原理 ✅ 說得出每個模型的邏輯與核心機制 Level 3 能比較模型優劣與應用場景選擇 ✅ 理解適用時機、模型之間的 trade-off Level 4+ 深入優化與理論推導 🚫 本系列不會深入涵蓋，建議另尋高階資源 系列預告與進展節奏 本系列將以「一日一模型」為目標，每篇聚焦於一個經典或常見模型，從實用視角出發說明其:\n核心邏輯與設計理念 適用情境與限制條件 與其他模型的比較與選擇策略 Python 範例實作與評估觀察 預計涵蓋模型範圍包括: Linear Regression、Polynomial Regression、Logistic Regression、SVM、KNN、Decision Tree、Random Forest、XGBoost、PCA、KMeans、FCNN、CNN、RNN、Transformer \u0026hellip; 等。\n","date":"30 July 2025","permalink":"http://twcch.io/posts/column_article/ironman_2025_30%E5%A4%A9%E5%85%A5%E9%96%80%E5%B8%B8%E8%A6%8B%E7%9A%84%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%BC%94%E7%AE%97%E6%B3%95/articles_25073001/","title":"(Day 1) 介紹與準備"},{"content":"近年來，我觀察到無論在台灣還是中國，「學歷無用論」的聲音愈發強烈。許多人開始質疑讀書是否還有意義，認為不靠學歷反而更能致富，網紅、直播、投資客、白手起家的商人充斥版面，讀書人反倒被視為落後者、被剝削者、社會規訓的犧牲品，但我有不同的看法。\n為什麼「學歷無用論」會出現？ 我認為這不是單純的個人選擇，而是結構性問題:\n教育擴張讓學歷貶值，碩博士已成基本門檻 階級複製讓弱勢者難以翻身，「努力不再保證回報」 高回報的機會集中在少數風口行業，炒短線者當道 社群媒體製造「一夜暴富」神話，反智氛圍蔓延 「讀書沒用」已經不只是判斷，更是一種情緒對制度失望、對未來無感、對努力失信。\n那讀書究竟還有沒有價值? 如果只探討「賺多少錢」作為唯一標準，那的確讀書沒有用，因為讀書不一定有最即時的回報。但若把時間尺度拉長、把價值層次拉高，會發現:\n學習不是為了立刻賺錢，而是為了讓你能夠分辨真偽、建立邏輯、理解世界、保有尊嚴地思考與行動\n工具層面: 讓你擁有專業能力，立足於社會 認知層面: 訓練你思辨、整合、表達的能力 存在層面: 引導你認識自己、世界與人生的關係 簡單來說，我 30 年的人生觀告訴我，讀書可以讓我的境界提升，能夠自我昇華\n我們為什麼會覺得「努力應該有回報」? 許多陷入犬儒的人會說：「我不是不努力，我努力過了，沒用。」\n這恰恰反映出對努力的誤解，努力是會失敗的，而且也從來不會立即兌現，它更像是一種長期累積的複利，過程中你會改變視角、強化心智，最終與眾不同\n真正的努力，不只是行為上的執行，更是認知上的轉變。不是用熱血硬幹，而是用策略、用反思、用節奏走出自己的路。\n那我們應該怎麼做？ 不要盲目追求文憑，但也不要過早放棄學習 看懂社會結構的變動，但也要打造自己可控的核心能力 知道短期內「投機」可能勝出，但長期是價值與認知力的勝利 一段送給未來自己的話 讀書不是為了成功，而是為了不被世界輕易騙走 當社會用最廉價的快樂來交換你一生的時間時 教育與自省，是你最後的防線\n哪怕這個時代看起來對知識不再禮遇，我仍願意選擇學習，因為我相信厚積才能薄發，深耕才能穿透表象，真正理解世界，並在其中活出自己的姿態\n","date":"16 July 2025","permalink":"http://twcch.io/posts/articles_25071601/","title":"學歷無用? 我仍相信學習的價值"},{"content":"這是一個資料視覺化專案——「Dynamic Visualization: 200 Countries, 200 Years, 4 Minutes」。它將涵蓋 1816 至 2016 年，200 個國家的歷史變遷以互動動畫呈現，整體動畫長度約四分鐘，旨在結合「時間」與「地理」維度，提供用戶沉浸式的歷史視覺體驗。\n成品呈現頁面: https://twcch.io/TwoHundredYearsTwoHundredCountries/views.html\nGitHub 原始碼: https://github.com/twcch/TwoHundredYearsTwoHundredCountries\n專案目標: 動態傳遞跨時代趨勢 我這次的核心目的，是打造一段「高品質又美觀」的互動式動畫。相比靜態圖表，此動畫能讓使用者更直覺地感受到全球歷史變化的脈絡與節奏。\n跨國維度: 一次呈現 200 國家在相同指標上的變化 跨年代視角: 覆蓋整整兩個世紀 互動與美感: 最終以 Plotly Express 強化動畫的動態感與互動性 這是一個典型的「Proof of Concept」，驗證我能用純 Python 開源工具在本地完成動態資料視覺化，而不是依賴商業軟體。\n處理流程解析 資料擷取與清理 使用 pandas 從 Gapminder 或其他開源來源讀入年份、國家與指標。 透過 core/data.py 標準化欄位名稱、處理缺值、並轉換為長型結構，以利後續分析。 寫入 SQLite 為了方便查詢與存取，我用 core/sqlite_db.py 將清理後的資料匯入 SQLite 資料庫，一併記錄 metadata。 產生視覺化資料表 scripts/build_view_table.py 將資料按年與國家展開，組合成完整用於視覺化的 DataFrame。 動態驗證：matplotlib 原型 在 proof_of_concept.py 中，以 matplotlib 建立由靜態圖逐幀拼湊的基本動畫，確認播放邏輯與視覺節奏。 互動動畫：Plotly Express 最終在 plot_with_px.py 中改以 Plotly Express，產出包含滑動條、國家標籤、時間軸與音效的四分鐘互動畫面，並輸出至 docs/views.html。 技術選擇與實務考量 資料處理: pandas 濾除缺值、重塑表格、處理 metadata，全套操作都在 pandas 中完成。 儲存管理: 使用 SQLite 儲存資料，方便查詢與重複執行，而不用每次都從頭開 CSV。 動畫原型: matplotlib 可迅速驗證概念、調整幀率與時間間隔。 互動視覺化: Plotly Express 能更快速加入滑桿、hover 標籤，動畫更加流暢美觀，也更適合網頁展示。 展示成果 最終輸出是一個 HTML 檔，內嵌動態 html5 視覺化:\n","date":"9 July 2025","permalink":"http://twcch.io/posts/projects/articles_25070901/","title":"視覺化專案 - 200 個國家 200 百年 4 分鐘"},{"content":"這是一個資料科學專案，目標是透過 Kaggle 經典的 Titanic 生存預測題目，建立一套結構清晰、模組化的預測系統。我不只是想交出一份準確的預測結果，更希望藉由這個專案練習:\n如何設計可擴充、可維護的資料分析架構 如何把模型訓練與推論流程標準化 如何用設定檔 (config-driven) 控制整個 pipeline 如何實踐工程導向的資料科學流程 GitHub 原始碼: https://github.com/twcch/TitanicSurvivalPrediction\n專案定位：不只是「解題」，而是「設計一套解法系統」 我不滿足於單純把資料丟進模型調整參數。我希望打造的是一個「可重複使用的機器學習預測框架」，因此我做了以下幾點設計:\n架構模組化: 依照功能拆分為 data/, features/, models/, utils/，程式碼清楚分工 流程自動化: 所有步驟都由 main.py 控制，方便一鍵執行與重現實驗 設定檔驅動: 核心設定集中管理於 config.json，可以快速切換特徵、模型參數與輸出路徑 可擴充性設計: 未來若要換模型、加特徵、改評估指標，幾乎不需改動主程式碼 這些設計不只是在技術上提升效率，也讓我在做資料科學時，更接近實務工作者的思維模式\n資料前處理與特徵工程: 每個欄位都要能「解釋」 我對特徵的要求是: 不只要對模型有用，更要有邏輯、可解釋\n處理缺失值 Age 用中位數填補 Embarked 用眾數填補 Fare 缺值極少，仍完整處理 創造新特徵 FamilySize = SibSp + Parch: 模擬家庭是否有互助效果 選定使用特徵 類別型: Pclass, Sex, Embarked, Title 數值型: Age, Fare, FamilySize 模型設定: 我選擇 XGBoost，但更重視可控性 雖然這個任務可以用很多模型解，但我選擇以 XGBoost 為主模型，理由如下:\nTree-based 模型不需要特徵標準化，工程處理更簡潔 對類別特徵與數值特徵的混合表現良好 在 Kaggle 類似任務中表現穩定，可作為 baseline 模型訓練與推論流程 整個流程包含以下幾步，由 main.py 控制:\n","date":"30 June 2025","permalink":"http://twcch.io/posts/projects/articles_25063001/","title":"實戰專案 - Titanic 生存預測專案"},{"content":"最近，我正在參加一門職訓課程。本來對這堂課滿懷期待，尤其是對某位老師的專業背景很感興趣。不過，隨著課程進行，我漸漸感到一股說不出的落差感：每當我主動提出深入問題，收到的回信卻幾乎都像是 ChatGPT 生成的答案——格式漂亮、邏輯完整、語氣中立，但就是少了「人味」與「針對性」。\n是的，我知道他不是完全照抄。他有修改、有加註、有整合，但整體感受依然強烈：「這不是一個人對我問題的理解回應，而是一個工具對所有人都能複製的輸出。」\n這讓我很困惑，甚至有些失望。\n我不是反對使用 AI，事實上我自己也在用 先聲明，我並不是那種抗拒 AI 的人。相反地，我本身就是資料分析背景，也有使用 ChatGPT 作為輔助工具的習慣。無論是整理技術架構、釐清概念、或產出初步內容，我完全理解 LLM 在學習與知識組織方面的強大價值。\n但關鍵在於：「角色不同、責任也不同。」\n身為學習者，我使用 AI 是為了提升效率與學習深度。但作為老師、講師、顧問，使用 AI 不應該只是「產生回答」這麼簡單。\n教學不是交付答案，而是理解問題的脈絡 作為學生，我真正期待的，不是單純的一段知識回答，而是來自老師對我所處困境的共鳴與理解。我希望老師能理解我提問背後的「背景」、「盲點」與「問題設計的目的」，並根據這些脈絡回應，而不是直接貼上一段 ChatGPT 輸出的技術解釋。\n因為我相信，一個真正理解我問題的老師，會根據我當下的能力、背景、甚至目標給出回應——這種回應，不是任何一個 AI 可以「直接」產出的。\n而當老師只是當 ChatGPT 是一個快捷鍵，那麼學生也很快會意識到：你不是在回答我，你只是在轉寄一份資訊而已。\n當教學淪為「貼文產出」，學生會停止問問題 更嚴重的影響是：這樣的互動會直接打擊學生的提問動力。\n當我發現提問後收到的回應只是套用模板、換個措辭、格式一致卻無深入探討時，我會懷疑：\n我這麼認真思考的問題，真的值得你花時間思考嗎？ 還是我只是你輸入框中的另一個 prompt？ 久而久之，學生開始不再問問題，也不再相信提問能帶來真正的理解與對話。這對整個學習場域，是一種靜默但致命的傷害。\nAI 是輔助，不是教學本體 AI 可以作為老師教學的輔助工具：幫助蒐集資料、釐清知識、快速構思。但它不應該代替老師對學習者的思考與理解責任。在這個知識容易複製的年代，真正無法取代的價值，其實是「對個別學習者的回應能力」。\n我們當然不會要求每個老師都要一封封親筆手寫、寫出三千字的回信。但至少請不要用 ChatGPT 當成唯一的內容產出來源，更不要用它來「掩蓋」缺乏投入的回應。學習者看得出來，也感受得到。\n我寫這篇文章，不是為了批評老師，而是為了保護教學 我知道那位老師並不是惡意。他可能工作繁忙、學生太多、壓力很大。我甚至相信他是出於「想要給一個完整答案」的好意才選擇這樣回覆。但我們必須正視一件事：當我們過度依賴工具，而忘記了教學的本質是人與人之間的理解與連結，那麼再強大的 AI 也只會讓教育變得更冷漠、更廉價。\n我寫這篇文章，是希望提醒每一位教學者：你的價值，不在於你給的答案有多完整，而在於你有多願意理解學生的問題。因為 AI 可以幫你教知識，但唯有你能教會「怎麼成長」。\n","date":"25 June 2025","permalink":"http://twcch.io/posts/articles_25062501/","title":"當老師只靠 ChatGPT 回信：我們期待的不是答案，而是理解"},{"content":"在資料科學領域中，對企業進行舞弊檢測 (Fraud Detection) 被視為是一種分類問題: 輸入企業相關的數據，輸出舞弊或非舞弊。然而，真正投入研究後會發現，這個問題很難解決，非常具挑戰性。\n我目前主要研究方向，是運用人工智慧 (Artificial Intelligence) 技術，來解決企業進行財務報表舞弊的問題。這類型的議題與銀行信用卡詐欺、保險業中的理賠舞弊、甚至洗錢行為有相似之處，都是稀有事件、後知後覺、動態進化的「敵對性問題」。\n為什麼這不是一個單純的分類問題？ 在傳統機器學習框架下，分類問題的成功往往來自於充足的標記數據、清晰的邊界條件與相對穩定的資料分佈。然而，舞弊行為恰恰違反了這三項假設。\n可以從以下幾點具體說明：\n極度不平衡的資料 (Class Imbalance)\n在實務資料中，舞弊案件往往只佔所有資料的極小比例，可能是千分之一、甚至萬分之一。這意味著如果你採用傳統的精確度 (accuracy) 作為衡量指標，模型即使完全忽略舞弊也能達到 99% 以上的準確率，但這顯然毫無意義。\n標籤不完整且滯後揭露 (Label Latency \u0026amp; Missing Labels)\n很多舞弊行為要經過數月、甚至數年後才會被調查揭露，更遑論那些永遠未被發現的案件。這使得訓練資料的標籤具有高度不確定性，導致模型容易學到錯誤的決策邊界。\n舞弊技術持續演化 (Concept Drift)\n犯罪者會根據監管與模型檢測方式持續更新手法，導致模型在部署後迅速失效。這使得即使當下訓練準確的模型，也難以長期維持效能。\n異常並非來自單一特徵，而是整體脈絡的矛盾 (Contextual Inconsistency)\n財報舞弊往往不是單一財務指標異常，而是多個指標之間出現結構性不一致。例如: 營收大增但現金流卻大減、獲利提升但存貨異常膨脹。這種多變量脈絡異常，遠比簡單的 outlier detection 更為複雜。\n問題不是模型選得不夠好，而是問題設定錯了 如果僅停留在「用哪個模型比較準」、「要不要用 XGBoost 還是 LSTM」這種層級的思考，只會陷入技術細節的死胡同，無法解決核心困難。相反地，我認為更關鍵的兩個研究方向是：\n如何讓 AI 自己找到潛在的舞弊標籤？\n採用自監督學習 (Self-Supervised Learning)，不依賴人工標註，而是讓模型自行從大量正常樣本中學習「常態結構」，再對偏離常態的資料進行異常評分，進一步推論出可能的舞弊行為。\n如何讓深度模型的決策可以被人類審計人員理解？\n深度學習模型雖然強大，但往往是黑箱。導入可解釋性方法 (如 SHAP、LIME、Attention 可視化)，可以提升金融監理與內部稽核部門的信任與採用意願，也為模型導入實務場域鋪路。\n這不只是建模問題，更是科學問題 用 AI 解決舞弊，不是一場簡單的技術堆疊競賽，而是對整個金融風險邏輯、舞弊行為模式、以及資料特性深刻理解的綜合挑戰。這將是我博士研究的起點，從理解問題本質出發，探索如何用 AI 技術建立可行的風險偵測系統，不只是要「分類得準」，更要讓人「信得過」。我認為這是一條難走的路，但也因此充滿價值。\n","date":"2 June 2025","permalink":"http://twcch.io/posts/articles_25060201/","title":"為什麼用 AI 技術檢測企業舞弊，比想像中更困難？"},{"content":"五年前，我踏入壽險產業，成為一名 Business Analyst (BA)。當時的工作內容相當清晰：需求文件撰寫、報表製作、簡單的數據分析與溝通協調，是我每天的日常。那時候，這些任務仍需靠人力一項一項完成，效率與品質全憑個人經驗與熟練度。但如今，這些「核心能力」正快速被人工智慧工具重塑，甚至取代。\n我親身感受到的衝擊：工具進步得比我想像中快 當我首次使用大型語言模型 (LLM) 工具進行報告撰寫與 Python 代碼產出時，內心的震撼難以言喻。曾經需要數小時才能完成的分析報告，在幾分鐘內生成雛形；曾經為了釐清邏輯關係而反覆修改的流程圖，如今只需一句指令就能完成。\n我逐漸意識到，這並不是單一任務被加速，而是整個 BA 工作流程正被結構性重塑。換言之，AI 正在壓縮 BA 的邊際價值。這不只是主觀體感，更有明確的研究支持。根據美國 OpenAI 與賓州大學的聯合研究，約有 80% 的職業至少有 10% 的工作內容將受到 LLM 工具的影響；其中，高達 19% 的職業，其超過一半的工作可由 AI 完成。而 BA——尤其是負責初階文件處理、標準報表、流程規劃等工作的分析師，被列為高曝險族群。\n原因很明確因為 BA 所擅長的文字組織、資料彙整與需求敘述，正是 AI 最擅長模仿與執行的任務。\n市場變化正在發生，不是未來式，而是現在進行式 這樣的趨勢已經開始反映在勞動市場上：\nBA 的職缺增速放緩\n企業在內部導入 LLM 工具後，發現許多重複性任務可由 AI 初步完成，人力需求自然下降。\n初階 BA 的薪資競爭力下降\n對於只熟悉基本分析任務、無法主動創造洞察的人才，企業的願意支付薪資上升空間有限。\n高階 BA 的需求反而上升\n企業更看重能駕馭 AI 工具、快速整合資訊、提出具策略意義建議的分析人才。所謂「會用 AI 的人」，正逐步取代「被 AI 取代的人」。\n這代表，AI 並不是取代所有 BA，而是取代了不進化的 BA。\n我的轉型：從反應式執行者，到主動創造者 面對這樣的劇變，我無法視若無睹。\n於是我開始盤點自己的能力，明白單靠產業 Know-how 或不夠專精的技能，將難以應對未來的競爭。因此，我選擇投入更深層的技能學習: 博士班訓練，深度的掌握資料科學、機器學習與深度學習領域，建立自身的核心競爭力。不只是會用工具或套模，而是要能理解這些如何運作、能應用在哪些情境、又有何種侷限。這樣的技能，不僅能讓我在日常分析中脫穎而出，也為我開啟進入 AI 應用領域的可能性。\n結語：AI 不會毀滅職涯，但它會重寫價值分佈 AI 並不會取代 BA，但它會重新定義 BA 的角色。\n","date":"7 April 2025","permalink":"http://twcch.io/posts/articles_25040701/","title":"為什麼 AI 正在快速削弱低階 Business Analyst 的價值？"}]