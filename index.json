

    

[{"content":"關聯規則探勘，是一門讓資料自己開口說話的技術。它不預測未來，也不分類人群，而是靜靜地從無數筆交易中，尋找那些「總是一起出現」的痕跡。對數據分析師而言，這是一種不同於統計假設的思考方式——它不帶偏見，不設方向，只追隨共現的規律。\n啤酒與尿布的啟示 許多人第一次聽到「關聯規則探勘」 (Association Rule Mining) 這個名詞時，總會想起那個幾乎被引用成神話的故事。美國某家超市在分析顧客購物資料時，發現一個奇特的現象: 購買尿布的男性顧客，常常會順手買一瓶啤酒。\n當時的分析師並沒有先入為主地設定假設，他們只是單純讓演算法在龐大的交易資料中尋找共現的規律。結果揭露了一種不易察覺的生活節奏——年輕父親在深夜購物時，會同時買尿布與啤酒。這個行為的背後，不是消費理性，而是情緒的慰藉。\n這便是關聯規則探勘的精神所在: 它讓資料說話，而不是讓人去強迫資料符合預設的故事。在數據分析的世界裡，這種從共現關係中發現行為模式的方法，被廣泛應用於零售、金融、醫療、甚至網路內容推薦系統中。\n從購物籃看行為 想像一間超市的銷售資料表，每一筆交易就像一個購物籃 (basket)，裡面放著當次顧客購買的所有商品。我們想知道的問題其實很簡單:「哪些商品會經常一起被買走?」在資料的語言裡，這樣的問題就是「項目之間的共現關係」。\n若 20% 的交易同時出現牛奶與麵包，那麼這個組合的支持度 (support) 就是 0.2。如果在所有買牛奶的顧客中，有 80% 也買了麵包，則這條規則的信賴度 (confidence) 是 0.8。\n但僅憑這兩個數值，我們還無法判斷這是否只是巧合。因此分析師還會觀察第三個指標「提升度 (lift)」，即實際共現機率與隨機共現機率的比值。\n當 lift 大於 1，代表兩個項目之間的關聯比隨機還強；若小於 1，則可能互斥。這三個指標——support、confidence、lift——構成了關聯規則探勘的基礎語彙。\nApriori: 從最常見的開始 在技術層面上，最經典的演算法是 Apriori。它的核心思想很直觀:「若一個項目集是頻繁的 (Frequent Itemset)，那麼它的子集一定也是頻繁的。」\n這個原則讓我們得以從最基本的一項商品開始，逐步生成兩項、三項組合，並在每一層過濾不常見的組合，直到再也無法擴展。\n舉例來說，我們可以用 Python 的 mlxtend 套件進行實作:\nimport pandas as pd from mlxtend.frequent_patterns import apriori, association_rules # 模擬交易資料 (每列為一筆交易，每欄為商品) df = pd.DataFrame([ [1, 1, 0, 1, 0], [1, 1, 1, 1, 0], [0, 1, 0, 1, 1], [1, 0, 1, 1, 0], ], columns=[\u0026#39;milk\u0026#39;, \u0026#39;bread\u0026#39;, \u0026#39;beer\u0026#39;, \u0026#39;butter\u0026#39;, \u0026#39;diaper\u0026#39;]) # Step 1: 找出頻繁項集 frequent_itemsets = apriori(df, min_support=0.5, use_colnames=True) # Step 2: 產生關聯規則 rules = association_rules(frequent_itemsets, metric=\u0026#34;lift\u0026#34;, min_threshold=1.0) rules = rules[rules[\u0026#34;lift\u0026#34;] \u0026gt; 1] print(rules[[\u0026#39;antecedents\u0026#39;, \u0026#39;consequents\u0026#39;, \u0026#39;support\u0026#39;, \u0026#39;confidence\u0026#39;, \u0026#39;lift\u0026#39;]]) 輸出結果可能如下:\n","date":"6 September 2025","image":"https://twcch.io/","permalink":"https://twcch.io/posts/2025/the-art-of-association/","title":"關聯分析: 數據分析師的洞察之眼"}]